{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+66E66royauWk5FGWYf25",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mefoolyhi/PHA-Biodegradation/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#baesan ridge\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingRegressor  # Возвращаем GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import (mean_absolute_error, r2_score,\n",
        "                           median_absolute_error, mean_squared_error)\n",
        "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler, TargetEncoder, Normalizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.linear_model import LinearRegression, Ridge  # Для Platt Scaling\n",
        "from sklearn.preprocessing import PolynomialFeatures  # Для Beta Calibration\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "train_df = pd.read_excel('preprocessed_train.xlsx')\n",
        "\n",
        "X = train_df.drop(columns=['mass'])\n",
        "y = train_df['mass']\n",
        "\n",
        "bins = [-1, 1, 10, 45, 55, 65, 75, 85, 90, 100, 110]\n",
        "y_binned = pd.cut(y, bins=bins, labels=False, duplicates='drop')\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(x=y_binned, y=y)\n",
        "plt.title('Распределение по бинам стратификации')\n",
        "plt.show()\n",
        "\n",
        "print(\"Original y:\", y.values)\n",
        "print(\"Binned y:  \", y_binned.values)\n",
        "bin_counts = y_binned.value_counts().sort_index()\n",
        "print(bin_counts)\n",
        "\n",
        "# Пайплайн для препроцессинга\n",
        "numerical_cols = ['% second component', 'day', 'ph']\n",
        "categorical_cols = ['type of pha', 'environment', 'form', 'dimensionality',\n",
        "                    'porosity', 'in vivo', 'enzymatic']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='mean')),\n",
        "            ('robust', RobustScaler()),\n",
        "            ('scaler', Normalizer())\n",
        "        ]), numerical_cols),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "        ]), categorical_cols)\n",
        "    ])\n",
        "\n",
        "X_preprocessed = preprocessor.fit_transform(X, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test, y_train_binned, y_test_binned = train_test_split(\n",
        "    X_preprocessed, y, y_binned,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_binned,\n",
        ")\n",
        "\n",
        "\n",
        "adasyn = ADASYN(sampling_strategy='minority',\n",
        "                n_neighbors=1,\n",
        "                random_state=42)\n",
        "\n",
        "X_train_resampled, y_train_resampled_binned = adasyn.fit_resample(X_train, y_train_binned)\n",
        "\n",
        "\n",
        "bin_centers = []\n",
        "for i in range(len(bins) - 1):\n",
        "    lower = bins[i]\n",
        "    upper = bins[i + 1]\n",
        "    median_val = (lower + upper) / 2\n",
        "    bin_centers.append(median_val)\n",
        "\n",
        "y_train_resampled = np.array([bin_centers[int(cls)] for cls in y_train_resampled_binned])\n",
        "\n",
        "print(\"\\nРаспределение после ADASYN (только на тренировочных данных):\")\n",
        "print(pd.Series(y_train_resampled_binned).value_counts().sort_index())\n",
        "\n",
        "sample_weights = compute_sample_weight(\n",
        "    class_weight='balanced',\n",
        "    y=y_train_resampled_binned\n",
        ")\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from scipy.stats import loguniform\n",
        "\n",
        "# Определяем параметры для перебора\n",
        "param_dist = {\n",
        "    'alpha_1': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
        "    'alpha_2': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
        "    'lambda_1': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
        "    'lambda_2': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
        "    'max_iter': [100, 200, 300, 400, 500],\n",
        "    'tol': [1e-3, 1e-4, 1e-5]\n",
        "}\n",
        "\n",
        "# Создаем модель BayesianRidge\n",
        "bayesian_ridge = BayesianRidge(compute_score=True)\n",
        "\n",
        "# Настраиваем RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=bayesian_ridge,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,  # Количество комбинаций параметров для проверки\n",
        "    cv=5,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Обучение модели с подбором параметров\n",
        "random_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Выводим лучшие параметры\n",
        "print(\"Лучшие параметры:\", random_search.best_params_)\n",
        "\n",
        "# Используем лучшую модель\n",
        "best_bayesian_ridge = random_search.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "# Метрики\n",
        "def print_metrics(y_true, y_pred, model_name):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    medae = median_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    rmse_val = rmse(y_true, y_pred)\n",
        "    print(f\"\\n{model_name} результаты:\")\n",
        "    print(f\"{'Метрика':<15}{'Значение':<15}\")\n",
        "    print(f\"{'MAE':<15}{mae:.4f}\")\n",
        "    print(f\"{'MedAE':<15}{medae:.4f}\")\n",
        "    print(f\"{'R²':<15}{r2:.4f}\")\n",
        "    print(f\"{'RMSE':<15}{rmse_val:.4f}\")\n",
        "    return mae\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Визуализация результатов\n",
        "def plot_results(y_true, y_pred, title):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.scatterplot(x=y_true, y=y_pred, alpha=0.6)\n",
        "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], '--r', linewidth=2)\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.title(f'Actual vs Predicted\\n{title}')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    errors = y_true - y_pred\n",
        "    sns.histplot(errors, kde=True, bins=30)\n",
        "    plt.xlabel('Prediction Error')\n",
        "    plt.ylabel('Count')\n",
        "    plt.title(f'Error Distribution\\n{title}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Предсказания на тестовых данных\n",
        "y_pred_test_br = best_bayesian_ridge.predict(X_test)\n",
        "\n",
        "# Оценка качества\n",
        "print_metrics(y_test, y_pred_test_br, \"BayesianRidge (test)\")\n",
        "\n",
        "# Визуализация результатов\n",
        "plot_results(y_test, y_pred_test_br, \"BayesianRidge\")\n",
        "\n",
        "# Сравнение первых 20 образцов\n",
        "plt.figure(figsize=(15, 6))\n",
        "sample_indices = range(min(20, len(y_val)))\n",
        "plt.plot(sample_indices, y_val[sample_indices], 'o-', label='Actual', markersize=8)\n",
        "plt.plot(sample_indices, y_pred_val_base[sample_indices], 's--', label='Base Predicted', markersize=6)\n",
        "plt.plot(sample_indices, y_pred_val_cal[sample_indices], 'd--', label='Calibrated Predicted', markersize=6)\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Mass')\n",
        "plt.title('Comparison of Actual and Predicted Values for First 20 Samples')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "train_errors = abs(y_train_resampled - y_pred_train_cal)\n",
        "test_errors = abs(y_test - y_pred_test_cal)\n",
        "val_errors = abs(y_val - y_pred_val_cal)\n",
        "\n",
        "# 1. Сначала получим названия всех фичей после препроцессинга\n",
        "num_features = numerical_cols\n",
        "cat_features = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_cols)\n",
        "all_feature_names = list(num_features) + list(cat_features)\n",
        "\n",
        "# 2. Создадим функцию для сопоставления индексов\n",
        "def get_original_indices(X_resampled, X_original):\n",
        "    \"\"\"Находит соответствие между сэмплами после ADASYN и оригинальными данными\"\"\"\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "    # Находим ближайших соседей для сгенерированных сэмплов\n",
        "    nbrs = NearestNeighbors(n_neighbors=1).fit(X_original)\n",
        "    _, indices = nbrs.kneighbors(X_resampled)\n",
        "\n",
        "    return indices.flatten()\n",
        "\n",
        "# 3. Получаем индексы оригинальных данных для train выборки\n",
        "original_indices = get_original_indices(X_train_resampled, X_preprocessed)\n",
        "\n",
        "# 4. Создаем DataFrame с ошибками для train\n",
        "train_df_with_errors = pd.DataFrame(X_train_resampled, columns=all_feature_names)\n",
        "train_df_with_errors['True_Value'] = y_train_resampled\n",
        "train_df_with_errors['Predicted'] = y_pred_train_cal\n",
        "train_df_with_errors['Absolute_Error'] = train_errors\n",
        "\n",
        "# 5. Добавляем оригинальные категориальные признаки\n",
        "for col in categorical_cols:\n",
        "    train_df_with_errors[col] = train_df.iloc[original_indices][col].values\n",
        "\n",
        "# 6. Аналогично для test (если нужно)\n",
        "test_df_with_errors = pd.DataFrame(X_test, columns=all_feature_names)\n",
        "test_df_with_errors['True_Value'] = y_test\n",
        "test_df_with_errors['Predicted'] = y_pred_test_cal\n",
        "test_df_with_errors['Absolute_Error'] = test_errors\n",
        "\n",
        "val_df_with_errors = pd.DataFrame(X_val, columns=all_feature_names)\n",
        "val_df_with_errors['True_Value'] = y_val\n",
        "val_df_with_errors['Predicted'] = y_pred_val_cal\n",
        "val_df_with_errors['Absolute_Error'] = val_errors\n",
        "\n",
        "# 7. Функция для вывода топ ошибок\n",
        "def print_top_errors(error_df, title, n=10):\n",
        "    top_errors = error_df.sort_values('Absolute_Error', ascending=False).head(n)\n",
        "    print(f\"\\n{title} (топ-{n} наибольших ошибок):\")\n",
        "    cols_to_show = ['True_Value', 'Predicted', 'Absolute_Error']\n",
        "    print(top_errors[cols_to_show])\n",
        "    print(\"\\nСредняя ошибка в топе:\", top_errors['Absolute_Error'].mean())\n",
        "\n",
        "# 8. Выводим результаты\n",
        "print_top_errors(train_df_with_errors, \"Обучающая выборка\")\n",
        "print_top_errors(test_df_with_errors, \"Тестовая выборка\")\n",
        "print_top_errors(val_df_with_errors, \"Диссертация\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JtGIEPihP0Nq",
        "outputId": "675d6c44-39d2-4d1a-a432-52ec811cbd31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original y: [100.   95.   90.   85.   80.   75.   70.   65.   60.  100.   98.   96.\n",
            "  94.   92.   90.   88.   86.   84.   90.   80.   70.   60.   98.   90.\n",
            "  80.   70.   95.   85.   75.   65.   95.   85.   75.   65.   80.   60.\n",
            "  40.   20.   75.   50.   30.   10.  100.   97.   94.   91.   88.   85.\n",
            "  82.   79.   76.  100.   99.   98.   97.   96.   95.   94.   93.   92.\n",
            "  77.5  77.5  20.   33.   10.   20.   40.   37.5  60.   60.   25.  100.\n",
            " 100.   75.   45.  100.  100.  100.  100.   63.   53.   27.   61.   53.\n",
            "  29.   67.   54.   29.   66.   70.   64.   84.  109.   96.   77.   93.\n",
            "  70.   45.   39.   88.   94.   74.   80.   75.   37.   40.   29.   76.\n",
            "  88.   47.   62.   56.   22.   21.   19.   80.   50.   64.   34.   40.\n",
            "  40.  100.  100.  100.  100.   75.   65.  100.  100.   58.   22.   20.\n",
            " 100.  100.  100.  100.  100.  100.  100.  100.   64.9  92.5  97.  100.\n",
            " 100.  100.  100.  100.    0.    0.   92.5 100.  100.   71.7  59.4  48.3\n",
            " 100.   87.6  71.8  62.9 100.   82.6  72.4  66.  100.   76.1  67.3  56.3\n",
            " 100.   90.9  77.2  65.6 100.   89.4  76.2  66.4 100.  100.    1.6 100.\n",
            "  90.   50.   10.    0.    0.    0.   25.    0.   30.   30.   90.   99.\n",
            "   8.   10.   70.   60.  100.   58.   46.   22.  100.  100.   94.   90.\n",
            " 100.  100.   99.   94.  100.  100.  100.  100.  100.  100.  100.  100.\n",
            " 103. ]\n",
            "Binned y:   [8 8 7 6 6 5 5 4 4 8 8 8 8 8 7 7 7 6 7 6 5 4 8 7 6 5 8 6 5 4 8 6 5 4 6 4 2\n",
            " 2 5 3 2 1 8 8 8 8 7 6 6 6 6 8 8 8 8 8 8 8 8 8 6 6 2 2 1 2 2 2 4 4 2 8 8 5\n",
            " 2 8 8 8 8 4 3 2 4 3 2 5 3 2 5 5 4 6 9 8 6 8 5 2 2 7 8 5 6 5 2 2 2 6 7 3 4\n",
            " 4 2 2 2 6 3 4 2 2 2 8 8 8 8 5 4 8 8 4 2 2 8 8 8 8 8 8 8 8 4 8 8 8 8 8 8 8\n",
            " 0 0 8 8 8 5 4 3 8 7 5 4 8 6 5 5 8 6 5 4 8 8 6 5 8 7 6 5 8 8 1 8 7 3 1 0 0\n",
            " 0 2 0 2 2 7 8 1 1 5 4 8 4 3 2 8 8 8 7 8 8 8 8 8 8 8 8 8 8 8 8 9]\n",
            "mass\n",
            "0     6\n",
            "1     6\n",
            "2    30\n",
            "3     9\n",
            "4    22\n",
            "5    23\n",
            "6    23\n",
            "7    14\n",
            "8    82\n",
            "9     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Распределение после ADASYN (только на тренировочных данных):\n",
            "mass\n",
            "0     5\n",
            "1     5\n",
            "2    24\n",
            "3     7\n",
            "4    18\n",
            "5    18\n",
            "6    18\n",
            "7    11\n",
            "8    65\n",
            "9    66\n",
            "Name: count, dtype: int64\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Лучшие параметры: {'tol': 0.001, 'max_iter': 300, 'lambda_2': 1, 'lambda_1': 1, 'alpha_2': 1e-06, 'alpha_1': 0.0001}\n",
            "\n",
            "BayesianRidge (test) результаты:\n",
            "Метрика        Значение       \n",
            "MAE            17.9338\n",
            "MedAE          12.8062\n",
            "R²             0.2194\n",
            "RMSE           24.8738\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHpCAYAAABTH4/7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAv6hJREFUeJzs3Xd4U2X/x/F3utI9KG0ZhVKGUPZGZAuCMhRRcYAMQRzgwsnPCYi4HxwoojIUEGWoPA4UBDdTWYrsWYFSoJPu5vz+yNOU0AIttD1p+3ldVy+b+5ycfBJse+ebe1gMwzAQEREREREREREpQ25mBxARERERERERkcpHRSkRERERERERESlzKkqJiIiIiIiIiEiZU1FKRERERERERETKnIpSIiIiIiIiIiJS5lSUEhERERERERGRMqeilIiIiIiIiIiIlDkVpUREREREREREpMypKCUiIiIiIiIiImVORSkRKTcsFgvPPfec2TFM1717d7p37+64feDAASwWC3PmzDEt09nOzigiIiKuryz/fp/dr3vuueewWCycOHGiTB6/Tp06jBgxokweS0TOTUUpkUrqnXfewWKx0KFDh4u+xpEjR3juuefYvHlzyQVzcT/++CMWi8Xx5enpSd26dRk2bBj79u0zO16x/P777zz33HMkJiaaHUVERMRlzZkzx+lv/9lfa9euNTtioUaMGOGU09/fn7p163LjjTeyZMkSbDZbiTyOK/cnXDmbiNh5mB1ARMwxf/586tSpw/r169mzZw/169cv9jWOHDnCxIkTqVOnDi1btiz5kC7s/vvvp127dmRnZ/Pnn38yc+ZMvv76a7Zt20aNGjXKNEtUVBTp6el4enoW636///47EydOZMSIEQQHB5dOOBERkQpi0qRJREdHF2i/mD5UWbFarXzwwQcApKenc/DgQf773/9y44030r17d7788ksCAwMd53///ffFfoyL7U+kp6fj4VG6b0fPl23nzp24uWmMhojZVJQSqYT279/P77//ztKlS7nrrruYP38+zz77rNmxypUuXbpw4403AjBy5Eguu+wy7r//fubOncuECRMKvc/p06fx8/Mr8SwWiwVvb+8Sv66IiIjku+aaa2jbtm2x7pOTk4PNZsPLy6vAsUvtFxiGQUZGBj4+Puc8x8PDg6FDhzq1Pf/887z44otMmDCBO++8k08//dRxrLCcJclms5GVlYW3t7fpfRer1Wrq44uInUrDIpXQ/PnzCQkJoV+/ftx4443Mnz+/0PMSExN56KGHqFOnDlarlcjISIYNG8aJEyf48ccfadeuHWAvyuQNDc9b1+hc8/TPXqsgKyuLZ555hjZt2hAUFISfnx9dunRh9erVxX5ecXFxeHh4MHHixALHdu7cicVi4e233wYgOzubiRMn0qBBA7y9vQkNDaVz586sWLGi2I8LcOWVVwL2gh/kr4uwfft2brvtNkJCQujcubPj/Hnz5tGmTRt8fHyoUqUKt9xyC4cPHy5w3ZkzZ1KvXj18fHxo3749v/zyS4FzzrWm1I4dOxg8eDBhYWH4+PjQsGFDnnzySUe+Rx99FIDo6GjHv9+BAwdKJaOIiEhFl/f3+NVXX2XatGnUq1cPq9XK9u3bz9svyMnJYfLkyY7z69Spw//93/+RmZnpdP06derQv39/vvvuO9q2bYuPjw/vvffeRWV94okn6N27N4sWLWLXrl2O9sLWlHrrrbdo0qQJvr6+hISE0LZtWxYsWABcuD9hsVgYN24c8+fPp0mTJlitVpYvX+44VthaoSdOnGDw4MEEBgYSGhrKAw88QEZGRoHXubC1NM+85oWyFdZX3bdvHzfddBNVqlTB19eXyy+/nK+//trpnLylHD777DOmTJlCZGQk3t7e9OzZkz179pzzNReRwmmklEglNH/+fAYNGoSXlxe33nor7777Lhs2bHAUmQBSU1Pp0qUL//zzD3fccQetW7fmxIkTLFu2jNjYWGJiYpg0aRLPPPMMY8aMoUuXLgBcccUVxcqSnJzMBx98wK233sqdd95JSkoKH374IX369GH9+vXFmhYYERFBt27d+OyzzwqM/Pr0009xd3fnpptuAuwdlalTpzJ69Gjat29PcnIyGzdu5M8//+Sqq64q1nMA2Lt3LwChoaFO7TfddBMNGjTghRdewDAMAKZMmcLTTz/N4MGDGT16NPHx8bz11lt07dqVTZs2OYaXf/jhh9x1111cccUVPPjgg+zbt49rr72WKlWqUKtWrfPm2bp1K126dMHT05MxY8ZQp04d9u7dy3//+1+mTJnCoEGD2LVrF5988gn/+c9/qFq1KgBhYWFlllFERKQ8SUpKKrAIt8ViKfC3f/bs2WRkZDBmzBisVitVqlRxHCusXzB69Gjmzp3LjTfeyMMPP8y6deuYOnUq//zzD59//rnTtXfu3Mmtt97KXXfdxZ133knDhg0v+vncfvvtfP/996xYsYLLLrus0HPef/997r//fm688UZHcWjr1q2sW7eO22677YL9CYBVq1bx2WefMW7cOKpWrUqdOnXOm2vw4MHUqVOHqVOnsnbtWt58800SEhL46KOPivX8ipLtTHFxcVxxxRWkpaVx//33Exoayty5c7n22mtZvHgx119/vdP5L774Im5ubjzyyCMkJSXx8ssvM2TIENatW1esnCKVniEilcrGjRsNwFixYoVhGIZhs9mMyMhI44EHHnA675lnnjEAY+nSpQWuYbPZDMMwjA0bNhiAMXv27ALnREVFGcOHDy/Q3q1bN6Nbt26O2zk5OUZmZqbTOQkJCUZERIRxxx13OLUDxrPPPnve5/fee+8ZgLFt2zan9saNGxtXXnml43aLFi2Mfv36nfdahVm9erUBGLNmzTLi4+ONI0eOGF9//bVRp04dw2KxGBs2bDAMwzCeffZZAzBuvfVWp/sfOHDAcHd3N6ZMmeLUvm3bNsPDw8PRnpWVZYSHhxstW7Z0en1mzpxpAE6v4f79+wv8O3Tt2tUICAgwDh486PQ4ef92hmEYr7zyigEY+/fvL/WMIiIi5dXs2bMNoNAvq9XqOC/v73FgYKBx/Phxp2ucq1+wefNmAzBGjx7t1P7II48YgLFq1SpHW1RUlAEYy5cvL1Lu4cOHG35+fuc8vmnTJgMwHnroIUfb2f206667zmjSpMl5H+dc/QnDsPfd3NzcjL///rvQY2f26/Jeo2uvvdbpvHvvvdcAjC1bthiGUXi/51zXPF+2s/uqDz74oAEYv/zyi6MtJSXFiI6ONurUqWPk5uYahpHfF4yJiXHq/7zxxhuF9kFF5Pw0fU+kkpk/fz4RERH06NEDsH/Cd/PNN7Nw4UJyc3Md5y1ZsoQWLVoU+FQo7z4lxd3d3bF+gc1m49SpU+Tk5NC2bVv+/PPPYl9v0KBBeHh4OK2P8Ndff7F9+3ZuvvlmR1twcDB///03u3fvvqjcd9xxB2FhYdSoUYN+/fpx+vRp5s6dW2Ctibvvvtvp9tKlS7HZbAwePJgTJ044vqpVq0aDBg0c0xY3btzI8ePHufvuu53WdxgxYgRBQUHnzRYfH8/PP//MHXfcQe3atZ2OFeXfriwyioiIlDfTp09nxYoVTl/ffvttgfNuuOGGc47GObtf8M033wAwfvx4p/aHH34YoMDUsejoaPr06XPRz+FM/v7+AKSkpJzznODgYGJjY9mwYcNFP063bt1o3Lhxkc8fO3as0+377rsPyH+tSss333xD+/btnZZb8Pf3Z8yYMRw4cIDt27c7nT9y5Ein/k/erIHythuziNk0fU+kEsnNzWXhwoX06NHDsfYRQIcOHXjttdf44Ycf6N27N2CfjnbDDTeUSa65c+fy2muvsWPHDrKzsx3the1wcyFVq1alZ8+efPbZZ0yePBmwT93z8PBg0KBBjvMmTZrEddddx2WXXUbTpk25+uqruf3222nevHmRHueZZ56hS5cuuLu7U7VqVWJiYgrdQebs57B7924Mw6BBgwaFXjdvB72DBw8CFDjP09OTunXrnjdbXmeoadOmRXouZyuLjCIiIuVN+/bti7TQ+fn6L2cfO3jwIG5ubgV28KtWrRrBwcGOv7VFuXZxpaamAhAQEHDOcx5//HFWrlxJ+/btqV+/Pr179+a2226jU6dORX6c4mY+u19Rr1493NzcnNa9LA0HDx6kQ4cOBdpjYmIcx8/sW539wV9ISAgACQkJpZhSpOJRUUqkElm1ahVHjx5l4cKFLFy4sMDx+fPnO4pSl+pcI3Jyc3Nxd3d33J43bx4jRoxg4MCBPProo4SHh+Pu7s7UqVMd6zQV1y233MLIkSPZvHkzLVu25LPPPqNnz56OtQQAunbtyt69e/nyyy/5/vvv+eCDD/jPf/7DjBkzGD169AUfo1mzZvTq1euC5529I47NZsNisfDtt986vQ558j61NFN5yCgiIuKqzrcb3rmOFXUU+vmuXVx//fUXQIGC2JliYmLYuXMnX331FcuXL2fJkiW88847PPPMM4VuLFOYS8189mtzvj5mWSqsjwQ41goTkaJRUUqkEpk/fz7h4eFMnz69wLGlS5fy+eefM2PGDHx8fKhXr56js3Iu5+tAhYSEkJiYWKD94MGDTqNoFi9eTN26dVm6dKnT9c5eqLw4Bg4cyF133eWYwrdr1y4mTJhQ4LwqVaowcuRIRo4cSWpqKl27duW5554rUlHqYtWrVw/DMIiOjj7noqIAUVFRgH3UUt7OfmDfNXD//v20aNHinPfNe30v9t+vLDKKiIiI/W+pzWZj9+7djhE5YF90OzEx0fG3tjR8/PHHWCyWC27w4ufnx80338zNN99MVlYWgwYNYsqUKUyYMAFvb+8SXdYB7P2KM0dX7dmzB5vN5lggPW9E0tn9zLNHlUHxlpyIiopi586dBdp37NjhOC4iJU9rSolUEunp6SxdupT+/ftz4403FvgaN24cKSkpLFu2DLCvh7Bly5YCu75A/idAfn5+QMFOAdgLG2vXriUrK8vR9tVXX3H48GGn8/I+ZTrzU6V169axZs2ai36uwcHB9OnTh88++4yFCxfi5eXFwIEDnc45efKk021/f3/q169fYPvlkjZo0CDc3d2ZOHFigU/SDMNw5Grbti1hYWHMmDHD6TWcM2dOoa/3mcLCwujatSuzZs3i0KFDBR4jz7n+/coio4iIiEDfvn0BmDZtmlP766+/DkC/fv1K5XFffPFFvv/+e26++eZzTteHgv0lLy8vGjdujGEYjiUXztcfvBhnf3j61ltvAXDNNdcAEBgYSNWqVfn555+dznvnnXcKXKs42fr27cv69eud+qCnT59m5syZ1KlTp1jrYolI0WmklEglsWzZMlJSUrj22msLPX755ZcTFhbG/Pnzufnmm3n00UdZvHgxN910E3fccQdt2rTh1KlTLFu2jBkzZtCiRQvq1atHcHAwM2bMICAgAD8/Pzp06EB0dDSjR49m8eLFXH311QwePJi9e/cyb9486tWr5/S4/fv3Z+nSpVx//fX069eP/fv3M2PGDBo3buxY6+Bi3HzzzQwdOpR33nmHPn36EBwc7HS8cePGdO/enTZt2lClShU2btzI4sWLGTdu3EU/ZlHUq1eP559/ngkTJnDgwAEGDhxIQEAA+/fv5/PPP2fMmDE88sgjeHp68vzzz3PXXXdx5ZVXcvPNN7N//35mz55dpPWa3nzzTTp37kzr1q0ZM2YM0dHRHDhwgK+//prNmzcD0KZNGwCefPJJbrnlFjw9PRkwYECZZRQRESlPvv32W8eomTNdccUVF/13r0WLFgwfPpyZM2eSmJhIt27dWL9+PXPnzmXgwIGOjWkuVk5ODvPmzQMgIyODgwcPsmzZMrZu3UqPHj2YOXPmee/fu3dvqlWrRqdOnYiIiOCff/7h7bffpl+/fo61qM7Vn8grCBXX/v37ufbaa7n66qtZs2YN8+bN47bbbnMagT169GhefPFFRo8eTdu2bfn555/ZtWtXgWsVJ9sTTzzBJ598wjXXXMP9999PlSpVmDt3Lvv372fJkiW4uWk8h0ipMGXPPxEpcwMGDDC8vb2N06dPn/OcESNGGJ6ensaJEycMwzCMkydPGuPGjTNq1qxpeHl5GZGRkcbw4cMdxw3DML788kujcePGhoeHR4HteV977TWjZs2ahtVqNTp16mRs3LixwFbDNpvNeOGFF4yoqCjDarUarVq1Mr766itj+PDhRlRUlFM+ztrm93ySk5MNHx8fAzDmzZtX4Pjzzz9vtG/f3ggODjZ8fHyMRo0aGVOmTDGysrLOe928bYAXLVp03vPytjWOj48v9PiSJUuMzp07G35+foafn5/RqFEjY+zYscbOnTudznvnnXeM6Ohow2q1Gm3btjV+/vnnAq/hubZG/uuvv4zrr7/eCA4ONry9vY2GDRsaTz/9tNM5kydPNmrWrGm4ubkV2DK5JDOKiIiUV7NnzzaAc37l/f3N+3v8yiuvFLjG+foF2dnZxsSJE43o6GjD09PTqFWrljFhwgQjIyPD6byoqCijX79+Rc49fPhwp5y+vr5GnTp1jBtuuMFYvHixkZubW+A+Z//9fu+994yuXbsaoaGhhtVqNerVq2c8+uijRlJSktP9ztWfAIyxY8cWmu/sfl3ea7R9+3bjxhtvNAICAoyQkBBj3LhxRnp6utN909LSjFGjRhlBQUFGQECAMXjwYOP48eOF9hXPlS0qKsoYPny407l79+41brzxRkffqX379sZXX33ldM65+oLn6o+JyPlZDEMrsYmIiIiIiIiISNnSGEQRERERERERESlzKkqJiIiIiIiIiEiZU1FKRERERERERETKnIpSIiIiIiIiIiJS5lSUEhERERERERGRMqeilIiIiIiIiIiIlDkVpUSkUrNYLDz33HNmx3A4cOAAFouFOXPmXPDcESNGUKdOnVLPJCIiIpWL+kciUlZUlBKRizJnzhwsFovTV3h4OD169ODbb781O55L6d69u9Pr5OPjQ/PmzZk2bRo2m83seCIiIlJC1D8qOvWPRATAw+wAIlK+TZo0iejoaAzDIC4ujjlz5tC3b1/++9//0r9/f7PjXVB6ejoeHqX/qzAyMpKpU6cCcOLECRYsWMBDDz1EfHw8U6ZMcZwXFRVFeno6np6epZ5JRERESof6R0Wj/pGIqCglIpfkmmuuoW3bto7bo0aNIiIigk8++aRcdLq8vb3L5HGCgoIYOnSo4/bdd99No0aNeOutt5g0aRLu7u6Afbh8WWUSERGR0qH+UdGofyQimr4nIiUqODgYHx8fp0/XXn31Va644gpCQ0Px8fGhTZs2LF682Ol+3bp1o0WLFoVes2HDhvTp08dx22azMW3aNJo0aYK3tzcRERHcddddJCQkON1v48aN9OnTh6pVq+Lj40N0dDR33HGH0zlnr5lw8OBB7r33Xho2bIiPjw+hoaHcdNNNHDhwwOl+ecPzf/vtN8aPH09YWBh+fn5cf/31xMfHX/B18vb2pl27dqSkpHD8+HFH+7nWTPjiiy9o2rQp3t7eNG3alM8//7zQ6548eZLbb7+dwMBAgoODGT58OFu2bCn0mjt27ODGG2+kSpUqeHt707ZtW5YtW3bB7CIiIlI86h+pfyQihdNIKRG5JElJSZw4cQLDMDh+/DhvvfUWqampTp96vfHGG1x77bUMGTKErKwsFi5cyE033cRXX31Fv379ALj99tu58847+euvv2jatKnjvhs2bGDXrl089dRTjra77rqLOXPmMHLkSO6//37279/P22+/zaZNm/jtt9/w9PTk+PHj9O7dm7CwMJ544gmCg4M5cOAAS5cuPe/z2bBhA7///ju33HILkZGRHDhwgHfffZfu3buzfft2fH19nc6/7777CAkJ4dlnn+XAgQNMmzaNcePG8emnn17wtcvrYAUHB5/3vO+//54bbriBxo0bM3XqVE6ePMnIkSOJjIx0Os9mszFgwADWr1/PPffcQ6NGjfjyyy8ZPnx4gWv+/fffdOrUiZo1a/LEE0/g5+fHZ599xsCBA1myZAnXX3/9BfOLiIhI4dQ/Uv9IRIrIEBG5CLNnzzaAAl9Wq9WYM2eO07lpaWlOt7OysoymTZsaV155paMtMTHR8Pb2Nh5//HGnc++//37Dz8/PSE1NNQzDMH755RcDMObPn+903vLly53aP//8cwMwNmzYcN7nARjPPvvsObMahmGsWbPGAIyPPvqowPPv1auXYbPZHO0PPfSQ4e7ubiQmJjraunXrZjRq1MiIj4834uPjjR07dhiPPvqoARj9+vVzeqz9+/cbgDF79mxHW8uWLY3q1as7XfP77783ACMqKsrRtmTJEgMwpk2b5mjLzc01rrzyygLX7Nmzp9GsWTMjIyPD0Waz2YwrrrjCaNCgwXlfMxERESmc+kfqH4lI8Wj6nohckunTp7NixQpWrFjBvHnz6NGjB6NHj3b6xM3Hx8fxfUJCAklJSXTp0oU///zT0R4UFMR1113HJ598gmEYAOTm5vLpp58ycOBA/Pz8AFi0aBFBQUFcddVVnDhxwvHVpk0b/P39Wb16NYDj07WvvvqK7OzsIj+fM7NmZ2dz8uRJ6tevT3BwsFPePGPGjMFisThud+nShdzcXA4ePOh03o4dOwgLCyMsLIxGjRrxyiuvcO21115wa+OjR4+yefNmhg8fTlBQkKP9qquuonHjxk7nLl++HE9PT+68805Hm5ubG2PHjnU679SpU6xatYrBgweTkpLieA1PnjxJnz592L17N//+++95c4mIiMi5qX+k/pGIFI2KUiJySdq3b0+vXr3o1asXQ4YM4euvv6Zx48aMGzeOrKwswN7xufzyy/H29qZKlSqEhYXx7rvvkpSU5HStYcOGcejQIX755RcAVq5cSVxcHLfffrvjnN27d5OUlER4eLijE5P3lZqa6lh/oFu3btxwww1MnDiRqlWrct111zF79mwyMzPP+3zS09N55plnqFWrFlarlapVqxIWFkZiYmKBvAC1a9d2uh0SEgJQYP2GOnXqsGLFCr777jveeecdatasSXx8/AUX7czrvDVo0KDAsYYNGxY4t3r16gWG0NevX9/p9p49ezAMg6effrrAa/jss88COK3jICIiIsWj/pH6RyJSNFpTSkRKlJubGz169OCNN95g9+7dnDp1imuvvZauXbvyzjvvUL16dTw9PZk9ezYLFixwum+fPn2IiIhg3rx5dO3alXnz5lGtWjV69erlOMdmsxEeHs78+fMLffywsDDAvkDn4sWLWbt2Lf/973/57rvvuOOOO3jttddYu3Yt/v7+hd7/vvvuY/bs2Tz44IN07NiRoKAgLBYLt9xyCzabrcD5ebvCnC3v08w8fn5+Ts+jU6dOtG7dmv/7v//jzTffLPQapSXveTzyyCNOC6Se6eyOmoiIiFw89Y/s1D8SkbOpKCUiJS4nJweA1NRUlixZgre3N9999x1Wq9VxzuzZswvcz93dndtuu405c+bw0ksv8cUXX3DnnXc6dWzq1avHypUr6dSpk9NQ8nO5/PLLufzyy5kyZQoLFixgyJAhLFy4kNGjRxd6/uLFixk+fDivvfaaoy0jI4PExMSiPv0iad68OUOHDuW9997jkUceKfCJYp6oqCjA/gno2Xbu3Fng3NWrV5OWlub0aeCePXuczqtbty4Anp6eTh1BERERKT3qH12Y+kcilY+m74lIicrOzub777/Hy8uLmJgY3N3dsVgs5ObmOs45cOAAX3zxRaH3v/3220lISOCuu+4qsEsNwODBg8nNzWXy5MkF7puTk+PoHCUkJBT4NK5ly5YA5x2i7u7uXuB+b731llP+kvLYY4+RnZ3N66+/fs5zqlevTsuWLZk7d67T8PgVK1awfft2p3P79OlDdnY277//vqPNZrMxffp0p/PCw8Pp3r077733HkePHi3wmEXZsllERESKTv2jolP/SKRy0UgpEbkk3377LTt27ADs8+wXLFjA7t27eeKJJwgMDKRfv368/vrrXH311dx2220cP36c6dOnU79+fbZu3Vrgeq1ataJp06YsWrSImJgYWrdu7XS8W7du3HXXXUydOpXNmzfTu3dvPD092b17N4sWLeKNN97gxhtvZO7cubzzzjtcf/311KtXj5SUFN5//30CAwPp27fvOZ9P//79+fjjjwkKCqJx48asWbOGlStXEhoaWrIvHNC4cWP69u3LBx98wNNPP33Ox5g6dSr9+vWjc+fO3HHHHZw6dYq33nqLJk2akJqa6jhv4MCBtG/fnocffpg9e/bQqFEjli1bxqlTpwCcFhydPn06nTt3plmzZtx5553UrVuXuLg41qxZQ2xsLFu2bCnx5ysiIlJZqH908dQ/EqlkzNr2T0TKt8K2PPb29jZatmxpvPvuu07bAH/44YdGgwYNDKvVajRq1MiYPXu28eyzzxrn+hX08ssvG4DxwgsvnPPxZ86cabRp08bw8fExAgICjGbNmhmPPfaYceTIEcMwDOPPP/80br31VqN27dqG1Wo1wsPDjf79+xsbN250ug5nbXmckJBgjBw50qhatarh7+9v9OnTx9ixY4cRFRVlDB8+vMDzP3tL5dWrVxuAsXr1akdbt27djCZNmhT6PH788UenDIVteWwY9u2MY2JiDKvVajRu3NhYunSpMXz4cKctjw3DMOLj443bbrvNCAgIMIKCgowRI0YYv/32mwEYCxcudDp37969xrBhw4xq1aoZnp6eRs2aNY3+/fsbixcvPserLiIiIuej/pH6RyJSPBbDOGscpoiIyd544w0eeughDhw4cM61BKTovvjiC66//np+/fVXOnXqZHYcERERuQjqH5Us9Y9EXIOKUiLiUgzDoEWLFoSGhrJ69Wqz45Q76enpTguc5ubm0rt3bzZu3MixY8eKtPipiIiIuBb1jy6N+kcirktrSomISzh9+jTLli1j9erVbNu2jS+//NLsSOXSfffdR3p6Oh07diQzM5OlS5fy+++/88ILL6jDJSIiUs6of1Qy1D8ScV0aKSUiLuHAgQNER0cTHBzMvffey5QpU8yOVC4tWLCA1157jT179pCRkUH9+vW55557GDdunNnRREREpJjUPyoZ6h+JuC4VpUREREREREREpMy5mR1AREREREREREQqH60pBdhsNo4cOUJAQAAWi8XsOCIiIlKOGIZBSkoKNWrUwM2tYnzep76RiIiIXIqi9o9UlAKOHDlCrVq1zI4hIiIi5djhw4eJjIw0O0aJUN9IRERESsKF+kcqSgEBAQGA/cUKDAw0OY2IiIiUJ8nJydSqVcvRn6gI1DcSERGRS1HU/pGKUuAYlh4YGKiOl4iIiFyUijTNTX0jERERKQkX6h9VjIUPRERERERERESkXFFRSkREREREREREypyKUiIiIiIiIiIiUuZUlBIRERERERERkTKnopSIiIiIiIiIiJQ5FaVERERERERERKTMqSglIiIiIiIiIiJlTkUpEREREREREREpcypKiYiIiIiIiIhImVNRSkREREREREREypyKUiIiIiIiIiIiUuY8zA4gIiIiUlpSMrKJTUgnNSMHf28PIkN8CPD2NDuWiIiIiKCilIiIiFRQh06msXRTLHHJmY62iEArg1pFUjvU18Rkpa9OnTocPHiwQPu9997L9OnTTUgkIiIiUpCm74mIiEiFk5KRXaAgBRCXnMnSTbGkZGSblKxsbNiwgaNHjzq+VqxYAcBNN91kcjIRERGRfBopVUlpOoOIiFRksQnpBQpSeeKSM4lNSCemesX9uxcWFuZ0+8UXX6RevXp069at0PMzMzPJzMx/vZKTk0s1n4iIQHx8PElJSRd9/6CgoAK/70XKGxWlKqHKPJ1BREQqh9SMnEs6XpFkZWUxb948xo8fj8ViKfScqVOnMnHixDJOJiJSecXHx1O/fgOSky++KBUYGMSePbtVmJJyTUWpSuZC0xlGdY7WiCkRESn3/L3P38W50PGK5IsvviAxMZERI0ac85wJEyYwfvx4x+3k5GRq1apVBulERCqnpKQkkpOTuPulOYSE1yj2/ROOH2HG4yNISkpSUUrKtcrTIxNA0xlERKRyiAzxISLQWujfvIhAK5EhPiakMseHH37INddcQ40a537TY7VasVqtZZhKREQAQsJrEFYzyuwYIqbRQueVjKYziIhIZRDg7cmgVpGE+nmSmJZFfEoGiWlZhPp5Mqh1ZKUZFXzw4EFWrlzJ6NGjzY4iIiIiUoBGSlUyms4gIiKVSe0qvoQFeJOZnYvV0x0fTzcwzE5VdmbPnk14eDj9+vUzO4qIiIhIAaaOlPr5558ZMGAANWrUwGKx8MUXXzgdNwyDZ555hurVq+Pj40OvXr3YvXu30zmnTp1iyJAhBAYGEhwczKhRo0hNTS3DZ1G+5E1nKExlm84gIiIVV94aipsOJ7HjWAr7T6ax41gKmw4nsXRTLCkZ2WZHLHU2m43Zs2czfPhwPDz0oZOIiIi4HlOLUqdPn6ZFixZMnz690OMvv/wyb775JjNmzGDdunX4+fnRp08fMjIyHOcMGTKEv//+mxUrVvDVV1/x888/M2bMmLJ6CuVO3nSGswtTEYHWSjWdQUREKrairKFY0a1cuZJDhw5xxx13mB1FREREpFCmfmx2zTXXcM011xR6zDAMpk2bxlNPPcV1110HwEcffURERARffPEFt9xyC//88w/Lly9nw4YNtG3bFoC33nqLvn378uqrr55zQc/MzEwyM/M7qsnJySX8zFxb7VBfRnWOJjYhndSMHPy9PYgM8VFBSkREKoy8NRJr7dpK1I7N/HrtsEKPV2S9e/fGMCrRXEUREREpd1x2ofP9+/dz7NgxevXq5WgLCgqiQ4cOrFmzBoA1a9YQHBzsKEgB9OrVCzc3N9atW3fOa0+dOpWgoCDHV2Xc8jjA25OY6oG0i65CTPVAFaRERKRCyVsj0Ss9jas//g/Rf20o9LiIiIiImMdli1LHjh0DICIiwqk9IiLCcezYsWOEh4c7Hffw8KBKlSqOcwozYcIEkpKSHF+HDx8u4fQiIiJiprw1FPe2uJzf+w3h8u8+cxzTGooiIiIirqFSfkxotVqxWgtf7FtERETKKcOAb7+Fa65xrKG4dFMs3w15AMPNAmgNRRERERFX4rJFqWrVqgEQFxdH9erVHe1xcXG0bNnScc7x48ed7peTk8OpU6cc9xcREZFK4MQJuPNO+OILeOstGDdOayiKiIiIuDiXnb4XHR1NtWrV+OGHHxxtycnJrFu3jo4dOwLQsWNHEhMT+eOPPxznrFq1CpvNRocOHco8s4iIiJjgu++gWTN7QQrg0Ufh6FFAayiKiIiIuDJTR0qlpqayZ88ex+39+/ezefNmqlSpQu3atXnwwQd5/vnnadCgAdHR0Tz99NPUqFGDgQMHAhATE8PVV1/NnXfeyYwZM8jOzmbcuHHccsst59x5T0RERCqI9HR4/HH7yKg8oaHwwQdwxihrEREREXFNphalNm7cSI8ePRy3x48fD8Dw4cOZM2cOjz32GKdPn2bMmDEkJibSuXNnli9fjre3t+M+8+fPZ9y4cfTs2RM3NzduuOEG3nzzzTJ/LiIiIlKGNm+GIUNg+/b8tquvhlmzVJASERERKSdMLUp1794dwzDOedxisTBp0iQmTZp0znOqVKnCggULSiOeiIiIuBqbDV57DZ58ErKz7W3e3vDKKzB2LFgs5uYTERERkSJz2YXORURERAp45RV44on82y1bwvz50LixaZFERERE5OK47ELnIiIiIgXccw/UqWMfEfXYY7BunQpSIiIiIuWURkqJiIiI6zIM5yl5gYGwYAFkZkL37qbFEhEREZFLp5FSIiIi4pp++QVat4bDh53bO3ZUQUpERESkAlBRSkRERFxLVpZ9IfPu3e277A0bBrm5ZqcSERERkRKm6XsiIiLiOnbsgKFD4Y8/8ttycyEpCapUMS+XiIiIiJQ4jZQSERER8xkGzJhhn66XV5Dy8ICpU2H1ahWkRERERCogjZQSERERc8XFwahR8PXX+W0NG9oXNG/d2rxcIiIiIlKqNFJKREREzPPdd9CsmXNB6t574c8/VZASERERqeA0UkpERETMk5UF8fH278PDYdYs6NfP3EwiIiIiUiZUlBIRERHzDBgAd90FR47ABx/YC1MiIiIiUimoKCUiIlJOpGRkE5uQTmpGDv7eHkSG+BDg7Wl2rKLLzYXPP4cbbgCLJb/9zTfB09O5TUREREQqPBWlREREyoFDJ9NYuimWuORMR1tEoJVBrSKpHeprYjK7CxbMDhyAYcPgl1/sU/RGjsw/5uVV5nlFRERExHwqSomIiLi4lIzsAgUpgLjkTJZuimVU52hTR0ydt2BWxQfmz4exYyE52X7woYdg0CAICjIpsYiIiIi4Au2+JyIi4uJiE9ILFKTyxCVnEpuQXsaJ8p2vYPb1z3+TPfhmuP32/IJUnTrw1VcqSImIiIiIRkqJiIi4utSMnEs6XprOVTCru209N731JJ4n4/Ibhw2zrx9VhgWpcr8Ol4iIiEgFpqKUiIiIi/P3Pv+f6wsdL0xJFWvOLoi5Z2fRe8FbdP7vR7gZhr0xJARmzIDBg4t9/Uvh6utwiYiIiFR2KkqJiIi4uMgQHyICrYWOSIoItBIZ4lOs65VksebsgthVn7xN12VzHbdPd+6K3yfzITKyWNe9VK6+DpeIiIiIaE0pERERlxfg7cmgVpFEBFqd2iMCrQxqHVms4sqFijUpGdnFypZXMMvz8/V3kBwSRo6HJz+PeRzbd9+XeUEKXHsdLhERERGx00gpERGRcqB2qC+jOkdf8pS7ohRrYqoX/ZoBXu4MahXpKHSlBQTzyfiX8QurQtebehHga73wRUqBK6/DJSIiIiJ2KkqJiIiUEwHensUqGBWmRIs1n38OTz5J7VWrnAtmHaNMX1C8NNbhEhEREZGSpR6ZiIhIJVIixZrUVHjwQfjwQ/vtUaMI+OorYqoHXnrAElLS63CJiIiISMnTmlIiIiKVyNlrQJ2psGJNSkY2/xxNZsP+U/xzNJnTP/8GLVvmF6QArFZId601mkpyHS4RERERKR0aKSUiIlKJ5BVrCt1976xizZm79Lnl5tB9yQc0XPQe2HLtJ/j7w5tvwogRYLGU8TO5sJJah0tERERESoeKUiIiIpVMUYo1Z+7SV+XYYQa/+X9E7dziOJ7bvgPuC+ZDvXpmPIUiK4l1uERERESkdKgoJSIiUgldqFiTt0tfi1++5voZk7FmpAGQ6+bO6pvGUPOV54mpVaWs4oqIiIhIBaSilIiIiBSQtwufYXFzFKROVqvFpw+8wOHLWjCoGJv0iYiIiIgURkUpERERKSBvF76tna+h0R+/kOPpyVcjHyPLx8/puIiIiIjIxVKPUkREROwyMmDJEhgyxLFLX1xyJovHTcLmnt9lKGyXPhERERGR4nIzO4CIiIi4gK1boW1bGDoUPv3UsUtfRKC1QEHq7F36ykJKRjb/HE1mw/5T/HM0mZSM7DJ9fBEREREpeRopJSIiUpnZbDBtGkyYAFlZ9rYHH4TrrivSLn1l4dDJNMdOgHkiAq0MahVJ7VDfMs0iIiIiIiVHRSkREZHKKjYWhg+HVavy25o3hwULwNsbuPAufaUtJSO7QEEKIC45k6WbYhnVObrMi2QiIiIiUjI0fU9ERKQyWrTIXoDKK0hZLPDII7B+PTRpYm62M8QmpBcoSOWJS84kNiG9jBOJiIiISElRUUpERKQySU62j44aPBgSEuxtkZGwciW88gpYrebmO0tqRs4lHa/M/v33X4YOHUpoaCg+Pj40a9aMjRs3mh1LRERExEHT90RERCqThx+Gjz7Kvz14MMyYASEh5mU6D3/v83dVLnS8skpISKBTp0706NGDb7/9lrCwMHbv3k2Ii/47i4iISOWknpyIiEhlMnkyfPEFZGbC9On23fYsFrNTnVNkiA8RgdZCp/BFBFqJDPExIZXre+mll6hVqxazZ892tEVHR5uYSERERKQgTd8TERGpyHLOmt5WrRosXgxbt8Ltt7t0QQrsC60PahVJRKDztMKIQCuDWkdqkfNzWLZsGW3btuWmm24iPDycVq1a8f7775/z/MzMTJKTk52+REREREqbilIiIiIVkWHAzJnQuDGcPOl8rFs3qFPHlFgXo3aoL6M6RzOsYxSDWtVkWMcoRnWOpnYVX7Ojuax9+/bx7rvv0qBBA7777jvuuece7r//fubOnVvo+VOnTiUoKMjxVatWrTJOLCIiIpWRpu+JiIhUNMePw+jR8N//2m/fdZd9tz0XHxV1PgHensRU16ioorLZbLRt25YXXngBgFatWvHXX38xY8YMhg8fXuD8CRMmMH78eMft5ORkFaZERESk1KkoJSIiUpF88w2MHGkvTOUJC7NP4/Msv0WdlIxsYhPSSc3Iwd/bg8gQH03dO4/q1avTuHFjp7aYmBiWLFlS6PlWqxWri+28KCIiIhWfilIiLkxvwkSkyNLS4NFH4Z138tvCwmDWLOjf37xcJeDQyTSWbop1Wuw8ItDKoFaR1A7VFL7CdOrUiZ07dzq17dq1i6ioKJMSiYiIiBSkopSIi9KbMBEpsj//hCFDYMeO/LZ+/eDDDyEiwrxcJSAlI7vA70KAuORMlm6KZVTnaBXrC/HQQw9xxRVX8MILLzB48GDWr1/PzJkzmTlzptnRRERERBy00LmIC7rQm7CUjGyTkomIy3nzTbj88vyClI8PvPuufT2pcl6QAohNSC/wuzBPXHImsQnpZZyofGjXrh2ff/45n3zyCU2bNmXy5MlMmzaNIUOGmB1NRERExEEjpURcUFHehGnBXxEBwN8fsv9XqG7dGubPh0aNzM1UglIzci7peGXWv39/+pfzqZsiIiJSsakoJeKC9CZMRIps5EhYvhzq14fnngMvL7MTlSh/7/N3VS50XERERERcl3pyIi5Ib8JEpFCJifD55/ZCVB6LBRYuBLeKOSM/MsSHiEBroaNHIwKtRIb4mJBKREREREpCxezBipRzeW/CCqM3YSKV1E8/QfPmcMcd9vWizlRBC1IAAd6eDGoVWeB3YkSglUGtI7XIuYiIiEg5puEWIi4o701Yobvv6U2YSOWSlQXPPAMvvwyGYW975BHo2xfc3c3NVkZqh/oyqnM0sQnppGbk4O/tQWSIj34XioiIiJRzKkqJuCi9CRMR/vkHbrsNNm/Ob+veHT76qNIUpPIEeHtqgwcRERGRCkZFKREXpjdhIpWUYcA779hHRGVk2Ns8PWHKFHj44Qo9XU9EREREKg8VpURERFzJsWP2daO+/Ta/LSYGFiyAli1Ni1VUKRnZGuEpIiIiIkWiopSIiIgrGTfOuSB1333w0kvg4/obHBw6mVb4WnitIqkd6mtiMhERERFxRRr/LyIi4kpefx2CgqBaNfjmG3jzzXJRkErJyC5QkAKIS85k6aZYUjKyTUomIiIiIq5KI6VERETMlJkJVmv+7dq1Ydky+5S9sDDzchVTbEJ6gYJUnrjkTGIT0rVGnoiIiIg40UgpERERM+TkwOTJ0KwZJCU5H+vatVwVpAAys3NpVC2A6FBfYqoHULeqL+5uFsfx1IwcE9OJiIiIiCvSSCkREZGytm8f3H47/P67/fb998PcueZmugSHTqaxbMsRftp1wtEWFepLz0bh/HMshVybgb936Xc5tMi6iIiISPmiopSIiEhZMQz46CP74uUpKfY2NzeIigKbzf59OZO3llRyRg4+Xm6kZ9kAOHgyjR92HKdj3SqczsolMqR018XSIusiIiIi5Y9L935zc3N5+umniY6OxsfHh3r16jF58mQMw3CcYxgGzzzzDNWrV8fHx4devXqxe/duE1OLiIgU4uRJGDwYRozIL0hFR8Mvv8CkSeWyIAX5a0l5ursRHeqPj1f+8zh4Mo0gXy8GtY4s1RFL51tkfcG6g2w8eIrl246yZu8JjidnlFoOERERESkelx4p9dJLL/Huu+8yd+5cmjRpwsaNGxk5ciRBQUHcf//9ALz88su8+eabzJ07l+joaJ5++mn69OnD9u3b8fb2NvkZiIiIACtXwvDhcORIftvIkTBtGgQGmharJJy5VpS/tweNqgVyOjOH7Fwbnu5uRAb7ULtK6Y5UOtci6wmns/h1dzwe7m58+9cxAC6L8Gdcj/o0qRlUqplERERE5MJc+mPZ33//neuuu45+/fpRp04dbrzxRnr37s369esB+yipadOm8dRTT3HdddfRvHlzPvroI44cOcIXX3xxzutmZmaSnJzs9CUiIlIqnnwSrroqvyAVEgKLFsGsWeW+IAUUWCvK092NYF8vwgK8Cfb1IsTPq9QzFLaIekZWDn8fSSIpPZusXJujfVdcKm+v3qMRUyIiIiIuwKWLUldccQU//PADu3btAmDLli38+uuvXHPNNQDs37+fY8eO0atXL8d9goKC6NChA2vWrDnndadOnUpQUJDjq1atWqX7REREpPKqXj3/+169YNs2uPFG8/KUsMgQHyICrYUeiwi0lvpaUlCwMAaQlJFDUno2AF7uzt2dXXGp7IlPLfVcIiIiInJ+Lj1974knniA5OZlGjRrh7u5Obm4uU6ZMYciQIQAcO2Yfih8REeF0v4iICMexwkyYMIHx48c7bicnJ6swJSLigirEbmpjx8IPP0C3bvZd9srp2lHnEuDtyaBWkYUvMl7Ka0nlySuMnfn42Tn20VHRVf2ITyk4tS85LbvUc4mIiIjI+bl0Ueqzzz5j/vz5LFiwgCZNmrB582YefPBBatSowfDhwy/6ularFau18E91RUTENZTL3dT+/Re+/RZGj85vs1hg6VL7fyuo2qG+jOocbVoBsbDCmKeHG9FV/eh6WRgrtscVuE+gbzkrboqIiIhUQC5dlHr00Ud54oknuOWWWwBo1qwZBw8eZOrUqQwfPpxq1aoBEBcXR/UzpkfExcXRsmVLMyKLiEgJON9uaks3xTKqc7TrjZhasgTGjIFTp+y76vXsmX+sAhek8gR4exJT3bx/k7MLY+5uFn7bfYKjKen0iokgK9eG1cON48mZpGXlUD/M37SsIiIiImLn0kWptLQ03M6a5uDu7o7N9r8h+dHRVKtWjR9++MFRhEpOTmbdunXcc889ZR1XRERKyLl2UwN7YSo2Id3UAoiTlBT7tLw5c/Lb/u//YO3aSlGMciVnF8YswGsrdvLVlqOOtuaRQTzcuyHhgdqhV0RERMRsLl2UGjBgAFOmTKF27do0adKETZs28frrr3PHHXcAYLFYePDBB3n++edp0KAB0dHRPP3009SoUYOBAweaG15ERC5aYbupFed4mfn9d7j9dti3L7/txhvhvfdUkDJZSkY2P+2OJ8zfSts6VcjOseHp4UaQtwc/7Yqnfri/6422ExEREalkXLoo9dZbb/H0009z7733cvz4cWrUqMFdd93FM8884zjnscce4/Tp04wZM4bExEQ6d+7M8uXL8fbWJ6AiIuVVYbupFed4qcvOhueft3/9b/Qu/v7w9tswbJgKUi4gb7Sdt5cH3l7O/7+43Gg7ERERkUrKpYtSAQEBTJs2jWnTpp3zHIvFwqRJk5g0aVLZBRMRkVJV2G5qeSICrUSG+JiQ6n9274ahQ2H9+vy2K66Ajz+GunXNyyVOys1oOxEREZFKrGLtSy0iIhVC3m5qEYHOO6VGBFoZ1DrS3GlX996bX5Byd4fJk+Gnn1SQcjEuP9pORERERFx7pJSIiFReZ++m5u/tQWSIj/nrAL37LrRsCTVqwLx50L69uXmkUC492k5EREREABWlRETEhZ29m5opTp8GP7/82/Xrw7ffQuvWzu3iUvJG263dd4L0bBuZ2bl4e7nj7eHG5fWqml/cFBEREREVpURERAqVng5PPAHffw8bNzoXoLp0MS+XFMuhU2nsjT9Ndq4NT3c36oX5cblmWoqIiIi4BK0pJSIicrbNm6FtW3jzTdixAx591OxEUkwpGdks3RTLydPZBPt6ERbgTbCvFydP29tTMrLNjigiIiJS6akoJSIiksdmg1desa8TtX27vc3bG5o0MTeXFFtsQjpxyZlk59pITMsiPiWDxLQssnNtxCVnEpuQbnZEERERkUpP0/dEREQADh+GYcPgxx/z21q2hPnzoXFjs1LJRUrNyCE1I4f9J1NJz7I52n283IgO9Sc1I8fEdCIiIiICGiklIiKVXEpGNv++O4ucps3yC1IWCzz2GKxbp4JUOeXl4VagIAWQnmVj/8lUvDzUBRIRERExm0ZKiYhIuZaSkU1sQjqpGTn4e3sQGeJT5J3VDp04TcrQYTT5bqmjLTmsOunvzyLiuqtLK7KUAauHG+EB3hw8mVbgWHiAN1YVpURERERMp6KUiIiUW4dOprF0UyxxyZmOtohAK4NaRVI71Pe8903JyGbp5n9pGF6bvBWjtnS6mi/GPEWQXxijMrIdxa1LKXyJOVIzcujZKJwfdhx3KkxFhfrSMyZc0/dEREREXICKUiIiUi7l7a52ZkEKIC45k6WbYhnVOfq8haO8hbCPDxhO7R1b+OuK3mzu2g+AjP8thB1T3fOSCl9iHj9vD/45lkLHulXodlkYmdm5WD3dycrJ5Z+jKbSuHWJ2RBEREZFKT0UpEREpl/KKSoWJO6Oo5GTHDvjlF7jzTsdIGcPdnXlPvFHgGqkZOZdc+BLzRIb4UNXfi30nCk7fiwi0EhniY0IqERERETmTFlQQEZFy6ULTr5yOGwa8+y60bg133w2//Ya/9/k/l/H39ihS4UtcU4C3J4NaRRIRaHVqjwi0Mqh1pIqJIiIiIi5AI6VERKRcKkpRCYC4OBg1Cr7+Ov/glClELv2SiEBroUWnvJE0O46mnPcxtC6Ra6sd6suoztFaD0xERETERWmklIiIlEuRIT4FRsHkcUzP+u9/oVkz54LUvffC4sVFGklT5MKXuKwAb09iqgfSLroKMdUDVZASERERcSHqTYuISLmUV1QqbBHyGxqGEPDgffDee/l3CA+H2bOhb19H04VG0uQVvs43mkpERERERC6OilIiUqpSMrI1dUZKTWFFpdr7tuPXawDs2pV/4oAB8MEH9sLUWewjaQr/f/J8hS+tSyQiIiIicmlUlBKRUnPoZFrhb+ZbRVI71NfEZFKROBWVDAOuuz+/IOXjA//5D4wZAxbLRV1f6xJJefTcc88xceJEp7aGDRuyY8cOkxKJiIiIFKSilIiUipSM7AIFKbDvWLZ0UyyjOkfrTb2UPIvFPkWvbVto2hTmzYOGDS/5sucbTSXiqpo0acLKlSsdtz081O0TERER16LeiYiUitiE9ELX4QF7YSo2IV1v8uXSGQYkJUFwcH5bkyawapW9MOWp/8cqu8o8hdjDw4Nq1aqZHUNERETknFSUEpFSkZqRc0nHRS4oIQHuvht27ID168F6xi56HTual0tcRmWfQrx7925q1KiBt7c3HTt2ZOrUqdSuXbvQczMzM8nMzH+dkpOTyyqmiIiUU/Hx8SQlJV30/YOCgggLCyvBRFIeqSglIqXC3/v8v14udFzkvFatguHDITbWfvvJJ+HVV83NJC6lsk8h7tChA3PmzKFhw4YcPXqUiRMn0qVLF/766y8CAgIKnD916tQCa1CJiIicS3x8PPXrNyA5+eKLUoGBQezZs1uFqUpO7wpFpFREhvgQEWgtdApfRKCVyBAfE1JJuZeZaS9AvfZafltICLRvb14mcUmVfQrxNddc4/i+efPmdOjQgaioKD777DNGjRpV4PwJEyYwfvx4x+3k5GRq1apVJllFRKT8SUpKIjk5ibtfmkNIeI1i3z/h+BFmPD6CpKQkFaUqORWlRKRUBHh7MqhVZOFTZ1pHVugRClJK/voLhgyBrVvz2668EubOhchI83KJS9IUYmfBwcFcdtll7Nmzp9DjVqsV65lTYEVERIogJLwGYTWjzI4h5ZiKUiJSamqH+jKqc3SlXWRYSojNBm+9BY8/bh8pBeDlBS+8AA89BG5u5uYTl6QpxM5SU1PZu3cvt99+u9lRRERERBwqV49MRMpcgLdnhZ4iI6XMZoMBA+Cbb/LbmjSB+fOhRQvzconLq+xTiB955BEGDBhAVFQUR44c4dlnn8Xd3Z1bb73V7GgiIiIiDvp4WUREXJebG7Rtm3/7gQdg40YVpOSC8qYQRwQ6T0mrLFOIY2NjufXWW2nYsCGDBw8mNDSUtWvXat0OERERcSkaKSUiIq7tqafs60jdcw/07m12GilHKvMU4oULF5odQUREROSCVJQSERHXsXatfUHz0aPz2zw94fPPzcsk5ZqmEIuIiIi4LhWlRETEfDk5MGUKTJ4MFgu0bm3/ErlEKRnZlXKklIiIiEh5oKKUiIiYa+9eGDrUPkoqz7Rp8NFHpkWSiuHQyTSWbop1Wuw8ItDKoFaR1A71NTGZiIiIiIAWOheRUpaSkc0/R5PZsP8U/xxNJiUj2+xI4ioMA2bPhpYt8wtS7u4wcSLMmmVqNCn/UjKyCxSkAOKSM1m6KVa/i0RERERcgEZKiUip0SgF813K1KVSnfZ08iSMGQNLl+a31asH8+bB5ZeXzGNIpRabkF6gIJUnLjmT2IR0rTUlIiIiYjIVpUSkVFxolMKoztFa16WUXUpRsFQLit9/DyNGwNGj+W2jRtmn7Pn7X9q1Rf4nNSPnko6LiIiISOm75Ol7ycnJfPHFF/zzzz8lkUdEKoiijFKQ0nMpU5dKddpTTg48+GB+QSo01D5a6oMPVJCSEuXvff7P3S50XERERERKX7GLUoMHD+btt98GID09nbZt2zJ48GCaN2/OkiVLSjygiJRPGqVgrkspCpZqQdHDAz7+2P7fPn1g2za4/vqLv57IOUSG+BARaC30WESglcgQnzJOJCIiIiJnK3ZR6ueff6ZLly4AfP755xiGQWJiIm+++SbPP/98iQcUkfJJoxTMdSlFwRItKNps9vWjztSmjX1h82++gerVi36tckqL/ZsjwNuTQa0iCxSmIgKtDGodqenDIiIiIi6g2O8Kk5KSqFKlCgDLly/nhhtuwNfXl379+vHoo4+WeEARKZ/yRikUNuJGoxRK36UUBUusoBgbC8OHQ2oq/PoreJ5RBGjTpmjXKOe02L+5aof6MqpzdOkt2C8iIiIil6TYI6Vq1arFmjVrOH36NMuXL6d3794AJCQk4O3tXeIBRaR80igFc13K1KUSmfa0aBE0bw6rVsH69TB5cpFyVySlujaXFFmAtycx1QNpF12FmOqB+t0jIiIi4kKKPVLqwQcfZMiQIfj7+1O7dm26d+8O2Kf1NWvWrKTziUg5plEK5skrChY6SucCRcFLuS/JyXDfffDRR/ltkZHQo8clPZ/yqChrc8VU18+CiIiIiFRexS5K3XvvvbRv357Dhw9z1VVX4eZmH2xVt25drSklIgXYRynojbcZLqUoeFH3/fVXuP12OHAgv+3mm+HddyEk5NKfUDmjxf5FRERERM7volYabtu2Lc2bN2f//v3Uq1cPDw8P+vXrV9LZRETkEl1KUbDI983OhokTYepU+8LmAIGBMH06DBkCFstFPX55p8X+RURERETOr9hrSqWlpTFq1Ch8fX1p0qQJhw4dAuC+++7jxRdfLPGAIiLiwrKyoHNnmDIlvyDVuTNs2QJDh1baghSU0NpcIiIiIiIVWLGLUhMmTGDLli38+OOPTgub9+rVi08//bREw4mIiIvz8oIuXezfe3jYi1M//gh16piZyiVosX8RERERkfMr9tyBL774gk8//ZTLL78cyxmfgDdp0oS9e/eWaDgRETm3lIxs11hEfsoUOHgQHn8c2rYt+8cvY8V53bXYv4iIiIjIuRW7KBUfH094eHiB9tOnTzsVqUREpPQcOplW+O54rSKpHepbeg/8zTdw7BjccUd+m9UKixaV3mO6kIt53bXYv4iIiIhI4Yo9fa9t27Z8/fXXjtt5hagPPviAjh07llwyEREpVEpGdoHCCEBcciZLN8WSkpFd8g+algb33gv9+tn/+/ffJf8YhUjJyOafo8ls2H+Kf44ml8pzK+pjmPK6i4iIiIhUYMUeKfXCCy9wzTXXsH37dnJycnjjjTfYvn07v//+Oz/99FNpZBQRkTPEJqQXKIzkiUvOJDYhvWRH5vz5p30XvR077LczM2HWLHjttZJ7jEKUxWiw4jxGmb/uIiIiIiIVXLFHSnXu3JnNmzeTk5NDs2bN+P777wkPD2fNmjW0adOmNDKKiMgZUjNyLul4keXmwosvQocO+QUpHx9491149dWSeYxzKItRScV9jDJ73UVEREREKolij5QCqFevHu+//35JZxERkSLw9z7/r+4LHS+Sgwdh2DD4+ef8ttatYf58aNTo0q9/AWUxKqm4j1Emr7uIiIiISCVS7B70oUOHznu8du3aFx1GREQuLDLEh4hAa6EFlYhAK5EhPpf2APPn29eNSk6237ZY4Ikn4LnnwMvr0q5dRGUxKqm4j1Hqr7uIiIiISCVT7KJUnTp1zrvLXm5u7iUFEhGR8wvw9mRQq8jC10JqHUmA9yWMIEpPh6efzi9IRUXBxx9Dly6XmLp4ymJUUnEfo1RfdxERERGRSqjYvfpNmzY53c7OzmbTpk28/vrrTJkypcSCiYjIudUO9WVU52hiE9JJzcjB39uDyBCfSy+M+PjYi1Bdu8Jtt8Hbb0NQUMmELoayGJV0MY9Raq+7iIiIiEglVOyiVIsWLQq0tW3blho1avDKK68waNCgEgkmIiLnF+Dteem7vWVm2kdFhYXlt3XqBFu2QNOml3btS1AWo5Iu9jFK5HUXEREREZGLW+i8MA0bNmTDhg0ldTkRESlt27fDkCH2kVA//ADu7vnHTCxI5SmLUUka+SQiIiIiYp5iF6WS89YZ+R/DMDh69CjPPfccDRo0KLFgIiJSSgwDpk+HRx+FjAx726uvwuOPm5urEGUxKkkjn0REREREzFHsolRwcHCBhc4Nw6BWrVosXLiwxIKJiEgpOHYMRo6E5cvz22JioE8f8zKJiIiIiEil5FbcO6xevZpVq1Y5vn788Ue2b9/O3r176dixY4kH/Pfffxk6dCihoaH4+PjQrFkzNm7c6DhuGAbPPPMM1atXx8fHh169erF79+4SzyEiUu59+SU0a+ZckLrvPvjjD2jZ0rRYIiIiIiJSORV7pFS3bt1KI0ehEhIS6NSpEz169ODbb78lLCyM3bt3ExIS4jjn5Zdf5s0332Tu3LlER0fz9NNP06dPH7Zv3463t3eZZRUROVNKRrbrrFN0+jQ89BC8/35+W7VqMHs2XH21OZlEyohL/SyKiIiIiJMiFaWWLVtW5Atee+21Fx3mbC+99BK1atVi9uzZjrbo6GjH94ZhMG3aNJ566imuu+46AD766CMiIiL44osvuOWWWwq9bmZmJpmZ+Tstnb1OlojIpTh0Mq3wHd1aRVI71Ldsw6SkQJs2cOYI0oEDYeZM5x33RCogl/pZFBEREZECilSUGjhwYJEuZrFYyM3NvZQ8TpYtW0afPn246aab+Omnn6hZsyb33nsvd955JwD79+/n2LFj9OrVy3GfoKAgOnTowJo1a85ZlJo6dSoTJ04ssZwiInlSMrILvAkGiEvOZOmmWEZ1ji7bURoBAdCrl70o5ecHb7wBd9wBZ60NKFLRuNzPooiIiIgUUKQ1pWw2W5G+SrIgBbBv3z7effddGjRowHfffcc999zD/fffz9y5cwE4duwYABEREU73i4iIcBwrzIQJE0hKSnJ8HT58uERzi0jlFZuQXuBNcJ645ExiE9LLOBH2nfWGDIFNm2DUKBWkpFhSMrL552gyG/af4p+jyaRkZJsdqUhc8mdRRERERJwUe02psmSz2Wjbti0vvPACAK1ateKvv/5ixowZDB8+/KKva7VasVqtJRVTRMQhNSPnko5fEsOAjz6yF52GDctv9/WFefNK73GlwirP099M/VkUERERkSK5qKLU6dOn+emnnzh06BBZWVlOx+6///4SCQZQvXp1Gjdu7NQWExPDkiVLAKhWrRoAcXFxVK9e3XFOXFwcLbWTlIiYwN/7/L9WL3T8op08CXffDYsX26fpXXEF1K9fOo8llUJ5n/5m2s+iiIiIiBRZsXtkmzZtom/fvqSlpXH69GmqVKnCiRMn8PX1JTw8vESLUp06dWLnzp1Obbt27SIqKgqwL3perVo1fvjhB0cRKjk5mXXr1nHPPfeUWA4RkaKKDPEhItBa6LShiEArkSE+Jf+gK1fC8OFw5Ij99unTsGQJPP54yT+WVBpFmf4WU911i1Km/CyKiIiISLEUaU2pMz300EMMGDCAhIQEfHx8WLt2LQcPHqRNmza8+uqrJRruoYceYu3atbzwwgvs2bOHBQsWMHPmTMaOHQvYF1Z/8MEHef7551m2bBnbtm1j2LBh1KhRo8iLs4uIlKQAb08GtYokItB5inBEoJVBrSNLdmRJRgaMHw9XXZVfkKpSBRYtUkFKLll5n/5Wpj+LIiIiInJRij1SavPmzbz33nu4ubnh7u5OZmYmdevW5eWXX2b48OEMGjSoxMK1a9eOzz//nAkTJjBp0iSio6OZNm0aQ4YMcZzz2GOPcfr0acaMGUNiYiKdO3dm+fLleHt7l1gOEZHiqB3qy6jO0cQmpJOakYO/tweRIT4l+yZ42zb74uXbtuW39eoFc+ZAzZol9zhSaVWE6W9l8rMoIiIiIhet2D1KT09P3NzsA6zCw8M5dOgQMTExBAUFlcoudv3796d///7nPG6xWJg0aRKTJk0q8ccWEblYAd6epTO1yWaDN96AJ56AvDX9rFZ48UW4/35wK/YAWJFCVZTpb6X2sygiIiIil6zYRalWrVqxYcMGGjRoQLdu3XjmmWc4ceIEH3/8MU2bNi2NjCIikic5GV57Lb8g1awZzJ9v/6+4pJSM7HI5Uidv+luhu+9p+puIiIiIlIAif6Sem5sLwAsvvODY6W7KlCmEhIRwzz33EB8fz8yZM0snpYiI2AUHw9y59hFR48fD+vUqSLmwQyfT+PDX/Xy05iBLN/3LR2sO8uGv+zl0Ms3saEWSN/1tWMcoBrWqybCOUYzqHE3tKr5mR5NievHFFx1rcYqIiIi4iiKPlKpZsyYjRozgjjvuoG3btoB9+t7y5ctLLZyISKWXnAyZmRAWlt/Wsyfs3An165uXSy4oJSO7wCgjsO9ct3RTLKM6R5eL0Uaa/lb+bdiwgffee4/mzZubHUVERETESZFHSo0dO5bFixcTExNDly5dmDNnDmlp5eOTXhGRcun336FlS7j9djAM52MqSLm82IT0QtdjAnthKjYhvYwTSWWUmprKkCFDeP/99wkJCTE7joiIiIiTIo+Uevrpp3n66af58ccfmT17NuPGjeOBBx5g8ODBjB49mg4dOpRmThGRyiM7GyZPhilT7Aub798P77wDY8eanUyKITUj55KOi5SEsWPH0q9fP3r16sXzzz9/zvMyMzPJzMwvoiYnJ5dFPBERMVF8fDxJSUkXdd+DBw+WcJriu5T8eYKCggg7c0aClLliL3TevXt3unfvzvTp01m4cCFz5syhY8eOxMTEMGrUKMaPH18aOUVEKofdu2HoUPtaUXmuuAL69jUvk1wUf+/z/4m90HGpnOrWrcuGDRsIDQ11ak9MTKR169bs27evyNdauHAhf/75Jxs2bLjguVOnTmXixInFzisiIuVTfHw89es3IDn50oo6GRnmzJ4qqfyBgUHs2bNbhSkTXXSP2N/fn9GjRzN69Gi+/vprhg0bxqOPPqqilIjIxTAM+OADePBByJsa7e4Ozz0HTzwBHipglDeRIT5EBFoLncIXEWglMsTHhFTi6g4cOODYXOZMmZmZ/Pvvv0W+zuHDh3nggQdYsWIF3t7eFzx/woQJTn245ORkatWqVeTHExGR8iUpKYnk5CTufmkOIeE1in3/A9s38ckrj5OZmVUK6S7sUvMDJBw/wozHR5CUlKSilIku+l1OWloan332GbNnz+bXX3+lXr16PProoyWZTUSkcoiPhzvvhC+/zG9r0ADmzYP27c3LJZckwNuTQa0iCyx2HhFoZVDryHKxyLmUnWXLljm+/+677wgKCnLczs3N5YcffqBOnTpFvt4ff/zB8ePHad26tdN1fv75Z95++20yMzNxd3d3HLNarVit1kt7EiIiUu6EhNcgrGZUse93Kq7oH5SUpovNL66j2EWp33//nVmzZrFo0SJycnK48cYbmTx5Ml27di2NfCIiFdvx49CiBRw7lt82Zgy8/jr4+ZmXS0pE7VBfRnWOJjYhndSMHPy9PYgM8VFBSgoYOHAgABaLheHDhzsd8/T0pE6dOrz22mtFvl7Pnj3Ztm2bU9vIkSNp1KgRjz/+uFNBSkRERMQsRS5Kvfzyy8yePZtdu3bRtm1bXnnlFW699VYCAgJKM5+ISMUWHg69e8NHH0HVqvDhh3DttWankhIU4O1JTHUVoeT8bDYbANHR0WzYsIGqVate0vUCAgJo2rSpU5ufnx+hoaEF2kVERETMUuSi1CuvvMLQoUNZtGiROjMiIiXprbfAy8u+4161amanERET7d+/3+wIIiIiImWmyEWpI0eO4OmpT3pFRC5abq59Wl7t2nDzzfntgYHw/vvm5RIRl/LDDz/www8/cPz4cccIqjyzZs266Ov++OOPl5hMREREpGQVuSilgpSIyCU4dAiGD4cff4SgIOjY0V6cEhE5w8SJE5k0aRJt27alevXqWCwWsyOJiIiIlBrtMS4iUtoWLoS774akJPvt5GRYsQJGjTI3l4i4nBkzZjBnzhxuv/12s6OIiIiIlDoVpURESktiIowbB/Pn57fVqgUffwzdupkWS0RcV1ZWFldccYXZMURERETKhJvZAUREKqSffoIWLZwLUrfeClu3qiAlIuc0evRoFixYYHYMERERkTJRpJFSycnJRb5gYGDgRYcRESn3srLg2WfhpZfAMOxtgYHw7rtw223mZhMRl5eRkcHMmTNZuXIlzZs3L7Cm5+uvv25SMhEREZGSV6SiVHBwcJEX2szNzb2kQCIi5VpiInz4YX5BqmtX+OgjiIoyNZaIlA9bt26lZcuWAPz1119Ox7TouYiIiFQ0RSpKrV692vH9gQMHeOKJJxgxYgQdO3YEYM2aNcydO5epU6eWTkoRkfIiPNxelLrhBpg8GR55BNzdzU4lIuXEmX0uERERkYquSEWpbmesfzJp0iRef/11br31VkfbtddeS7NmzZg5cybDhw8v+ZQiIq4qLg48PCA0NL9twADYu9e+qLmIiIiIiIgUqti7761Zs4YZM2YUaG/bti2jR48ukVAiIuXCf/8Lo0ZBly6weDGcObVGBSkRuQg9evQ47zS9VatWlWEaERERkdJV7N33atWqxfvvv1+g/YMPPqCW3oSJSGVw+jTcfTdcey3Ex8PSpfDxx2anEpEKoGXLlrRo0cLx1bhxY7Kysvjzzz9p1qyZ2fFERERESlSxR0r95z//4YYbbuDbb7+lQ4cOAKxfv57du3ezZMmSEg8oIuJSNm6EIUNg1678tgED4OqrzcskIhXGf/7zn0Lbn3vuOVJTU8s4jYiIiEjpKvZIqb59+7Jr1y4GDBjAqVOnOHXqFAMGDGDXrl307du3NDKKXLSUjGz+OZrMhv2n+OdoMikZ2WZHkvIqNxemTIGOHfMLUr6+8N578OWX9gXORURKydChQ5k1a5bZMURERERKVLFHSoF9Ct8LL7xQ0llEStShk2ks3RRLXHKmoy0i0MqgVpHUDvU1MZmUO/v3w+23w2+/5be1awfz5sFll5mXS0QqjTVr1uDt7W12DBEREZESdVFFqV9++YX33nuPffv2sWjRImrWrMnHH39MdHQ0nTt3LumMIsWWkpFdoCAFEJecydJNsYzqHE2At6dJ6aRc2b8fWrSAlBT7bTc3+L//g2eeAU/9PyQiJWvQoEFOtw3D4OjRo2zcuJGnn37apFQiIiIipaPY0/eWLFlCnz598PHx4c8//yQz0/6mPykpSaOnxGXEJqQXKEjliUvOJDYhvYwTSblVpw706ZP//c8/w+TJKkiJSKkICgpy+qpSpQrdu3fnm2++4dlnnzU7noiIiEiJKvZIqeeff54ZM2YwbNgwFi5c6Gjv1KkTzz//fImGE7lYqRk5l3RcxMFigRkzoGZNmDQJAgPNTiQiFdjs2bPNjiAiIiJSZopdlNq5cyddu3Yt0B4UFERiYmJJZBK5ZP7e5/9f+0LHpZLKzISnnoLOneG66/LbQ0Nh2jTTYolI5fPHH3/wzz//ANCkSRNatWplciIREakMbDaDzBwbmTm5ALhZLHi6u+Ht6YbFYjE5nVRExX5nXq1aNfbs2UOdOnWc2n/99Vfq1q1bUrkqjJSMbGIT0knNyMHf24PIEB+tZVQGIkN8iAi0FjqFLyLQSmSIjwmpxKX9/Tfcdhts3Qpz5kCHDlCtmtmpRKSSOX78OLfccgs//vgjwcHBACQmJtKjRw8WLlxIWFiYuQFFRKRCMAwDj+Dq7EvKZVvKcU6dziIxLYvTWbmFnu9mAV8vD0L8PAn1s5KbacU9oGoZp5aKqNhrSt1555088MADrFu3DovFwpEjR5g/fz6PPPII99xzT2lkLLcOnUzjw1/389Gagyzd9C8frTnIh7/u59DJNLOjVXgB3p4MahVJRKDVqT0i0Mqg1pEqDEo+mw3efBPatLEXpACSk2HtWnNziUildN9995GSksLff//NqVOnOHXqFH/99RfJycncf//9ZscTEZFyzDAMNhw4xaT/bmfYZ/upedf7rD2ay7Z/k/g3Md2pIOXhZsHT3YKHm310lM2A1MwcDp9KZ/PhRLalBRJ57xxWH/fm513xHElMxzAMs56alGPFHin1xBNPYLPZ6NmzJ2lpaXTt2hWr1cojjzzCfffdVxoZyyXt/ma+2qG+jOoc7RIj1TRizkUdOQIjR8L33+e3NW0K8+dD8+bm5RKRSmv58uWsXLmSmJgYR1vjxo2ZPn06vXv3NjGZiIiUV4lpWSzccJjPNhxm34nTjnYjJ5uwAC9qhwUR5m8l2NeLQB8PvD3ccXPLn6qXazNIy8ohNTOHU6ezOJGaxf4j8SRmu5GGO5sOJ7LpcCKB3h40qRlEk+qB+Fm1XIoUTbH/T7FYLDz55JM8+uij7Nmzh9TUVBo3boy/v39p5Cu3irL7W0x1FSVKW4C3p+mv86GTaQUKlBGBVga1iqR2qK+JySq5pUthzBg4eTK/7cEHYepU8PY2LZaIVG42mw3PQnb39PT0xGazmZBIRETKq7jkDD74ZR8L1h1yjILy9XLn6ibVaFbFYFS/KxgycxlhNc8/NdzdzUKAtycB3p5UD7Ivg1ItdTczn7mX6yfNI9Valf3xp0nOyGHN3pOs23eSRtUCaRMVQhU/r1J/nlK+Fbsodccdd/DGG28QEBBA48aNHe2nT5/mvvvuY9asWSUasLzS7m8CGjHnklJS7MWnM39XVa8Oc+fCVVeZFktEBODKK6/kgQce4JNPPqFGjRoA/Pvvvzz00EP07NnT5HQiIlIepGbm8N5Pe3n/l31kZNs/0GhULYARV9Shf4sa+Fs92LNnD0Z2xiU9jpGVTjXvXOo3rkZ2ro09x1PZ9m8SR5My2H40me1Hk7kswp8r6lUlyEfveaRwxS5KzZ07lxdffJGAgACn9vT0dD766CMVpf5Hu78JaMScS0pKso+SyjNoEMycad9hr5SZMY1TU0dFype3336ba6+9ljp16lCrVi0ADh8+TNOmTZk3b57J6URExJUZhsGXm4/w/NfbOZGaBUDr2sHc17MB3S8LK9Xd8zzd3YipHkhM9UCOJqWz8UAC+06cZldcKnuOp9I8MpjL61bB6uFeahmkfCpyZSQ5ORnDMDAMg5SUFLzPmN6Sm5vLN998Q3h4eKmELI+0+5uARsy5pMhIeO89GDXKvsD5iBFQBtvbmjGNU1NHRcqfWrVq8eeff7Jy5Up27NgBQExMDL169TI5mYiIuLLDp9L4v8+38cvuEwBEV/Xj8asb0adJRKkWowpTPciHAS18iE/J5Nc9Jzh0Ko3NhxPZFZdC1wZhXBahpX8kX5GLUsHBwVgsFiwWC5dddlmB4xaLhYkTJ5ZouPIsb/e3Qt8Qave3SkMj5lzA3r1QtSoEBeW3DR4M3bpBRESZRDBjGqemjoqUL6tWrWLcuHGsXbuWwMBArrrqKq7635TipKQkmjRpwowZM+jSpYvJSUVExJUYhsGSP2J5dtnfpGbm4OXhxgM9G3Bnl7p4ebiZmi0swMr1rWpy8ORpftwVT2JaNsv/PsaOY760CtFOfWJX5HfEq1evxjAMrrzySpYsWUKVKlUcx7y8vIiKinKsfSB2rrT7m5hDI+ZMZBgwezbcfz9cfz18/LHz8TIqSIE50zg1dVSkfJk2bRp33nkngYGBBY4FBQVx11138frrr6soJSIiDhYvH15YfZTV+1IAaFcnhJdvbEF0VT+TkzmLCvVjSAcf/jiYwIb9CRw4mcaRBPBt1NnsaOICilyU6tatGwD79++ndu3aZT4EsLxyhd3fxDwaMWeSEyfgrrvy146aN89emBo0yJQ4Zkzj1NRRkfJly5YtvPTSS+c83rt3b1599dUyTCQiIq4sKdOg+rDXWb0vBXc3Cw/1asA93evj7uaa79M93NzoEB1K/TB/vt8ex/GUTMKue4L//HqM16Ki8fbUWlOVVbHnDq1atQp/f39uuukmp/ZFixaRlpbG8OHDSyycSEWgEXNl7Pvv7etEHT2a3zZqFPTubVokM6ZxauqoSPkSFxeHp+e5/y54eHgQHx9fholERMRV7YtP5buD2XiG1qKqrwfvDW9Pm6gQs2MVSai/lcFta7F66z7+OpHD1zuS2Dv9N2YMbUMdFxvhJWWj2JNMp06dStWqVQu0h4eH88ILL5RIKJGKxj5iLpB20VWIqR6oglRpSE+HBx6APn3yC1KhofbRUh98AP7mLaiYN42zMKU1jdOMxxSRi1ezZk3++uuvcx7funUr1atXL8NEIiLiijYfTuS/W4+SY4OMQ9t4d2BUuSlI5XF3s9AizIPjnz1DsLc7O46lcO3bv/LzLn34UhkVuyh16NAhoqOjC7RHRUVx6NChEgklIlIsW7ZAu3b23fTy9OkD27bZp+2ZLG8a59lFotKcxmnGY4rIxevbty9PP/00GRkZBY6lp6fz7LPP0r9/fxOSiYiIKzAMg592xfPT/wo39YPdiPv0KUJ8y+/o94wDm5lxfR1a1Q4mOSOHEbPXM+vX/WbHkjJW7P+Dw8PD2bp1K3Xq1HFq37JlC6GhoSWVS0SkaLZsgfbtISvLfttqhVdegbFjwc3cHUfOZMY0Tk0dFSk/nnrqKZYuXcpll13GuHHjaNiwIQA7duxg+vTp5Obm8uSTT5qcUkREzJBrM1j5Txw7jtkXNO9cvyq13JP4wZZrcrJLV9XPg4VjLufpL/7is42xTPpqO3HJGTx+dSPcXHR9LClZxS5K3Xrrrdx///0EBATQtWtXAH766SceeOABbrnllhIPKCJyXs2bQ8+e8O230KIFzJ8PTZqYnapQZmx8oM0WRMqHiIgIfv/9d+655x4mTJiAYdi3yrZYLPTp04fp06cTUYa7hoqIiGvIybXx7V/H2HfiNG4W6N24Gg2rBRD/b7LZ0UqM1cOdl25oTnRVf15avoP3ft5HfEomL93YHE931/mQWUpHsYtSkydP5sCBA/Ts2RMPD/vdbTYbw4YN05pSIlL2LBaYNQveeQeefNI+UkpEpByKiorim2++ISEhgT179mAYBg0aNCAkpHytFSIiIiUj12bw9bajHDiZhrubhX7NqhNdQRcDt1gs3NO9HmEBVh5fspWlm/7l5Oks3hnSGj9r+Z2iKBdW7H9dLy8vPv30UyZPnsyWLVvw8fGhWbNmREVFlUY+EZF8SUlw//0wdChcdVV+e7VqMGmSeblEREpQSEgI7dq1MzuGiIiYyGYz+PYve0HKw83CtS1qUKuKr9mxSt2NbSKp4ufJvfP/5Kdd8dz2/lpmjWhHqL8+eK6oLnos3GWXXcZNN91E//79VZASkdL366/26XkffQQjRsDJk2YnEhEREREpcTbD4PvtceyNP427xUL/5tUrRUEqz5WNIlhw5+UE+3qyJTaJIR+s49TpLLNjSSkp0kip8ePHM3nyZPz8/Bg/fvx5z3399ddLJJiICADZ2fDcc/Dii2Cz2dtSU+0763XvbmYyEREREZESZRgGq3YcZ2dcCm4W6NusGlGhFXPK3vm0rh3C4ruv4Lb317LjWApDP1jHgjs7EOzrZXY0KWFFKkpt2rSJ7Oxsx/fnYrFodXwRKUE7d9qn6m3cmN/WpYt9tNRZO4CKiIiIiJRnhmHw0654/j6SjAW4ukk16ob5mx3LNPXD/Vlw5+XcMnMt248mc/uH65k3ugNBPtrEpyIpUlFq9erVhX4vIlIqDANmzoTx4yEtzd7m4WFfN+qxx8Dd3dx8IiIiIiIlbMOBBLbEJgFwVeMIGkQEmJzIfPbCVAdunbmWbf8mMWzWej4e1d7sWFKCtL+iiLiW48fhuuvg7rvzC1ING8LatTBhggpSIiIiIlLh7DyWwpp99jVTu18WRkz1QJMTuY7LIgKYN7qDfY2pw4mMmLWetCyb2bGkhBRppNSgQYOKfMGlS5dedBiRS5GSkU1sQjqpGTn4e3sQGeJDgLeGdpY7KSlw5ojMe+6BV18F38qzuKOIiIiIVB5HEtNZ8U8cAK1qB9OiVrC5gVxQTPVA5o3qwG3vr+XPQ4lM/CEL3IpUzhAXV6R/xaCgIMf3hmHw+eefExQURNu2bQH4448/SExMLFbxSqQkHTqZxtJNscQlZzraIgKtDGoVSe1QFTPKlXr14M034fHHYdYs6N/f7EQiIiIiIqUiJctg5d6j5NoM6lb1o3P9qmZHcllNawbx8agO3Pr+Wv74N43Qq+/DMAyzY8klKlJRavbs2Y7vH3/8cQYPHsyMGTNw/980mtzcXO69914CAzXEUMpeSkZ2gYIUQFxyJks3xTKqc7RGTLmyzZuhQQPwO2NXkREjYOBACAkxKZSIiIiISOlys/rxU2w26dkQHmDl6qbVcNPmYefVolYw04e0ZtScDfg368nWE7n0ijQ7lVyKYq8pNWvWLB555BFHQQrA3d2d8ePHM2vWrBINJ1IUsQnpBQpSeeKSM4lNSC/jRFIkubnw4ovQrh08/LDzMYtFBSkRkUvw7rvv0rx5cwIDAwkMDKRjx458++23ZscSEZH/ybEZhF3/fyRngb/Vg2tb1MDTXUs+F0WPhuE81LkaAH+ftLE1NtHcQHJJiv1/fU5ODjt27CjQvmPHDmw2LTYmZS81I+eSjosJDh6EHj3sC5fn5MB778HKlWanEhGpMCIjI3nxxRf5448/2LhxI1deeSXXXXcdf//9t9nRREQEmLk+Hu+oFni4wbUtauBn1fpIxXFNwyASf50PwI8749kbn2pyIrlYxf4/f+TIkYwaNYq9e/fSvr19K8Z169bx4osvMnLkyBIPKHIh/t7n/9/4QseljM2fD/feC8nJ9tsWi7041bWrublERCqQAQMGON2eMmUK7777LmvXrqVJkyYFzs/MzCQzM3/UcXLe72gRETmn+Ph4kpKSin2/VXuTWfpXAgBXVPcgLMBa0tEqhaTfPqFNv9vZm2Rj+V/HuKFNJNUCvYt9nYMHD150hqCgIMLCwi76/nIRRalXX32VatWq8dprr3H06FEAqlevzqOPPsrDZ0/BKWEvvvgiEyZM4IEHHmDatGkAZGRk8PDDD7Nw4UIyMzPp06cP77zzDhEREaWaRVxHZIgPEYHWQqfwRQRaiQzxMSGVFJCYaC9GffJJfltUFHz8MXTpYlosEZGKLjc3l0WLFnH69Gk6duxY6DlTp05l4sSJZZxMRKT8io+Pp379BiQnF68o5Vk1imq3v4ablzdJv39K1dtuKKWElUO7au7kenhz4GQaX209wq3tahd51FlaciJgoVevXhf9+IGBQezZs1uFqUtQ7KKUm5sbjz32GI899pjjU7SyWOB8w4YNvPfeezRv3typ/aGHHuLrr79m0aJFBAUFMW7cOAYNGsRvv/1W6pnENQR4ezKoVWThu++1jtQi567gxx9h2DA4fDi/7fbb4a234IzdPUVEpORs27aNjh07kpGRgb+/P59//jmNGzcu9NwJEyYwfvx4x+3k5GRq1apVVlFFRMqdpKQkkpOTuPulOYSE1yjSfbJyDZYfyCY1G4KMVA7+Op/MGwZc+I5yTm4WC1c3rcZnG2M5dTqLr7Ye5YbWNfEowvpcGemnAYMhT75J7fqNiv3YCcePMOPxESQlJakodQkual5TTk4OP/74I3v37uW2224D4MiRIwQGBuLv71+iAQFSU1MZMmQI77//Ps8//7yjPSkpiQ8//JAFCxZw5ZVXAvadAmNiYli7di2XX355odfTEPWKp3aoL6M6RxObkE5qRg7+3h5EhvioIOUKfvoJrrwS8rZrDQ6GGTPg5ptNjSUiUtE1bNiQzZs3k5SUxOLFixk+fDg//fRToYUpq9WK1arpIyIixRUSXoOwmlEXPM8wDL7aepTU7GwCvD1oY81gq6E1mUuC1cOdAc2rs3DDYY4lZ7Bq53GuionAUsSdDIPCqhXp31BKR7EXOj948CDNmjXjuuuuY+zYscTHxwPw0ksv8cgjj5R4QICxY8fSr1+/AsPq/vjjD7Kzs53aGzVqRO3atVmzZs05rzd16lSCgoIcX/oksGII8PYkpnog7aKrEFM9UAUpV9GlC3Tvbv++Rw/YulUFKRGRMuDl5UX9+vVp06YNU6dOpUWLFrzxxhtmxxIRqZQ2HExg34nTuFss9GtWHS83w+xIFUqwrxfXNK2GBfjnaAqbDyeaHUmKqNhFqQceeIC2bduSkJCAj0/+Wj3XX389P/zwQ4mGA1i4cCF//vknU6dOLXDs2LFjeHl5ERwc7NQeERHBsWPHznnNCRMmkJSU5Pg6fOaUIhEpWW5uMHcuvP66fYc9FYFFRExhs9mcRoqLiEjZiE1IY+3ekwB0bxhGxEUsxi0XFhXqR+cGVQH4Zc8JDp1KMzmRFEWxp+/98ssv/P7773h5eTm116lTh3///bfEggEcPnyYBx54gBUrVuDtXXI/uBqiLlJKjh2D0aPh8cedFy+vVQseesi8XCIilcyECRO45pprqF27NikpKSxYsIAff/yR7777zuxoIiKVSnp2Lt/9HYcBxFQLoGlNradamlrVCuZEaib/HE3hm21HubV9bYJ8NIPGlRV7pJTNZiM3N7dAe2xsLAEBASUSKs8ff/zB8ePHad26NR4eHnh4ePDTTz/x5ptv4uHhQUREBFlZWSQmJjrdLy4ujmrVqpVoFhG5gC+/hGbN4Ouv7YuYX8T2uCIiUjKOHz/OsGHDaNiwIT179mTDhg189913XHXVVWZHExGpNAzDYOX2OFIzcwj29aR7w3CzI1V4FouFKxuGUy3Qm8wcG99sO0pOrtbucmXFLkr17t2badOmOW5bLBZSU1N59tln6du3b0lmo2fPnmzbto3Nmzc7vtq2bcuQIUMc33t6ejpNG9y5cyeHDh0655bHIlLCUlPhzjth4EA4ccLelpkJe/eaGktEpDL78MMPOXDgAJmZmRw/fpyVK1eqICUiUsa2xiY51pG6pmk1vDyK/fZbLoKHuxvXNKuGt4cbx1My+WX3CbMjyXkUe/req6++ytVXX03jxo3JyMjgtttuY/fu3VStWpVPPvmkRMMFBATQtGlTpzY/Pz9CQ0Md7aNGjWL8+PFUqVKFwMBA7rvvPjp27HjOnfdEpAStWwdDh8KePflt110H778P2hZVRERERCqp+JRMftljL4Z0blCV8ACtI1WWAr096dOkGl9uOcLWf5OoEexDw2olO7NLSkaxi1K1atViy5YtfPrpp2zZsoXU1FRGjRrFkCFDnBY+Lyv/+c9/cHNz44YbbiAzM5M+ffrwzjvvlHkOkUolJwdeeAEmTYK86bx+fvDGG3DHHVDE7VdFRERERCqa7Fwb3/51lFybQXRVP1pEah0pM9Sp6ke7OiFsOJDADzviCAuwUsXP68J3lDJVrKJUdnY2jRo14quvvmLIkCEMGTKktHKd048//uh029vbm+nTpzN9+vQyzyJSKe3fbx8d9fvv+W3t28O8edCggXm5RERERERcwE+74klIy8bP6s5VMRFY9IGtaS6vG8rRpAxiE9L5ZttRbm5XC093TaN0JcX61/D09CQjI6O0sohIeZCeDn/+af/ezQ2efRZ+/VUFKRERERGp9PadSOXvI8kAXN2kGj5e7iYnqtzcLBaublINXy93Tp7OYvWO42ZHkrMUu0Q4duxYXnrpJXJyckojj4i4usaN4ZVXoG5dezHquefAU9usioiIiEjllpGdyw//2IserWsHExnia3IiAfCzenBN02pYgH+OpbDjaLLZkeQMxV5TasOGDfzwww98//33NGvWDD8/P6fjS5cuLbFwIuICfv7ZPj3P+4zFGceOhZEj7etIiYiIiIgIP+6KJy0rlxBfTzrWDTU7jpwhMsSXDnWrsHbfKVbtPE61IC087yqKXZQKDg7mhhtuKI0sIuJKMjJgwgSYNg0eeghefz3/mMWigpSIiIiIyP/sOZ7KzmMpWIDejavhoXWLXE67OlU4dCqNI4kZLP/7GC30T+QSil2Umj17dmnkEBFXsnUrDBkCf/1lv/2f/8Att9hHTImIiIiIiENaVg6r/rdWUds6IRqF46LcLBb6NKnGgnWHiEvOZI+3ple6giLXBm02Gy+99BKdOnWiXbt2PPHEE6Snp5dmNhEpazabfURUu3b5BSmr1T5aqm1bU6OJiIiIiLgawzBYvTOe9OxcQv29aB9dxexIch6B3p70bBQOwL4MX6y1m5mcSIpclJoyZQr/93//h7+/PzVr1uSNN95g7NixpZlNRMrSv/9C797w8MOQlWVva9YMNmyABx6w77QnIiIiIiIOB1Ns7DmeipsFejeOwEN9ZpfXICKAJjUCAQtV+z9Mls3sRJVbkX9iPvroI9555x2+++47vvjiC/773/8yf/58bDb9C4qUe4sX2wtQP/yQ3/bww7B+vb1dREREREScuPkFs/FYLmBfryg8QNP2yotul4Xh65aDR0BVtiZ6YRiG2ZEqrSIXpQ4dOkTfvn0dt3v16oXFYuHIkSOlEkxEysjnn8NNN0FCgv12zZqwciW8+qrzjnsiIiIiIgLYp+2F9rmPLBuEB1hpV0fT9soTT3c3WvilYORmE5fpwT/HUsyOVGkVuSiVk5OD91lvUD09PcnOzi7xUCJShgYMgA4d7N/fdJN9kfOePc3NJCIiIiLiwlbsTsa3QQfcLHBV4wjc3SxmR5JiCvLIIfGX+QD8tDOe5HTVNsxQ5N33DMNgxIgRWK1WR1tGRgZ33303fmdsDb906dKSTSgiJcswwHLGH00PD5g3D37/HW6/3fmYiIiIiIg4OZqUzvS19t32mlV1p6q/9QL3EFeVvH4pda+6nYRsWPFPHINa1cSi90NlqsgjpYYPH054eDhBQUGOr6FDh1KjRg2nNhFxYbt3Q5cusHGjc3v9+jBsmApSIiIiIiLnYRgGjy/ZxuksG5lHdhBTRQubl2uGjRbBWXi6W4hNSGfz4USzE1U6RR4pNXv27NLMISKlyTDggw/gwQchLQ2GDIE//4QzRjmKiIiIiMj5LdxwmJ93xePlbuHfr/+D25V6n1ze+XkYdKkfxqqdx/lt70lqV/ElVKPfyozKuiIVXXw8XH89jBljL0iBvUilTQpERERERIrs8Kk0nv9qOwB3tK1Kzql/TU4kJaVpzUCiQn3JtRl8vz2OXJt24ysrKkqJVGTffgvNmsGXX+a33XUXbNoEDRqYl0tEREREpByx2QweW7yV01m5tKsTwvVNQsyOJCXIYrHQKyYCbw83jqdksv7AKbMjVRoqSolUROnpcN990LcvxMXZ26pWtRenZszQtD0RERERkWL4eO1B1uw7iY+nO6/e1EK77VVA/lYPejQKB2DjgVMcT8kwOVHloKKUSEWzdSu0aQNvv53f1rcvbNsG115rXi4RERERkXLowInTvPjtDgAm9G1EVKg+4K2oLosIoH64PzYDVmgaX5lQUUqkosnNhT177N97e8P06fDVV1Ctmrm5RERERETKmVybwSOLtpCencsV9UIZ2iHK7EhSyno0DMPb040TqVls1DS+UqeilEhF06oVPP88tG5t32Hv3nvBouHFIiIiIiLFNevX/Ww8mIC/1YOXb2yOm6btVXi+Xh50v8w+jW/9gVPEp2SanKhiU1FKpLz7+mvIznZue/hhWLMGYmLMySQiIiIiUs7tOZ7CK9/vBOCpfjFEhvianEjKymUR/tQL88NmwMp/NI2vNKkoJVJeJSbC0KHQvz9MmuR8zN0dvLxMiSUiIiIiUt7l5Np4eNFWsnJsdLssjJvb1TI7kpQhi8VCj4bhWP+3G98fhxLMjlRhqSglUh79/DO0aAHz59tvv/AC7NhhbiYRERERkQrivZ/3seVwIgHeHrx4QzMsWg6j0vGzetD9sjAA1u87xclUTeMrDSpKiZQnWVkwYQJ07w6HDtnbgoLg44+hUSNTo4mIiIiIVAQ7jiUzbeUuAJ4b0ITqQT4mJxKzNKwWQHRVP3INgxX/xGHTNL4Sp6KUSHmxYwd07AgvvgjG/34Zdu0KW7bAbbeZm01EREREpALIzrXx8GdbyM416BUTwaDWNc2OJCayWCxc2TAcLw834pIz+fOwpvGVNBWlRFydYcA77+Tvpgfg6QkvvQSrVkGUtqUVERERESkJb6/aw99Hkgn29eSFQU01bU/w9/agWwP7NL61+05x6nSWyYkqFhWlRFzdrFkwdiykp9tvN2oEa9fCY4/ZFzQXEREREZFL9te/SUxfvQeAydc1JTzA2+RE4ipiqgcQFepLrs1gxfY4bIam8ZUUFaVEXN3QodCypf37sWPhjz/so6ZERERERKREZObkMv6zzeTYDPo1q86AFjXMjiQuxGKx0LNROF7ubhxLzmBrbJLZkSoMFaVEXM3ZVXer1b7L3tdfw9tvg6+vOblERERERCqoaSt3sysular+Xkwe2NTsOOKCArw96VQ/FIDf957gdLZGS5UEFaVEXMnGjfZRUdu2Obc3bgx9+5oSSURERESkItt0KIH3ftoLwPMDm1HFz8vkROKqmtUMokaQN9m5BuuP5Zgdp0JQUUrEFeTmwpQp9t31tm6FIUMgI8PsVCIiIiIiFVpGdi4PL9qCzYCBLWtwddNqZkcSF2axWOgZE4G7xcLR0wa+Md3MjlTuqSglYrb9+6FbN3jqKcj5X7Xd2xtOnTI3l4iIiIhIBffqdzvZF3+a8AArE6/VtD25sCp+XrSPrmL/vtcYkjI0YupSqCglYhbDgI8+ghYt4Lff7G1ubvbi1G+/QQ0trigiIiIiUlo2HDjFh7/tB+ClG5oT5OtpciIpL9pEhRBkteDuG8S7a+PNjlOuqSglYoZTp+Dmm2H4cEhJsbdFR8PPP8PkyeCpP4giIiIiIqUlNTOH8Z9txjBgcNtIejQKNzuSlCPubhY6VHPHMGys3JPMT7tUmLpYKkqJlLVffoHmzWHRovy24cNh82bo1Mm0WCIiIiIilcXzX23n8Kl0agb78FT/xmbHkXKoqo8bKRuXAfB/S7dxOlPT+C6GilIiZc3DA44etX8fEgKffQZz5kBgoKmxREREREQqg5Xb41i44TAWC7w2uAWB3pqlIBcn8Zd5RPh78G9iOq+v2GV2nHJJRSmRstaxo33dqJ497Tvt3XST2YlERERERCqFk6mZPLF0KwCjO0dzed1QkxNJeWZkZ/BAJ/uOjbN/28/mw4nmBiqHVJQSKU02GyxcCLm5zu1PPw3ffw+RkebkEhERERGpZAzDYMLSbZxIzaJhRAAP925odiSpANrX8uP6VjWxGfDEkq1k59rMjlSuqCglUlqOHIFrroFbb4WXX3Y+5uFh32lPRERERETKxOI/Yvl+exye7hb+c3NLvD3dzY4kFcTT/RtTxc+LHcdSmPnzPrPjlCt6VyxSGpYutS9m/v339tvPPQf//mtqJBERqTymTp1Ku3btCAgIIDw8nIEDB7Jz506zY4mImObwqTQm/nc7AA9ddRmNa2g9Vyk5Vfy8eOZ/C+a/8cNu9sanmpyo/FBRSqQkpaTAqFFwww1w8qS9rUYN+OorqFnT3GwiIlJp/PTTT4wdO5a1a9eyYsUKsrOz6d27N6dPnzY7mohImcu1GTy8aAupmTm0jQrhrq71zI4kFdB1LWvQ7bIwsnJsTFiyDZvNMDtSueBhdgCRCmPtWhg6FPbuzW+74QZ47z0I1QKKIiJSdpYvX+50e86cOYSHh/PHH3/QtWvXAudnZmaSmZnpuJ2cnFzqGUXEfPHx8SQlJV30/YOCgggLCyvBRKXjw1/3sX7/Kfy83Hl9cEvc3SzApT3/gwcPlmTEi3axOZS/5JyZZUyrANbtO8H6A6d48+s/6B8TfN77lpefodKkopTIpcrJgeeft3/lLWju7w9vvQXDh4PFYm4+ERGp9PLedFWpUqXQ41OnTmXixIllGUlETBYfH0/9+g1ITr74olRgYBB79ux26TfV/xxN5tXvdgH2dX9qh/oCJfP8ATIy0i4548VIS04ELPTq1euSrqP8F+9czyGgzbVU6TWG11ft45Hb7iU39eQ5r1EefoZKm4pSIpdq2jQ4syPfsSN8/DHU07BgERExn81m48EHH6RTp040bdq00HMmTJjA+PHjHbeTk5OpVatWWUUUERMkJSWRnJzE3S/NISS8RrHvn3D8CDMeH0FSUpLLvqHOyM7loU83k5Vro1dMODe3y/+9dqnP/8D2TXzyyuNkZmaVZOQiy0g/DRgMefJNatdvVOz7K/+lO9dzsBkGKw7mcBI/Ln/8I7rU9MBSyECF8vAzVBZUlBK5VPfeCx9+CLt3w7PPwoQJ9t31REREXMDYsWP566+/+PXXX895jtVqxWq1lmEqEXEVIeE1CKsZZXaMUjH1m3/YcSyFUD8vpg5qXmhh4GKf/6k419jEKCismvKbrLDncHVwJp+sP0RsqkGSVygNwgNMSuf69M5ZpLhyc8H9jO1jfX3hk08gMxM6dDAvl4iIyFnGjRvHV199xc8//0xkZKTZcUREysz3fx9j7hr7Wj+vDm5BWIAK71J2qvpbaRtVhfUHTvHjznhqhfji7el+4TtWQtp9T6Q4vv8eGjWyj4o6U8uWKkiJiIjLMAyDcePG8fnnn7Nq1Sqio6PNjiQiUmaOJqXz2JKtAIzuHE2PhuEmJ5LKqF2dEEJ8PUnLyuXXPSfMjuOyVJQSKYr0dHjgAejTB/bsgSFDIDvb7FQiIiKFGjt2LPPmzWPBggUEBARw7Ngxjh07Rnp6utnRRERKVa7N4MGFm0lMy6ZZzSAeu7r46xWJlAQPdzd6xkQA8PeRZA6fMm9RdlemopTIhWzZAu3awZtv5rdVqQKpqeZlEhEROY93332XpKQkunfvTvXq1R1fn376qdnRRERK1dur9rBu/yn8vNx589ZWeHnoLa+Yp2awD81rBgHww47jZOfaTE7kerSmlMi52Gzw+uvw5JOQ9b9dHby94ZVXYOxYKGShRBEREVdgGIbZEUREytyGA6d444ddAEwe2JToqn4mJxKBK+qHsu/EaZLSs1m77yRdGlTenfYKo7KxSGEOH4ZeveDRR/MLUi1awMaNMG6cClIiIiIiIi7kRGom9y3YhM2AQa1qMqi1NncQ12D1cKdHI3shatOhROKSM0xO5FpUlBI527Jl0Lw5rF5tv22x2ItT69ZBkybmZhMRERERESe5NoMHFm7iWHIGdcP8mDSwqdmRRJzUrerPZRH+GMDKf+LItWlEcx4VpUTO5u8PSUn27yMj4Ycf4OWXwaptZEVEREREXM20lbv4bc9JfDzdmTG0Df5WrVIjrqfbZWF4e7hxIjWLPw8lmB3HZagoJXK2K6+Ehx+Gm2+GrVuhRw+zE4mIiIiISCFW7zjOW6v2APDiDc24LCLA5EQihfP18qDrZfZpfOv2nyI5U6OlQEUpqeyysuDDD+2Lmp/pxRfhk08gJMScXCIiIiIicl6HT6Xx4KebARjWMYrrWtY0N5DIBTSqFkDtKr7k2gzWHcsBtFaxilJSee3cCVdcAaNHw1tvOR9zd9di5iIiIiIiLiojO5d75/9JUno2LWoF82S/GLMjiVyQxWKhZ6NwPN0txKcb+Le82uxIplNRSiofw4AZM6BVK/jjD3vbU09Bgub1ioiIiIi4OsMweG7Z32z7N4kQX0/eGdIa6/+3d9/hUVT7/8Dfu5vsZje9N1KAcCkSEggtoIiSr0hRUFTkggbkgiIo3GAhcq9g4YKiCCKi/oSAKEWugAgIN0a6IdRQJAQCaYQkpPey2T2/P1YWlkAIkOykvF/Ps08yZ87MfOZMdjPz2TNnLBRSh0VUL3ZqS4S2cwYAOA6cgJwyrcQRSYtJKWpdrl4FnnwSmDIFqKgwlHXsCOzZw1v1iIiIiIiagdV/pGD9kXTIZcDi57vD20EtdUhEdyXIxwHOVjLIVRp8fjAbQrTe8aWadFJq/vz56NWrF2xtbeHm5oaRI0ciMTHRpE5lZSWmTp0KZ2dn2NjYYNSoUcjOzpYoYmrStm8HAgOBbduul02ZAhw/DoSESBcXERERERHVy4ELufhgewIAIHJIZzz818DRRM2JXCZDH08FhE6L2LQybD+dKXVIkmnSSam9e/di6tSpOHToEKKjo6HVavHYY4+hrKzMWOef//wnfvnlF2zcuBF79+7FlStX8PTTT0sYNTU55eXAq68Cw4cbekoBgKsr8MsvwJdfAhqNtPEREREREdEdJeeWYera49DpBZ7u4Y1/PNRW6pCI7pmDSo6iQxsBAHO3/omCsmqJI5KGhdQB1GXnzp0m06tWrYKbmxuOHTuGAQMGoKioCCtWrMDatWvx6KOPAgCioqLQuXNnHDp0CH379r3lequqqlBVVWWcLi4ubrydIOl9+CGwfPn16eHDgW+/BdzdpYuJiIiIiIjqrbhSi0nfHUVRhRbdfR3wn6cCIeODiaiZK4r9Ed2GjUdaYTU+2H4Wi54Lljoks2vSPaVuVlRUBABwcnICABw7dgxarRZhYWHGOp06dYKvry9iY2Nvu5758+fD3t7e+PLx8WncwElas2YBbdsCarVhgPOtW5mQIiIiIiJqJnR6genrTiDpaik87Kzw9bgQWFlyYHNqAXQ1eOMhD8hkwKbjGfj9XOsbiqjZJKX0ej1mzJiB/v37o2vXrgCArKwsKJVKODg4mNR1d3dHVlbWbdcVGRmJoqIi4ys9Pb0xQydzq76p26OdHbBxI3DiBPDyywC/USEiIiIiajbmbU/A7sQcqCzk+ObFELjZWUkdElGD6eKuxkv9DbeiRm46jaKK1vU0vmaTlJo6dSrOnDmD9evX3/e6VCoV7OzsTF7UAggBfP890KEDkJpqOi8kxPCUPSIiIiIiaja+3X8JKw8mAwAWPhuEbm0cpA2IqBG88VhHtHWxRnZxFT7YdlbqcMyqWSSlpk2bhm3btmH37t1o06aNsdzDwwPV1dUoLCw0qZ+dnQ0PDw8zR0mSKigA/v534IUXgLQ0w0+dTuqoiIiIiIjoHm07dQUfGp+01wlPBnlJHBFR41ArFVj4TDfIZMB/j13G7nNXpQ7JbJp0UkoIgWnTpmHz5s34/fff0bat6dMVQkJCYGlpiZiYGGNZYmIi0tLSEBoaau5wSSq7dwPdugE39qLz9wduGMyeiIiIiIiaj7hLeYjYcBIAEB7qh8kD2kkcEVHj6unvZLyNb9amU63mNr4mnZSaOnUqvv/+e6xduxa2trbIyspCVlYWKioqAAD29vaYOHEiIiIisHv3bhw7dgwTJkxAaGjobZ+8Ry1IVRXw1lvAoEHA5cuGMgcHQ3Lqu+8AjUbS8IiIiIiI6O5dyC7BpO+Oolqnx+AH3PHuEw/wSXvUKrTG2/iadFJq+fLlKCoqwsCBA+Hp6Wl8bdiwwVjns88+w/DhwzFq1CgMGDAAHh4e2LRpk4RRk1mcPQv07QssXGgYSwoAHn0UOH0aGD1a2tiIiIiIiOieZBZVYHzUERRX1qCHrwOWPN8dCjkTUtQ6qJUKfNzKbuNr0kkpIcQtX+PHjzfWsbKywrJly5Cfn4+ysjJs2rSJ40m1dFFRhoHL4+MN00ol8MknQHQ0cMOYY0RERERE1HzklFRh7P+LQ0ZhBdq5WOPb8F6wslRIHRaRWfXyd8KEfq3nNr4mnZQiuiVXV6Cy0vB7ly7A4cPAzJmAnH/ORERERETNUUFZNV5YEYdLuWXwsrfCdxN7w8laKXVYRJJ4c3BH+DtrkF1chQ9b+G18vIqn5mf4cODVV4Hp04GjR4GgIKkjIiIiIiKie1RcqUV41GGcyyqBm60Kayf1RRtHjg9LrZdaqcDCZ4MgkwEbW/htfExKUdNWWgp8+eX1caOu+eILYPFiQK2WJCwiIiIiIrp/5dU1eCnqCE5dLoKTtRI//KMP/F2spQ6LSHI33sYXuek0ispb5m18TEpR0xUXBwQHA1OnAitXms7j0zeIiIiIiJq1imodJn93DEdTC2BnZYHvXuqNDu62UodF1GRcu40vq7gS7249I3U4jYJJKWp6amqA998H+vcHLl40lM2eDVRUSBsXERERERE1iNKqGkxYdRgHknJhrVRg1Uu90dXbXuqwiJoUtVKBRaODIZcBP8dfwS8nr0gdUoNjUoqalosXgQEDgDlzAJ3OUNanD3DgAG/VIyIiIiJqAYoqtHhxRRwOXcqHjcoCq1/qjR6+jlKHRdQk9fB1xNRHAgAA/9pyBllFlRJH1LCYlKKmQQggKspwu15srKFMoTAkpw4cAAICJA2PiIiIiIjuX35ZNcZ+ewjH0wphr7bED//og57+TlKHRdSkvT6oAwK97VFUocWb/z0JcfOYy80Yk1Ikvbw84NlngZdeMgxsDgDt2gH79wNz5wIWFpKGR0RERERE9+9qSSXGfHMIZzKK4WytxLpJfRHk4yB1WERNnqVCjs9GB0FlIcf+C7lYcyhV6pAaDJNSJL1//xv46afr0xMnAvHxQGioZCEREREREVHDScsrx+ivDyExuwTudipseLkvunjZSR0WUbMR4GaLWUM6AQD+syMBF3NKJY6oYTApRdL78EPA2xtwcjIkp779FrDlUzeIiIiIiFqCk+mFeHr5QSTnlsHbQY0fXw5FgBvP94nuVnioP/oHOKNSq0fEhnhodXqpQ7pvTEqR+d38FD0nJ2DzZuD0aeDpp6WJiYiIiIiIGtzv57Lx/DeHkFtajS6edtj0aj/4OVtLHRZRsySXy/DJs0Gws7LAyctFWBR9XuqQ7huTUmQ+ej2waBHQoQOQmWk6r1cvwMtLmriIiIiIiKjBrY1Lwz9WH0WFVoeHOrjgx1dC4W5nJXVYRM2ap70aH43qBgD4au9F/JGUK3FE94dJKTKPy5eBxx4DZs4EMjKACRMMT9wjIiIiIqIWRa8XWLjrHN7ZfBp6ATwT0gYrx/eCjYoPMCJqCEMCPTGmtw+EAGZsiEd+WbXUId0zJqWo8W3cCHTrBsTEXC/r2hWoqZEuJiIiIiIianAllVpMXnMUy3ZfBGB4lP3CZ7rBUsFLT6KG9O/hXdDe1RpXS6rw1n9PQjTTTh/8ZKDGU1wMjB8PPPccUFBgKPP2Bn77DfjkE8DSUtLwiIiIiIio4STnluGpL//AbwlXobSQ49NngxDxf3+DTCaTOjSiFkejtMDSMT2gVMjxW8JVrDmUKnVI94RJKWocBw8CwcHA6tXXy557Djh1Chg0SLKwiIiIiIio4e09n4MRXxxA0tVSeNhZYePLoRgV0kbqsIhatC5edpg1pBMA4MPtCTiXVSxxRHePSSlqeB9/DAwYACQnG6ZtbQ3JqfXrDU/aIyIiIiKiFkEvBL7ck4QJUYdRXFmDED9HbH2tP4J8HKQOjahVmNDfH490dEV1jR7T1p5AeXXzGiaHSSlqeG3bGp60BwD9+wMnTwIvvgiw2y4RERERUYshV9th9q4MfLwzEXoBPN/LB2sn9YGbLZ+wR2QuMpkMC58NgputCklXSzF785lmNb4Uk1LU8J59FvjHP4B584C9ew1JKiIiIiIiajGuluvhOWEpjlwug8pCjo9GBWL+04FQWSikDo2o1XGxUWHpmO5QyGXYfCID64+kSx1SvTEpRfcnJwf4/PPa5d98A7zzDqDgPyUiIiIiopZCCIHDKfmISauBha0zfO2V+Hlaf4zu5csBzYkk1KedM954rCMAYM7WP3Emo0jiiOqHSSm6d7/+CgQGAtOnA+vWmc7jPyQiIiIiohaluFKLTScyEHsxDwJA6ZnfsWykHzp52EkdGhEBeHlAOwzq5IbqGj2mrj2O4kqt1CHdEZNSdPfKy4Fp04ChQ4HsbEPZnDlATfMaUI2IiIiIiO5MCIGEzGL8cCgNlwsqYCGXoY+HAnnbF0FtyUtKoqZCLpfh0+eC4O2gRmpeOd7aeKrJjy/FTxC6OydOAD17AsuWXS8bOhTYtw+wsJAuLiIiIjLat28fnnjiCXh5eUEmk2HLli1Sh0REzVRFtQ7bT2fif2ezUa3Tw9PeCmP7+KK9A4fpIGqKHDRKLBvbA5YKGXb+mYUVB5KlDqlOTEpR/eh0wEcfAX36AAkJhjIrK0Nyats2wMND2viIiIjIqKysDEFBQVh245dIRER3KelqKb6PS8XFnDLIZUBoe2c806MNHDRKqUMjojoE+zhg9tDOAID5v57DH0m5Ekd0e+zaQneWlga8+KLhSXrX9OgBfP890LmzdHERERHRLQ0ZMgRDhgyROgwiaqbKqmqwJzEHSTmlAAAnayUGd3GHm52VxJERUX2F9/PHqctF2HQiA1PXHsfWaQ/Cx0kjdVi1MClFdzZr1vWElEwGvP028N57gJLfkBAREbUEVVVVqKqqMk4XFxebZbs5OTkoKrr3pwPZ29vD1dW1ASMic5L6+Eu9/YZwP/uQmppaq0wIgT8zi3HgQi6qavSQy4AQP0f09neCheLWN9ncaj31pdVqYWlpec/LN4VjQHS/GvM9NDFIgzPpVjifW4nx3/6BxU/4mowD1xTeQ0xK0Z199hnw22+AWg2sWQMMGCB1RERERNSA5s+fj/fee8+s28zJyUFAQAcUF997UsDOzh5JSRckP6Gmuyf18Zd6+w2hIfYBACorywEABWXV+D3xKi4XVAAA3GxVCOvsDldb1S2XKy8uBCBDWFjYvW9cJgeE/p4Xl/oYEN0Pc72HFLYu8Az/DBfhiEdnrUDu1o+N85rCe4hJKaqtpASwtb0+7e4O7NgBBAQADg6ShUVERESNIzIyEhEREcbp4uJi+Pj4NOo2i4qKUFxchFc+WgVHN6+7Xr7g6hV89fZ4FBUV8YK0GZL6+Eu9/YZwv/uQcvYE1i18G2UV1TiYlIvjaQXQC8BCLkPfds7o7uMAuVx22+UrK8oACIyd/Tl8Azrd8/bvdfmmcAyI7oc530NXy/WISauBdecB6D/gEXRxVjSZ9xCTUnRddTUwZ46hN1R8PODicn1ez56ShUVERESNS6VSQaW6dW+Ixubo5gVXbz9Jtk3Sk/r4S739hnCv+5CXlQH130KxN8cKlfoCAIC/swYP/831rgYyt3f1uKft52dn3NfyRC2FOd5DrgB06kLsTsxBfI4Ofl7ucHS7l2gbHp++RwYJCUDfvsCCBUBGBjB5MiCE1FEREREREVEDyy2twrFSe7g9NRuVejlsrSzwRDdPPBnkxSfrEbVQgd726OplBwD49UwWCqvu/dbZhsSeUq2dEMCXXwJvvAFUVhrKLC0NCSohDAObExERUbNSWlqKpKQk43RycjLi4+Ph5OQEX19fCSMjIimVVdXg0KU8/HmlGAJKiBotOjgAj/VsD8vbDGRORC2DTCbDwI5uKCjXIqOwAnvT9ZBrHKQOiz2lWrXsbGD4cGDatOsJqc6dgbg44K23ADn/PIiIiJqjo0ePonv37ujevTsAICIiAt27d8e7774rcWREJAWtTo+4S3lYHZuCM1eKIQC4W1bhyopX0dFWy4QUUSuhkMswrJsnHNSWKKsB3J7+F6prpO0xxZ5SrdXWrcA//gHk5FwvmzYN+OgjQKORLi4iIiK6bwMHDoTgbfhErZ5eCCRkFiP2Uh7KqnQAAA87KzzUwQUll07gcGGmxBESkbmpLRV4MtgL6+NSUW2pQmk1k1Jkbm+8AXz66fVpd3cgKgoYMkS6mIiIiIiIqEEIIZCcW4bYS3nILa0GANhZWaB/gAs6uNlAJpMhUeIYiUg6jholHvW1wDefvgWnd05JGguTUq1RYOD13598Evj2W4CPUSUiIiIiataEEEjNK0fspTxcLakCAKgs5Ojt74RuPvaw4PAcRPQXJys5RHWF1GEwKdUqvfgisHs30L+/4RY+DmZORERERNRsCSGQll+OQ5fykVVsGCvWQi5DkI8DQvwcobZUSBwhEdGtMSnV0iUnA1u2AP/85/UymQxYtUqqiIiIiIiIqIFkl+mx59hlXCkyJKMUchmC2tgjxM8RGiUv94ioaeOnVEslBLBmjWHw8pISoF07YMQIqaMiIiIiIqL7pNcLxKaWwn3sR4hJrwFQA4VchkBve/T0c4S1ipd5RNQ88NOqJcrPB6ZMAX788XrZf/5jGD+Kt+oRERERETVLVTU6/Bx/Bd/su4Skq6WwavMA5DKgq7c9evk5wcaKl3dE1LzwU6uliYkBwsOBjIzrZePHA0uWMCFFRERERNQMlVRqsTYuDSsPJiO72DCAucZSjsz9GxA+9u/w83eTOEIionvDpFRLUVUFzJ4NfPrp9TJHR+Cbb4BnnpEuLiIiIiIiuifp+eVYcygV6+LSUFJVAwBwt1Nh4oNt0celBsEfroZm/FiJoyQiundMSrUEZ84Af/87cPr09bJBg4DVqwFvb+niIiIiIiKiu6LXC+y9kIM1sanYnXgVQhjKA9xsMHlAO4wM9obSQo6kpCRpAyUiagBMSrUEb799PSGlVAILFgDTpwNyubRxERERERFRvRSWV2Pj0cv4Pi4VqXnlxvIBf3NFeKgfHunoBrmcw3EQUcvCpFRL8PXXQGAg0KYN8MMPQLduUkdERERERER3IITA0dQC/HgkHb+cuoJKrR4AYGtlgWdDfDCury/audpIHCURUeNhUqo5KigwjBd1TZs2hgHOu3QBrKyki4uIiIiIiO4oo7ACm45dxk/HLyPlhl5RnT3t8GKoH0YEe0Gj5KUaEbV8/KRrTkpKgBkzgN9+A06dAuztr8/r0UOysIiIiIiIqG4V1Trs/DMT/z12GX9czDOOFaVRKjAs0BOje/kgxM8RMj4xm4haESalmovYWGDcOODSJcP01KnA999LGxMREREREd1WpVaH/Rdysf3UFfyWcBWlfz1BDwBC2znjmZA2eLyrB6xVvCwjotaJn35NXU0N8OGHhpdOZyizsQHCwgAhAH6TQkRERETUZFTV6LDvfC52nM5E9Nlsk0SUj5Maz/TwwdM9vOHjpJEwSiKipoFJqaYsKcnQOyou7npZaKihh1S7dtLFRURERERERqVVNThwIRf/+zML0WezUXJDIsrDzgpDAz0xrJsHuvs48gl6REQ3YFKqKRICWLkSmD4dKCszlCkUwJw5QGQkYMHDRkREREQkJYWdG7b8WYCTe+MQdykf1Tq9cZ6HnRWGBHpgeDdPJqKIiOrA7EZT9MILwA8/XJ8OCDD0jurTR7qYiIiIiIhaMZ1eIKuoEil5ZbiQqUWbKSvxRexV43w/Zw0GdXLH0EAP9PBlIoqIqD6YlGqK+vW7npSaNAlYtMgwjhQREREREZmFEAJ5ZdVIyy9Hen45MgoroNWJ6/P1OgR52WB4Dz882skd7V2t+eQ8IqK7xKRUUzRlimEcqaeeAkaOlDoaIiIiIqJWobhSi/T8cqTnVyC9oBzl1TqT+WpLBXydNHBWlGPD288j5vQJBAS0lyhaIqLmj0kpqcXHAzExwMyZ18tkMmD1aslCIiIiIiJqDcq0AnmZxcgorMDlwgoUlmtN5lvIZfB2VMPXSQMfRw1cbJSQyWTIyUiFvrJUoqiJiFoOJqWkotcbbst75x1AqwUCA4HHHpM6KiIiIiKiFkkIgYs5ZTiSko+YU5nwfmUFfr6oBZBtrCOTGQYp93HUwNdJAw97Kyg4NhQRUaNhUkoK6elAeDiwe/f1siVLmJQiIiIiImogOr1AQmYxDifn40hKPg4n5yOvrNo438LeHTIAbnYqeDuoDS9HNVQWCumCJiJqZZiUMrcNG4BXXgEKCw3TMhnw5pvA++9LGhYRERERUXNWqdXh1OUiHEkxJKGOpRSgpKrGpI7KQo5gHwd0cJDh07dfwbR3P4aXj69EERMRUYtJSi1btgwLFy5EVlYWgoKCsHTpUvTu3VvqsK4rKgJeew1Ys+Z6mY8P8N13wMCBkoVFRERERNQcyVTWiEsvxU9J53AkOR+nLhehWqc3qWOjskBPf0f08ndCn7ZOCGxjD5WFAklJSZiXehKWvDWPiEhSLSIptWHDBkREROCrr75Cnz59sHjxYgwePBiJiYlwc3OTOjzgwAFg3DggNfV62fPPA19+CTg6ShcXEREREVEzUVpZg4zCClwpqkBajhY+09dh9q4MkzouNir0buuInn5O6N3WCZ097TgmFBFRE9YiklKLFi3CpEmTMGHCBADAV199he3bt2PlypWYNWtWrfpVVVWoqqoyThcXFzdecEIYBjO/lpCyszMko8aObbxtEhERERE1Y0IIFJRrcaWwwpCIKqxAcaXprXgymRzedpbo18Edvdo6oZe/E/ydNZDJmIQiImoumn1Sqrq6GseOHUNkZKSxTC6XIywsDLGxsbdcZv78+XjvvffME6BMBkRFAcHBQPfuhtv3/PzMs20iIiIiomZApxfIKa3Clb8SUFcKK1Gh1ZnUkQFwtVXBy14NG30p1r3zPH6LP4KAgABpgiYiovvW7JNSubm50Ol0cHd3Nyl3d3fHuXPnbrlMZGQkIiIijNPFxcXw8fFpvCDbtwcOHgQeeABQ8GkeRERERNS6VWj1sPILwulcHQqzLyOruBJanTCpo5DL4GFnBW8HNbwcrOBhb2V8Ml5ORjn0ZYUSRE5ERA2p2Sel7oVKpYJKpTLvRrt1M+/2iIiIiIiaiPyyasNT8ZLzcSS1AGcuF8L9+Xk4nasDUAHA8GQ8r78SUN4OarjaqmAhl0sbOBERNapmn5RycXGBQqFAdna2SXl2djY8PDwkioqIiIiIqHUSQiA9vwJHUvJxNDUfh5PzcTGnrFa9muIctG/jjnaezvByUMPZWsnxoIiIWplmn5RSKpUICQlBTEwMRo4cCQDQ6/WIiYnBtGnTpA2OiIiIiKiF0+kFzmUV42hKAQ6n5ONoSj6yi6tq1evgZoOe/k7o3dYRbijBgz2G48Wo/8HV28H8QRMRUZPQ7JNSABAREYHw8HD07NkTvXv3xuLFi1FWVmZ8Gh8RERERETWMSq0OJ9MLcTS1AIeT83E8tQAlVaZPxrOQyxDYxh69/Z3Q098JPf0c4WitNM5PSkoyd9hERNQEtYik1OjRo5GTk4N3330XWVlZCA4Oxs6dO2sNfk5ERERERPWn1wtcyi1DfHohTqYXIj69EAmZxajRmw5Kbq1UoIefozEJFezjALWSD/ghIqK6tYikFABMmzaNt+sREREREd2H3NIqxKcV4uRlQwIqPr0QJZU1teq52KjQu60jevo5oXdbJ3TysIWFgoOSExHR3WkxSSkiIiIiah7S88txKrMcKu/OyK3QQ1dcCRkAuUwGmQyQAbBQyGEhl8FCIYOlXA65nANgNySdXiAlrwwJmcV/vUpw9koxsoora9VVWcgR6G2PYB8HBPs6IKiNA9o4qjkoORER3TcmpYiIiIjIrNYfScOy3enwGLcQ/0utAVLT77iMXGZIVFnKZbC0kEOhr4Hbs+/hw9+vwOt0BezVlrCzsjT8VFvAXm0JB7USDhpLOGgsYaOyaJVJlOoaPdLyy3EppxTJuWW4lFOGxOwSJGaVoEKrq1VfJgPau9oYElB/vTp62MKSvaCIiKgRMClFRERERGblqFHCx16JS8kpcHD3glxhASEAvRDGnzq9MBm3SC8MCZZqAKg2JFPU7UKw51IJcKnkjtu0VMhgr1bCUWMJR40hWeWoUcLB2pC8ctRYwkHz13zrv5JZaiWUFk07GaPXC+SUVuFKYQUyiypxpbACVworkZJXhks5pUgvqIDupvGfrrGylKOjhx26eNqis6cdunjaoaOHLWytLM28F0RE1FoxKUVEREREZvWPh9phoKceHTo8hvCo/8HV2++W9cRfySmtXqBGp0eNzpCoqq7R42p2FjZ98zHe/WABlDb2KKrQoriixvCzUoviCi0Ky7UoKK9GVY0eWp1AbmkVckur7ipWG5Wh15Wj9bVk1k0JLI0S9mpLqJUKWFkqoLZUwMpSDitLxV8vORQyGWQyGeQy1OqtJYRAVY0eVVo9Kmt0Jj/LqmtQWK5FYXk1Csq1KKyoRmGZYZ8KyqtxpbAS2cWVtQYdv5lGqUA7V2u0dbFBOxdrBLjZoLOnHdq6WEPB2yKJiEhCTEoRERERUZMkkxnGlLJQALA0fZKbslyOsjO/4+mujggICKhzPRXVOmMi51qiqqBci6K/ft5Yfu1nUYUWQgClVTUorapBRmFFA++bYQyt2/ViuhtyGeBhZwVPBzU87a3g5aCGr5MG7Vys0c7VBu52qlZ56yIRETV9TEoRERERUYumViqgVqrh5aCu9zI6vTD0tqq4lqyqRkHZ7RNYlVodKrV6VGp1qNDqUKnVoa58kxCATphWkMsAK0sFVBZyY68rh796ZV273dBRYwl7jRJOGiU87FXwtFfDzVbFJ98REVGzxKQUERERUQu1bNkyLFy4EFlZWQgKCsLSpUvRu3dvqcNqFhRyGRytlXC0VqItrO96eSEEqnV6VGr10OsFxF9lhp+AgGH8LAu5DKq/ElEcTJyIiFobJqWIiIiIWqANGzYgIiICX331Ffr06YPFixdj8ODBSExMhJubm9ThtXgymQwqCwVUFoo7VyYiImql+HUMERERUQu0aNEiTJo0CRMmTECXLl3w1VdfQaPRYOXKlVKHRkRERASAPaUAGLpSA0BxcbHEkRAREVFzc+38QYj7H7C6oVRXV+PYsWOIjIw0lsnlcoSFhSE2NrZW/aqqKlRVXX8qXVFREYDGPTcqKSkBAGSnXURVRdldL1+YkwUAOHv2rHFdd0smk93XcePy9758eno6AOmOv9TbB+6//e93H/KupAEAci8nw0pp2eyWl/pvQOr95/L3t3xTiEHq5a+9h0pKShrl/319z49koimdQUnk8uXL8PHxkToMIiIiasbS09PRpk0bqcMAAFy5cgXe3t74448/EBoaaix/6623sHfvXsTFxZnUnzt3Lt577z1zh0lEREQt3J3Oj9hTCoCXlxfS09Nha2vbKI/LLS4uho+PD9LT02FnZ9fg66e6sf2lx2MgLba/9HgMpNXY7S+EQElJCby8vBp83eYSGRmJiIgI47Rer0dqaiqCg4P5d3sbfF/Xje1TN7ZP3dg+dWP71I3tUzdztU99z4+YlIKhO7s5vtm0s7Pjm0JCbH/p8RhIi+0vPR4DaTVm+9vb2zfKeu+Vi4sLFAoFsrOzTcqzs7Ph4eFRq75KpYJKpTIpk8sNQ4/y77ZubJ+6sX3qxvapG9unbmyfurF96maO9qnP+REHOiciIiJqYZRKJUJCQhATE2Ms0+v1iImJMbmdj4iIiEhK7ClFRERE1AJFREQgPDwcPXv2RO/evbF48WKUlZVhwoQJUodGREREBIBJKbNQqVSYM2dOrW7xZB5sf+nxGEiL7S89HgNptdb2Hz16NHJycvDuu+8iKysLwcHB2LlzJ9zd3eu1fGttt/pi+9SN7VM3tk/d2D51Y/vUje1Tt6bWPnz6HhERERERERERmR3HlCIiIiIiIiIiIrNjUoqIiIiIiIiIiMyOSSkiIiIiIiIiIjI7JqWIiIiIiIiIiMjsmJRqZMuWLYO/vz+srKzQp08fHD58WOqQWqT58+ejV69esLW1hZubG0aOHInExESTOpWVlZg6dSqcnZ1hY2ODUaNGITs7W6KIW74FCxZAJpNhxowZxjIeg8aVkZGBcePGwdnZGWq1GoGBgTh69KhxvhAC7777Ljw9PaFWqxEWFoYLFy5IGHHLotPp8O9//xtt27aFWq1G+/bt8cEHH+DG54nwGDSsffv24YknnoCXlxdkMhm2bNliMr8+7Z2fn4+xY8fCzs4ODg4OmDhxIkpLS824F03DvHnz0K9fP2g0Gjg4ONyyTlpaGoYNGwaNRgM3Nze8+eabqKmpMamzZ88e9OjRAyqVCgEBAVi1alXjBy+B8+fPY8SIEXBxcYGdnR0efPBB7N6926ROfdqrJdu+fTv69OkDtVoNR0dHjBw50mR+a28fAKiqqkJwcDBkMhni4+NN5p06dQoPPfQQrKys4OPjg48//liaIM0sJSUFEydONPlfOmfOHFRXV5vUa63tcw2vMQ14DVh/TfraTFCjWb9+vVAqlWLlypXizz//FJMmTRIODg4iOztb6tBanMGDB4uoqChx5swZER8fL4YOHSp8fX1FaWmpsc4rr7wifHx8RExMjDh69Kjo27ev6Nevn4RRt1yHDx8W/v7+olu3bmL69OnGch6DxpOfny/8/PzE+PHjRVxcnLh06ZLYtWuXSEpKMtZZsGCBsLe3F1u2bBEnT54UTz75pGjbtq2oqKiQMPKWY968ecLZ2Vls27ZNJCcni40bNwobGxuxZMkSYx0eg4a1Y8cOMXv2bLFp0yYBQGzevNlkfn3a+/HHHxdBQUHi0KFDYv/+/SIgIECMGTPGzHsivXfffVcsWrRIRERECHt7+1rza2pqRNeuXUVYWJg4ceKE2LFjh3BxcRGRkZHGOpcuXRIajUZERESIs2fPiqVLlwqFQiF27txpxj0xjw4dOoihQ4eKkydPivPnz4tXX31VaDQakZmZKYSoX3u1ZP/973+Fo6OjWL58uUhMTBR//vmn2LBhg3F+a2+fa15//XUxZMgQAUCcOHHCWF5UVCTc3d3F2LFjxZkzZ8S6deuEWq0WX3/9tXTBmsmvv/4qxo8fL3bt2iUuXrwofv75Z+Hm5iZmzpxprNOa20cIXmPeiNeA9dPUr82YlGpEvXv3FlOnTjVO63Q64eXlJebPny9hVK3D1atXBQCxd+9eIYQQhYWFwtLSUmzcuNFYJyEhQQAQsbGxUoXZIpWUlIgOHTqI6Oho8fDDDxs/+HgMGtfbb78tHnzwwdvO1+v1wsPDQyxcuNBYVlhYKFQqlVi3bp05Qmzxhg0bJl566SWTsqefflqMHTtWCMFj0NhuTkrVp73Pnj0rAIgjR44Y6/z6669CJpOJjIwMs8XelERFRd0yKbVjxw4hl8tFVlaWsWz58uXCzs5OVFVVCSGEeOutt8QDDzxgstzo0aPF4MGDGzVmc8vJyREAxL59+4xlxcXFAoCIjo4WQtSvvVoqrVYrvL29xbfffnvbOq25fa7ZsWOH6NSpk/jzzz9rJaW+/PJL4ejoaNIWb7/9tujYsaMEkUrv448/Fm3btjVOt/b24TXm7fEasLbmcG3G2/caSXV1NY4dO4awsDBjmVwuR1hYGGJjYyWMrHUoKioCADg5OQEAjh07Bq1Wa3I8OnXqBF9fXx6PBjZ16lQMGzbMpK0BHoPGtnXrVvTs2RPPPvss3Nzc0L17d/y///f/jPOTk5ORlZVl0v729vbo06cP27+B9OvXDzExMTh//jwA4OTJkzhw4ACGDBkCgMfA3OrT3rGxsXBwcEDPnj2NdcLCwiCXyxEXF2f2mJuy2NhYBAYGwt3d3Vg2ePBgFBcX488//zTWufmzf/DgwS3u79vZ2RkdO3bEd999h7KyMtTU1ODrr7+Gm5sbQkJCANSvvVqq48ePIyMjA3K5HN27d4enpyeGDBmCM2fOGOu05vYBgOzsbEyaNAlr1qyBRqOpNT82NhYDBgyAUqk0lg0ePBiJiYkoKCgwZ6hNQlFRkfGcHmjd7cNrzLrxGrC25nBtZmHWrbUiubm50Ol0Jv9sAcDd3R3nzp2TKKrWQa/XY8aMGejfvz+6du0KAMjKyoJSqaw1Toa7uzuysrIkiLJlWr9+PY4fP44jR47Umsdj0LguXbqE5cuXIyIiAu+88w6OHDmC119/HUqlEuHh4cY2vtVnEtu/YcyaNQvFxcXo1KkTFAoFdDod5s2bh7FjxwIAj4GZ1ae9s7Ky4ObmZjLfwsICTk5OPCY3ycrKumVbXptXV53i4mJUVFRArVabJ9hGJpPJ8Ntvv2HkyJGwtbWFXC6Hm5sbdu7cCUdHRwD1a6+W6tKlSwCAuXPnYtGiRfD398enn36KgQMH4vz588b3V2ttHyEExo8fj1deeQU9e/ZESkpKrTpZWVlo27atSdmN7XPt76w1SEpKwtKlS/HJJ58Yy1pz+/Aa8/Z4DVhbc7k2Y08panGmTp2KM2fOYP369VKH0qqkp6dj+vTp+OGHH2BlZSV1OK2OXq9Hjx498J///Afdu3fH5MmTMWnSJHz11VdSh9Zq/Pjjj/jhhx+wdu1aHD9+HKtXr8Ynn3yC1atXSx0atVKzZs2CTCar89XaL2JuVN/2EkJg6tSpcHNzw/79+3H48GGMHDkSTzzxBDIzM6XejUZT3/bR6/UAgNmzZ2PUqFEICQlBVFQUZDIZNm7cKPFeNJ76ts/SpUtRUlKCyMhIqUM2q3v5PMrIyMDjjz+OZ599FpMmTZIocmoueA1oqjldm7GnVCNxcXGBQqGoNXp9dnY2PDw8JIqq5Zs2bRq2bduGffv2oU2bNsZyDw8PVFdXo7Cw0CQbzOPRcI4dO4arV6+iR48exjKdTod9+/bhiy++wK5du3gMGpGnpye6dOliUta5c2f89NNPAGBs4+zsbHh6ehrrZGdnIzg42GxxtmRvvvkmZs2aheeffx4AEBgYiNTUVMyfPx/h4eE8BmZWn/b28PDA1atXTZarqalBfn5+i/hcmjlzJsaPH19nnXbt2tVrXR4eHrWe7nTtHOdaW3l4eNzyvMfOzq5Z9JKqb3v9/vvv2LZtGwoKCmBnZwcA+PLLLxEdHY3Vq1dj1qxZ9Wqv5qa+7XMtMXfj/ySVSoV27dohLS0NQP3+npqbu/n7iY2NhUqlMpnXs2dPjB07FqtXr77tewlo+e1zzZUrV/DII4+gX79++Oabb0zqtcT2qS9eY94arwFra07XZkxKNRKlUomQkBDExMQYH4Gr1+sRExODadOmSRtcCySEwGuvvYbNmzdjz549tbr0hoSEwNLSEjExMRg1ahQAIDExEWlpaQgNDZUi5BZn0KBBOH36tEnZhAkT0KlTJ7z99tvw8fHhMWhE/fv3r/UI3PPnz8PPzw8A0LZtW3h4eCAmJsZ4QV5cXIy4uDhMmTLF3OG2SOXl5ZDLTTsgKxQKY68BHgPzqk97h4aGorCwEMeOHTOOBfT7779Dr9ejT58+UoXeYFxdXeHq6tog6woNDcW8efNw9epV4y2P0dHRsLOzMyYfQkNDsWPHDpPloqOjm81nfH3bq7y8HABqvd/lcrnx/V6f9mpu6ts+ISEhUKlUSExMxIMPPggA0Gq1SElJMf5Pas3t8/nnn+PDDz80Tl+5cgWDBw/Ghg0bjJ87oaGhmD17NrRaLSwtLQEY2qdjx47N9ta0u/k8ysjIwCOPPGLsZXfze60ltk998RrTFK8Bb69ZXZuZdVj1Vmb9+vVCpVKJVatWibNnz4rJkycLBwcHkyeNUMOYMmWKsLe3F3v27BGZmZnGV3l5ubHOK6+8Inx9fcXvv/8ujh49KkJDQ0VoaKiEUbd8Nz7hQQgeg8Z0+PBhYWFhIebNmycuXLggfvjhB6HRaMT3339vrLNgwQLh4OAgfv75Z3Hq1CkxYsQI0bZtW1FRUSFh5C1HeHi48Pb2Ftu2bRPJycli06ZNwsXFRbz11lvGOjwGDaukpEScOHFCnDhxQgAQixYtEidOnBCpqalCiPq19+OPPy66d+8u4uLixIEDB0SHDh3EmDFjpNolyaSmpooTJ06I9957T9jY2BjbtaSkRAghRE1Njejatat47LHHRHx8vNi5c6dwdXUVkZGRxnVcunRJaDQa8eabb4qEhASxbNkyoVAoxM6dO6XarUaRk5MjnJ2dxdNPPy3i4+NFYmKieOONN4SlpaWIj48XQtSvvVqy6dOnC29vb7Fr1y5x7tw5MXHiROHm5iby8/OFEGyfGyUnJ9d6+l5hYaFwd3cXL7zwgjhz5oxYv3690Gg04uuvv5YuUDO5fPmyCAgIEIMGDRKXL182Oa+/pjW3jxC8xrwRrwHvTlO9NmNSqpEtXbpU+Pr6CqVSKXr37i0OHTokdUgtEoBbvqKioox1KioqxKuvviocHR2FRqMRTz31lMk/OGp4N3/w8Rg0rl9++UV07dpVqFQq0alTJ/HNN9+YzNfr9eLf//63cHd3FyqVSgwaNEgkJiZKFG3LU1xcLKZPny58fX2FlZWVaNeunZg9e7bJI6t5DBrW7t27b/nZHx4eLoSoX3vn5eWJMWPGCBsbG2FnZycmTJhgTMS0JuHh4bdsy927dxvrpKSkiCFDhgi1Wi1cXFzEzJkzhVarNVnP7t27RXBwsFAqlaJdu3Ym/4dbkiNHjojHHntMODk5CVtbW9G3b1+xY8cOkzr1aa+Wqrq6WsycOVO4ubkJW1tbERYWJs6cOWNSpzW3z41ulZQSQoiTJ0+KBx98UKhUKuHt7S0WLFggTYBmFhUVddvz+hu11va5hteYBrwGvDtN9dpMJoQQZuiQRUREREREREREZMSn7xERERERERERkdkxKUVERERERERERGbHpBQREREREREREZkdk1JERERERERERGR2TEoREREREREREZHZMSlFRERERERERERmx6QUERERERERERGZHZNSRERERERERERkdkxKERHdQCaTYcuWLY26jYEDB2LGjBmNug0iIiJqvcaPH4+RI0capxvi3IPnL0TUGJiUIiJJxMbGQqFQYNiwYXe9rL+/PxYvXtzwQd3BE088gccff/yW8/bv3w+ZTIZTp06ZOSoiIiJqDsaPHw+ZTAaZTAalUomAgAC8//77qKmpafRtb9q0CR988EG96u7ZswcymQyFhYX3vI57lZKSYmyjm1+HDh1q1G0TkTSYlCIiSaxYsQKvvfYa9u3bhytXrkgdTr1MnDgR0dHRuHz5cq15UVFR6NmzJ7p16yZBZERERNQcPP7448jMzMSFCxcwc+ZMzJ07FwsXLrxl3erq6gbbrpOTE2xtbSVfR3399ttvyMzMNHmFhITcsu7t2kmr1d7Ttu91OSK6N0xKEZHZlZaWYsOGDZgyZQqGDRuGVatW1arzyy+/oFevXrCysoKLiwueeuopAIau46mpqfjnP/9p/OYMAObOnYvg4GCTdSxevBj+/v7G6SNHjuD//u//4OLiAnt7ezz88MM4fvx4veMePnw4XF1da8VbWlqKjRs3YuLEicjLy8OYMWPg7e0NjUaDwMBArFu3rs713uqWQQcHB5PtpKen47nnnoODgwOcnJwwYsQIpKSkGOfv2bMHvXv3hrW1NRwcHNC/f3+kpqbWe9+IiIio8alUKnh4eMDPzw9TpkxBWFgYtm7dCuD6LXfz5s2Dl5cXOnbsCODO5wA6nQ4RERFwcHCAs7Mz3nrrLQghTLZ78613VVVVePvtt+Hj4wOVSoWAgACsWLECKSkpeOSRRwAAjo6OkMlkGD9+/C3XUVBQgBdffBGOjo7QaDQYMmQILly4YJy/atUqODg4YNeuXejcuTNsbGyMSbk7cXZ2hoeHh8nL0tISwPVzvm+//RZt27aFlZUVAMP51PLly/Hkk0/C2toa8+bNAwAsX74c7du3h1KpRMeOHbFmzRqTbd1uOSIyDyaliMjsfvzxR3Tq1AkdO3bEuHHjsHLlSpOTp+3bt+Opp57C0KFDceLECcTExKB3794ADF3H27Rpg/fff9/4zVl9lZSUIDw8HAcOHMChQ4fQoUMHDB06FCUlJfVa3sLCAi+++CJWrVplEu/GjRuh0+kwZswYVFZWIiQkBNu3b8eZM2cwefJkvPDCCzh8+HC947yZVqvF4MGDYWtri/379+PgwYPGE7vq6mrU1NRg5MiRePjhh3Hq1CnExsZi8uTJxoQdERERNU1qtdqkp09MTAwSExMRHR2Nbdu23fEcAAA+/fRTrFq1CitXrsSBAweQn5+PzZs317ndF198EevWrcPnn3+OhIQEfP3117CxsYGPjw9++uknAEBiYiIyMzOxZMmSW65j/PjxOHr0KLZu3YrY2FgIITB06FCTnkbl5eX45JNPsGbNGuzbtw9paWl444037rfZkJSUhJ9++gmbNm1CfHy8sXzu3Ll46qmncPr0abz00kvYvHkzpk+fjpkzZ+LMmTN4+eWXMWHCBOzevdtkfTcvR0RmJIiIzKxfv35i8eLFQgghtFqtcHFxEbt37zbODw0NFWPHjr3t8n5+fuKzzz4zKZszZ44ICgoyKfvss8+En5/fbdej0+mEra2t+OWXX4xlAMTmzZtvu0xCQoIAYBLvQw89JMaNG3fbZYYNGyZmzpxpnH744YfF9OnT69ymvb29iIqKEkIIsWbNGtGxY0eh1+uN86uqqoRarRa7du0SeXl5AoDYs2fPbWMgIiIiaYWHh4sRI0YIIYTQ6/UiOjpaqFQq8cYbbxjnu7u7i6qqKuMydzoHEEIIT09P8fHHHxvna7Va0aZNG+O2hDA990hMTBQARHR09C3j3L17twAgCgoKTMpvXMf58+cFAHHw4EHj/NzcXKFWq8WPP/4ohBAiKipKABBJSUnGOsuWLRPu7u63baPk5GQBQKjVamFtbW3yumbOnDnC0tJSXL161WRZAGLGjBkmZf369ROTJk0yKXv22WfF0KFD61yOiMyHPaWIyKwSExNx+PBhjBkzBoCh99Ho0aOxYsUKY534+HgMGjSowbednZ2NSZMmoUOHDrC3t4ednR1KS0uRlpZW73V06tQJ/fr1w8qVKwEYvqnbv38/Jk6cCMDQhf6DDz5AYGAgnJycYGNjg127dt3VNm528uRJJCUlwdbWFjY2NrCxsYGTkxMqKytx8eJFODk5Yfz48Rg8eDCeeOIJLFmy5K56kBEREZF5bNu2DTY2NrCyssKQIUMwevRozJ071zg/MDAQSqXSOH2nc4CioiJkZmaiT58+xmUsLCzQs2fP28YQHx8PhUKBhx9++J73IyEhARYWFibbdXZ2RseOHZGQkGAs02g0aN++vXHa09MTV69eveP6N2zYgPj4eJPXjfz8/ODq6lpruZv3OyEhAf379zcp69+/v0mMt1qOiMzHQuoAiKh1WbFiBWpqauDl5WUsE0JApVLhiy++gL29PdRq9V2vVy6X1xo/4eaBKsPDw5GXl4clS5bAz88PKpUKoaGhdz2Q6MSJE/Haa69h2bJliIqKQvv27Y0ndgsXLsSSJUuwePFiBAYGwtraGjNmzKhzGzKZrM7YS0tLERISgh9++KHWstdOyKKiovD6669j586d2LBhA/71r38hOjoaffv2vat9IyIiosbzyCOPYPny5VAqlfDy8oKFhenlmLW1tcl0fc4B7ta9nGfdq2vjQF1zq3OeW/Hx8UFAQMBt59/cTncqv5N7XY6I7h97ShGR2dTU1OC7777Dp59+avLN18mTJ+Hl5WUcELxbt26IiYm57XqUSiV0Op1JmaurK7KyskxOdG7+Vu3gwYN4/fXXMXToUDzwwANQqVTIzc296/147rnnIJfLsXbtWnz33Xd46aWXjOM3HTx4ECNGjMC4ceMQFBSEdu3a4fz583Wuz9XV1aRn04ULF1BeXm6c7tGjBy5cuAA3NzcEBASYvOzt7Y31unfvjsjISPzxxx/o2rUr1q5de9f7RkRERI3H2toaAQEB8PX1rZWQupU7nQPY29vD09MTcXFxxmVqampw7Nix264zMDAQer0ee/fuveX8az21bj7XulHnzp1RU1Njst28vDwkJiaiS5cud9wvc+ncuTMOHjxoUnbw4MEmFSNRa8ekFBGZzbZt21BQUICJEyeia9euJq9Ro0YZb+GbM2cO1q1bhzlz5iAhIQGnT5/GRx99ZFyPv78/9u3bh4yMDGNSaeDAgcjJycHHH3+MixcvYtmyZfj1119Ntt+hQwesWbMGCQkJiIuLw9ixY+/p20IbGxuMHj0akZGRyMzMND6V5to2oqOj8ccffyAhIQEvv/wysrOz61zfo48+ii+++AInTpzA0aNH8corr5h8szh27Fi4uLhgxIgR2L9/P5KTk7Fnzx68/vrruHz5MpKTkxEZGYnY2Fikpqbif//7Hy5cuIDOnTvf9b4RERFR03GncwAAmD59OhYsWIAtW7bg3LlzePXVV1FYWHjbdfr7+yM8PBwvvfQStmzZYlznjz/+CMBwa5xMJsO2bduQk5OD0tLSWuvo0KEDRowYgUmTJuHAgQM4efIkxo0bB29vb4wYMeK+9zsvLw9ZWVkmr8rKyrtez5tvvolVq1Zh+fLluHDhAhYtWoRNmzY1yGDrRNQwmJQiIrNZsWIFwsLCTHr3XDNq1CgcPXoUp06dwsCBA7Fx40Zs3boVwcHBePTRR02eXvf+++8jJSUF7du3N3Zd79y5M7788kssW7YMQUFBOHz4cK0TjhUrVqCgoAA9evTACy+8gNdffx1ubm73tC8TJ05EQUEBBg8ebHIr4r/+9S/06NEDgwcPxsCBA+Hh4YGRI0fWua5PP/0UPj4+eOihh/D3v/8db7zxBjQajXG+RqPBvn374Ovri6effhqdO3fGxIkTUVlZCTs7O2g0Gpw7dw6jRo3C3/72N0yePBlTp07Fyy+/fE/7RkRERE3Dnc4BAGDmzJl44YUXEB4ejtDQUNja2uKpp56qc73Lly/HM888g1dffRWdOnXCpEmTUFZWBgDw9vbGe++9h1mzZsHd3R3Tpk275TqioqIQEhKC4cOHIzQ0FEII7Nixo9Yte/ciLCwMnp6eJq8tW7bc9XpGjhyJJUuW4JNPPsEDDzyAr7/+GlFRURg4cOB9x0hEDUMm6nNTLxERERERERERUQNiTykiIiIiIiIiIjI7JqWIiIiIiIiIiMjsmJQiIiIiIiIiIiKzY1KKiIiIiIiIiIjMjkkpIiIiIiIiIiIyOyaliIiIiIiIiIjI7JiUIiIiIiIiIiIis2NSioiIiIiIiIiIzI5JKSIiIiIiIiIiMjsmpYiIiIiIiIiIyOyYlCIiIiIiIiIiIrP7/195PE/xqDvIAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_val' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-950d21321ce1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;31m# Сравнение первых 20 образцов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m \u001b[0msample_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_val_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Base Predicted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_val' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import(Dense, Conv1D, MaxPooling1D, Flatten,\n",
        "                                    Dropout, BatchNormalization, LSTM)\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import L2 as l2\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.metrics import(mean_absolute_error, median_absolute_error,\n",
        "                            r2_score, mean_squared_error)\n",
        "from sklearn.preprocessing import QuantileTransformer, OneHotEncoder, StandardScaler, RobustScaler, MaxAbsScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import ADASYN  # Заменяем SMOTE на ADASYN\n",
        "\n",
        "train_df = pd.read_excel('/content/big_train_no_duples.xlsx')\n",
        "\n",
        "X = train_df.drop(columns=['mass'])\n",
        "y = train_df['mass']\n",
        "\n",
        "def polynomial_decay_schedule(epoch, lr):\n",
        "    power = 1.0\n",
        "    max_epochs = 200\n",
        "    return 3e-4 * (1 - epoch / max_epochs) ** power\n",
        "\n",
        "#bins = [-1, 5, 20, 40, 70, 90, 99, 110]\n",
        "quantiles = [0, 0.25, 0.5, 0.75, 1]\n",
        "bins = [-1] + [y.quantile(q) for q in quantiles]\n",
        "y_binned = pd.cut(y, bins=bins, labels=False, duplicates='drop')\n",
        "\n",
        "numerical_cols = ['% second component', 'day', 'ph']\n",
        "categorical_cols = ['type of pha', 'environment', 'form', 'dimensionality',\n",
        "                    'porosity', 'in vivo', 'enzymatic', 'form_type', 'environment_type']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('custom', StandardScaler())\n",
        "    ]), numerical_cols),\n",
        "        ('cat', Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ]), categorical_cols)\n",
        "])\n",
        "\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test, y_train_binned, y_test_binned = train_test_split(\n",
        "    X_preprocessed, y, y_binned,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_binned,\n",
        ")\n",
        "\n",
        "adasyn = ADASYN(sampling_strategy='minority',  # Балансировать все классы\n",
        "                n_neighbors=3,  # Количество соседей для генерации (аналог k_neighbors в SMOTE)\n",
        "                random_state=42)\n",
        "\n",
        "X_train_resampled, y_train_resampled_binned = adasyn.fit_resample(X_train, y_train_binned)\n",
        "\n",
        "bin_centers = []\n",
        "for i in range(len(bins) - 1):\n",
        "    # Получаем все значения y в текущем бине\n",
        "    lower = bins[i]\n",
        "    upper = bins[i + 1]\n",
        "    median_val = (lower + upper) / 2\n",
        "    bin_centers.append(median_val)\n",
        "y_train_resampled = np.array([bin_centers[int(cls)] for cls in y_train_resampled_binned])\n",
        "\n",
        "# Compute sample weights for the resampled training data\n",
        "sample_weights = compute_sample_weight(\n",
        "    class_weight='balanced',\n",
        "    y=y_train_resampled_binned\n",
        ")\n",
        "\n",
        "X_train_processed = X_train_resampled\n",
        "X_test_processed = X_test\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "X_train_3d = np.expand_dims(X_train_processed, axis=1)\n",
        "X_test_3d = np.expand_dims(X_test_processed, axis=1)\n",
        "\n",
        "def create_cnn_model(input_shape, architecture='medium'):\n",
        "    model = Sequential()\n",
        "    if architecture == 'simple':\n",
        "        model.add(Conv1D(32, 1, activation='relu', input_shape=input_shape))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(1))\n",
        "    elif architecture == 'medium':\n",
        "        model.add(Conv1D(64, 1, activation='relu', input_shape=input_shape))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv1D(128, 1, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(1))\n",
        "    elif architecture == 'complex':\n",
        "        model.add(Conv1D(64, 1, activation='relu', input_shape=input_shape))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv1D(128, 1, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv1D(256, 1, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(256, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(Dropout(0.4))\n",
        "        model.add(Dense(128, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(1))\n",
        "    optimizer = RMSprop(learning_rate=3e-4, rho=0.9)\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "models_to_test = {\n",
        "    'CNN_simple': lambda: create_cnn_model((X_train_3d.shape[1], X_train_3d.shape[2]), 'simple'),\n",
        "    'CNN_medium': lambda: create_cnn_model((X_train_3d.shape[1], X_train_3d.shape[2]), 'medium'),\n",
        "    'CNN_complex': lambda: create_cnn_model((X_train_3d.shape[1], X_train_3d.shape[2]), 'complex')\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for model_name, model_creator in models_to_test.items():\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "       #ReduceLROnPlateau(factor=0.1, patience=5, threshold=0.01, cooldown=0, min_lr=1e-6),\n",
        "        LearningRateScheduler(polynomial_decay_schedule),\n",
        "\n",
        "    ]\n",
        "\n",
        "    model = model_creator()\n",
        "\n",
        "    train_data = X_train_3d\n",
        "    test_data = X_test_3d\n",
        "\n",
        "    history = model.fit(\n",
        "        train_data, y_train_resampled,  # Use the resampled y_train\n",
        "        validation_data=(test_data, y_test),\n",
        "        epochs=200,\n",
        "        batch_size=64,\n",
        "        callbacks=callbacks,\n",
        "        sample_weight=sample_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    val_df = pd.read_excel('/content/final_test.xlsx')\n",
        "\n",
        "    X_val = val_df.drop(columns=['mass'])\n",
        "    y_val = val_df['mass']\n",
        "    X_val_preprocessed = preprocessor.transform(X_val)\n",
        "    val_data = np.expand_dims(X_val_preprocessed, axis=1)\n",
        "\n",
        "    y_pred_train = model.predict(train_data).flatten()\n",
        "    y_pred_test = model.predict(test_data).flatten()\n",
        "    y_pred_val = model.predict(val_data).flatten()\n",
        "\n",
        "    metrics = {\n",
        "        'MAE_train': mean_absolute_error(y_train_resampled, y_pred_train),\n",
        "        'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
        "        'MAE_val': mean_absolute_error(y_val, y_pred_val),\n",
        "        'MedAE_train': median_absolute_error(y_train_resampled, y_pred_train),\n",
        "        'MedAE_test': median_absolute_error(y_test, y_pred_test),\n",
        "        'MedAE_val': median_absolute_error(y_val, y_pred_val),\n",
        "        'R2_train': r2_score(y_train_resampled, y_pred_train),\n",
        "        'R2_test': r2_score(y_test, y_pred_test),\n",
        "        'R2_val': r2_score(y_val, y_pred_val),\n",
        "        'RMSE_train': rmse(y_train_resampled, y_pred_train),\n",
        "        'RMSE_test': rmse(y_test, y_pred_test),\n",
        "        'RMSE_val': rmse(y_val, y_pred_val),\n",
        "        'history': history\n",
        "    }\n",
        "    results[model_name] = metrics\n",
        "\n",
        "    print(f\"\\nResults for {model_name} model:\")\n",
        "    print(f\"{'Метрика':<15}{'Обучающая':<15}{'Тестовая':<15}{'Диссертация':<15}\")\n",
        "    print(f\"{'MAE':<15}{metrics['MAE_train']:.4f}{'':<5}{metrics['MAE_test']:.4f}{'':<5}{metrics['MAE_val']:.4f}\")\n",
        "    print(f\"{'MedAE':<15}{metrics['MedAE_train']:.4f}{'':<5}{metrics['MedAE_test']:.4f}{'':<5}{metrics['MedAE_val']:.4f}\")\n",
        "    print(f\"{'R²':<15}{metrics['R2_train']:.4f}{'':<5}{metrics['R2_test']:.4f}{'':<5}{metrics['R2_val']:.4f}{'':<5}\")\n",
        "    print(f\"{'RMSE':<15}{metrics['RMSE_train']:.4f}{'':<5}{metrics['RMSE_test']:.4f}{'':<5}{metrics['RMSE_val']:.4f}\")\n",
        "\n",
        "print(\"\\nСравнение моделей:\")\n",
        "print(f\"{'Модель':<15}{'MAE (test)':<15}{'MedAE (test)':<15}{'R² (test)':<15}{'RMSE (test)':<15}\")\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name:<15}{metrics['MAE_val']:.4f}{'':<5}{metrics['MedAE_val']:.4f}{'':<5}{metrics['R2_val']:.4f}{'':<5}{metrics['RMSE_val']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uz4TxxPYnxp",
        "outputId": "ab3a1c01-bc9b-4cdf-c065-1dd0e96f8020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 4324.8267 - mae: 54.7854 - val_loss: 5630.1943 - val_mae: 68.4604 - learning_rate: 3.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4373.5176 - mae: 56.1736 - val_loss: 5601.2622 - val_mae: 68.2603 - learning_rate: 2.9850e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3674.8347 - mae: 50.2752 - val_loss: 5557.8916 - val_mae: 67.9690 - learning_rate: 2.9700e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3547.2229 - mae: 49.8060 - val_loss: 5507.4849 - val_mae: 67.6310 - learning_rate: 2.9550e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2863.2498 - mae: 43.8589 - val_loss: 5435.9414 - val_mae: 67.1502 - learning_rate: 2.9400e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2605.7273 - mae: 41.8157 - val_loss: 5342.8984 - val_mae: 66.5188 - learning_rate: 2.9250e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2305.5154 - mae: 39.1738 - val_loss: 5230.8916 - val_mae: 65.7561 - learning_rate: 2.9100e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2046.3191 - mae: 37.1713 - val_loss: 5084.7681 - val_mae: 64.7530 - learning_rate: 2.8950e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1548.9484 - mae: 32.1714 - val_loss: 4913.1143 - val_mae: 63.5742 - learning_rate: 2.8800e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1158.1429 - mae: 27.7695 - val_loss: 4723.8140 - val_mae: 62.2505 - learning_rate: 2.8650e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 889.5905 - mae: 24.0638 - val_loss: 4521.4902 - val_mae: 60.7894 - learning_rate: 2.8500e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 645.1702 - mae: 20.3800 - val_loss: 4324.1309 - val_mae: 59.3608 - learning_rate: 2.8350e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 559.0422 - mae: 19.2373 - val_loss: 4104.8276 - val_mae: 57.7677 - learning_rate: 2.8200e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 444.2695 - mae: 17.0173 - val_loss: 3879.7361 - val_mae: 56.1180 - learning_rate: 2.8050e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 317.9523 - mae: 14.2515 - val_loss: 3732.3730 - val_mae: 55.0334 - learning_rate: 2.7900e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 437.8214 - mae: 16.1779 - val_loss: 3596.1064 - val_mae: 54.0062 - learning_rate: 2.7750e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 297.2010 - mae: 13.9370 - val_loss: 3414.5359 - val_mae: 52.6331 - learning_rate: 2.7600e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 359.1064 - mae: 15.0024 - val_loss: 3292.2129 - val_mae: 51.6977 - learning_rate: 2.7450e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 359.6392 - mae: 14.9799 - val_loss: 3281.2227 - val_mae: 51.6254 - learning_rate: 2.7300e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 285.0374 - mae: 13.8205 - val_loss: 3208.9475 - val_mae: 51.0835 - learning_rate: 2.7150e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 250.4307 - mae: 12.7642 - val_loss: 3113.9692 - val_mae: 50.3242 - learning_rate: 2.7000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 257.4075 - mae: 12.3422 - val_loss: 3009.0876 - val_mae: 49.4859 - learning_rate: 2.6850e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 197.5479 - mae: 10.9476 - val_loss: 2925.6052 - val_mae: 48.8152 - learning_rate: 2.6700e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 286.0689 - mae: 13.1864 - val_loss: 2736.5911 - val_mae: 47.2012 - learning_rate: 2.6550e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 236.8114 - mae: 12.1672 - val_loss: 2845.9868 - val_mae: 48.1511 - learning_rate: 2.6400e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 227.2431 - mae: 12.1631 - val_loss: 2670.6018 - val_mae: 46.6275 - learning_rate: 2.6250e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 219.2345 - mae: 11.2648 - val_loss: 2597.8723 - val_mae: 45.9871 - learning_rate: 2.6100e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 205.9896 - mae: 11.1304 - val_loss: 2450.7083 - val_mae: 44.6568 - learning_rate: 2.5950e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 210.9067 - mae: 11.2650 - val_loss: 2414.8486 - val_mae: 44.3482 - learning_rate: 2.5800e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 237.8339 - mae: 11.5770 - val_loss: 2299.1418 - val_mae: 43.2344 - learning_rate: 2.5650e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 192.4899 - mae: 10.6244 - val_loss: 2206.0757 - val_mae: 42.3299 - learning_rate: 2.5500e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 173.5886 - mae: 9.9722 - val_loss: 2084.2834 - val_mae: 41.1342 - learning_rate: 2.5350e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 182.7951 - mae: 10.8966 - val_loss: 1961.8479 - val_mae: 39.9395 - learning_rate: 2.5200e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 237.6467 - mae: 11.6807 - val_loss: 1956.2260 - val_mae: 39.9033 - learning_rate: 2.5050e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 163.2040 - mae: 9.9524 - val_loss: 1826.8972 - val_mae: 38.5312 - learning_rate: 2.4900e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 174.9131 - mae: 9.7436 - val_loss: 1845.7488 - val_mae: 38.8287 - learning_rate: 2.4750e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 198.5460 - mae: 10.7077 - val_loss: 1764.2236 - val_mae: 37.9417 - learning_rate: 2.4600e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 143.0547 - mae: 9.4671 - val_loss: 1718.5217 - val_mae: 37.4738 - learning_rate: 2.4450e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 196.8113 - mae: 10.7562 - val_loss: 1647.2178 - val_mae: 36.7034 - learning_rate: 2.4300e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 173.9651 - mae: 10.2033 - val_loss: 1657.0717 - val_mae: 36.7248 - learning_rate: 2.4150e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 161.7877 - mae: 10.0412 - val_loss: 1561.9282 - val_mae: 35.6616 - learning_rate: 2.4000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 164.9280 - mae: 9.4141 - val_loss: 1474.6519 - val_mae: 34.5910 - learning_rate: 2.3850e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 148.2451 - mae: 9.3822 - val_loss: 1522.9148 - val_mae: 35.1702 - learning_rate: 2.3700e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 168.2532 - mae: 9.8378 - val_loss: 1407.2550 - val_mae: 33.7334 - learning_rate: 2.3550e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 187.4280 - mae: 10.6216 - val_loss: 1308.7018 - val_mae: 32.4971 - learning_rate: 2.3400e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 210.4690 - mae: 10.9216 - val_loss: 1235.3905 - val_mae: 31.5529 - learning_rate: 2.3250e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 166.2490 - mae: 9.7780 - val_loss: 1290.8369 - val_mae: 32.4087 - learning_rate: 2.3100e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 192.1083 - mae: 10.6623 - val_loss: 1171.7306 - val_mae: 30.8313 - learning_rate: 2.2950e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 179.8412 - mae: 9.7989 - val_loss: 1104.2588 - val_mae: 29.8817 - learning_rate: 2.2800e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 179.3790 - mae: 10.3079 - val_loss: 1112.9727 - val_mae: 29.9940 - learning_rate: 2.2650e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 189.3376 - mae: 10.5319 - val_loss: 1120.7384 - val_mae: 30.0984 - learning_rate: 2.2500e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 119.5764 - mae: 8.3408 - val_loss: 988.9873 - val_mae: 28.0104 - learning_rate: 2.2350e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 141.8827 - mae: 8.8167 - val_loss: 1015.7609 - val_mae: 28.4071 - learning_rate: 2.2200e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 151.2169 - mae: 9.1023 - val_loss: 931.7681 - val_mae: 27.0449 - learning_rate: 2.2050e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 158.0858 - mae: 9.4122 - val_loss: 840.9757 - val_mae: 25.5428 - learning_rate: 2.1900e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 157.6384 - mae: 9.4635 - val_loss: 884.1229 - val_mae: 26.4545 - learning_rate: 2.1750e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 173.7303 - mae: 9.7392 - val_loss: 786.7914 - val_mae: 24.7369 - learning_rate: 2.1600e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 147.0612 - mae: 9.0239 - val_loss: 751.7226 - val_mae: 24.0328 - learning_rate: 2.1450e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 169.5793 - mae: 9.4217 - val_loss: 800.2698 - val_mae: 25.0012 - learning_rate: 2.1300e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 157.1833 - mae: 9.1887 - val_loss: 813.9992 - val_mae: 25.2269 - learning_rate: 2.1150e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 156.2544 - mae: 9.3376 - val_loss: 864.3678 - val_mae: 26.2045 - learning_rate: 2.1000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 153.0435 - mae: 9.0899 - val_loss: 886.7748 - val_mae: 26.6304 - learning_rate: 2.0850e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 175.3882 - mae: 9.9137 - val_loss: 824.0438 - val_mae: 25.5611 - learning_rate: 2.0700e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 154.8973 - mae: 9.1836 - val_loss: 689.7205 - val_mae: 22.9995 - learning_rate: 2.0550e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 126.7951 - mae: 8.7079 - val_loss: 637.1921 - val_mae: 21.8181 - learning_rate: 2.0400e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 158.4032 - mae: 9.4607 - val_loss: 618.5555 - val_mae: 21.3034 - learning_rate: 2.0250e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 152.2690 - mae: 9.2862 - val_loss: 585.9396 - val_mae: 20.4560 - learning_rate: 2.0100e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 120.9646 - mae: 8.0279 - val_loss: 582.8205 - val_mae: 20.3559 - learning_rate: 1.9950e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 141.3015 - mae: 8.8157 - val_loss: 568.8835 - val_mae: 20.1033 - learning_rate: 1.9800e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 141.1777 - mae: 8.2737 - val_loss: 554.2829 - val_mae: 19.8125 - learning_rate: 1.9650e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 126.6416 - mae: 8.2949 - val_loss: 553.8086 - val_mae: 19.8561 - learning_rate: 1.9500e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 144.7977 - mae: 8.7940 - val_loss: 524.1184 - val_mae: 19.0326 - learning_rate: 1.9350e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 150.7177 - mae: 9.0658 - val_loss: 562.4704 - val_mae: 20.0452 - learning_rate: 1.9200e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 125.4163 - mae: 8.1584 - val_loss: 564.0648 - val_mae: 20.1428 - learning_rate: 1.9050e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 147.3313 - mae: 8.8208 - val_loss: 506.8976 - val_mae: 18.5952 - learning_rate: 1.8900e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 166.7850 - mae: 9.4727 - val_loss: 534.2209 - val_mae: 19.3056 - learning_rate: 1.8750e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 137.7594 - mae: 8.3652 - val_loss: 558.2330 - val_mae: 19.9835 - learning_rate: 1.8600e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 133.6590 - mae: 8.7914 - val_loss: 503.8201 - val_mae: 18.4028 - learning_rate: 1.8450e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 153.8507 - mae: 9.0605 - val_loss: 441.5902 - val_mae: 16.5256 - learning_rate: 1.8300e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 123.4599 - mae: 8.1922 - val_loss: 400.0136 - val_mae: 14.9003 - learning_rate: 1.8150e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 151.9337 - mae: 9.0098 - val_loss: 401.9055 - val_mae: 14.8854 - learning_rate: 1.8000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 140.2291 - mae: 8.3395 - val_loss: 392.4522 - val_mae: 14.6268 - learning_rate: 1.7850e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 122.4637 - mae: 7.9878 - val_loss: 435.7485 - val_mae: 16.3139 - learning_rate: 1.7700e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 128.8779 - mae: 8.0629 - val_loss: 409.9720 - val_mae: 15.0843 - learning_rate: 1.7550e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 134.0706 - mae: 8.4226 - val_loss: 374.2368 - val_mae: 13.6322 - learning_rate: 1.7400e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 115.2017 - mae: 7.5472 - val_loss: 373.5684 - val_mae: 13.3180 - learning_rate: 1.7250e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 140.5556 - mae: 8.9800 - val_loss: 378.2492 - val_mae: 13.4643 - learning_rate: 1.7100e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 125.5457 - mae: 8.1408 - val_loss: 375.3916 - val_mae: 13.5806 - learning_rate: 1.6950e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 121.3613 - mae: 7.9527 - val_loss: 366.1027 - val_mae: 13.1049 - learning_rate: 1.6800e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 144.2497 - mae: 8.5534 - val_loss: 358.6679 - val_mae: 12.8813 - learning_rate: 1.6650e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 131.7639 - mae: 8.4623 - val_loss: 351.6818 - val_mae: 12.5007 - learning_rate: 1.6500e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 139.3618 - mae: 8.8049 - val_loss: 356.9088 - val_mae: 13.0402 - learning_rate: 1.6350e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 175.3980 - mae: 9.8037 - val_loss: 353.5313 - val_mae: 12.9106 - learning_rate: 1.6200e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 129.9021 - mae: 8.1042 - val_loss: 342.5239 - val_mae: 12.6138 - learning_rate: 1.6050e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 117.1087 - mae: 7.6803 - val_loss: 335.5789 - val_mae: 12.2170 - learning_rate: 1.5900e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 149.3047 - mae: 9.2899 - val_loss: 332.0375 - val_mae: 12.0949 - learning_rate: 1.5750e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 124.3475 - mae: 8.0266 - val_loss: 335.3214 - val_mae: 12.0766 - learning_rate: 1.5600e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 118.6639 - mae: 7.8199 - val_loss: 334.5366 - val_mae: 11.8928 - learning_rate: 1.5450e-04\n",
            "Epoch 99/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 120.0149 - mae: 7.9718 - val_loss: 340.4968 - val_mae: 11.9674 - learning_rate: 1.5300e-04\n",
            "Epoch 100/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 124.0310 - mae: 8.1877 - val_loss: 344.5703 - val_mae: 12.5407 - learning_rate: 1.5150e-04\n",
            "Epoch 101/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 135.0755 - mae: 8.3287 - val_loss: 339.4128 - val_mae: 12.5078 - learning_rate: 1.5000e-04\n",
            "Epoch 102/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 127.1801 - mae: 8.1608 - val_loss: 330.2191 - val_mae: 12.2868 - learning_rate: 1.4850e-04\n",
            "Epoch 103/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 95.2974 - mae: 7.0511 - val_loss: 334.3085 - val_mae: 12.2818 - learning_rate: 1.4700e-04\n",
            "Epoch 104/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 123.6290 - mae: 8.3723 - val_loss: 333.4099 - val_mae: 12.2732 - learning_rate: 1.4550e-04\n",
            "Epoch 105/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 127.3193 - mae: 8.3220 - val_loss: 326.9627 - val_mae: 11.7843 - learning_rate: 1.4400e-04\n",
            "Epoch 106/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 163.9871 - mae: 9.3035 - val_loss: 321.1588 - val_mae: 11.6295 - learning_rate: 1.4250e-04\n",
            "Epoch 107/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 126.6016 - mae: 8.4092 - val_loss: 331.2911 - val_mae: 11.9556 - learning_rate: 1.4100e-04\n",
            "Epoch 108/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 157.0432 - mae: 8.8129 - val_loss: 337.3165 - val_mae: 12.3494 - learning_rate: 1.3950e-04\n",
            "Epoch 109/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 129.5827 - mae: 8.3119 - val_loss: 338.2625 - val_mae: 12.5528 - learning_rate: 1.3800e-04\n",
            "Epoch 110/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 121.6249 - mae: 8.3321 - val_loss: 330.3008 - val_mae: 11.9582 - learning_rate: 1.3650e-04\n",
            "Epoch 111/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 124.3143 - mae: 8.3199 - val_loss: 337.6322 - val_mae: 12.1388 - learning_rate: 1.3500e-04\n",
            "Epoch 112/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 134.2837 - mae: 8.4485 - val_loss: 350.1403 - val_mae: 11.9390 - learning_rate: 1.3350e-04\n",
            "Epoch 113/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 98.8016 - mae: 7.2253 - val_loss: 339.4659 - val_mae: 11.7003 - learning_rate: 1.3200e-04\n",
            "Epoch 114/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 132.6659 - mae: 8.2772 - val_loss: 338.9544 - val_mae: 11.4397 - learning_rate: 1.3050e-04\n",
            "Epoch 115/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 130.2971 - mae: 8.1727 - val_loss: 332.1534 - val_mae: 11.6576 - learning_rate: 1.2900e-04\n",
            "Epoch 116/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 135.6154 - mae: 8.5092 - val_loss: 329.3723 - val_mae: 11.1473 - learning_rate: 1.2750e-04\n",
            "Epoch 117/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 143.3934 - mae: 8.5080 - val_loss: 336.4622 - val_mae: 11.1073 - learning_rate: 1.2600e-04\n",
            "Epoch 118/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 129.3303 - mae: 8.2965 - val_loss: 330.8841 - val_mae: 11.2674 - learning_rate: 1.2450e-04\n",
            "Epoch 119/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 93.9587 - mae: 6.7724 - val_loss: 332.8242 - val_mae: 11.4811 - learning_rate: 1.2300e-04\n",
            "Epoch 120/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 114.6708 - mae: 7.7886 - val_loss: 331.2276 - val_mae: 11.2316 - learning_rate: 1.2150e-04\n",
            "Epoch 121/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 113.1490 - mae: 7.8237 - val_loss: 336.6218 - val_mae: 11.1466 - learning_rate: 1.2000e-04\n",
            "Epoch 122/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 167.1305 - mae: 8.8635 - val_loss: 331.9831 - val_mae: 11.1121 - learning_rate: 1.1850e-04\n",
            "Epoch 123/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 124.7962 - mae: 8.1237 - val_loss: 332.8841 - val_mae: 11.0974 - learning_rate: 1.1700e-04\n",
            "Epoch 124/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 127.2902 - mae: 8.0606 - val_loss: 336.8040 - val_mae: 11.3573 - learning_rate: 1.1550e-04\n",
            "Epoch 125/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 130.2843 - mae: 8.4870 - val_loss: 345.6035 - val_mae: 11.5363 - learning_rate: 1.1400e-04\n",
            "Epoch 126/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 138.6410 - mae: 8.7277 - val_loss: 347.7247 - val_mae: 11.7793 - learning_rate: 1.1250e-04\n",
            "Epoch 127/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 120.6231 - mae: 8.2502 - val_loss: 349.7646 - val_mae: 11.6211 - learning_rate: 1.1100e-04\n",
            "Epoch 128/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 124.4730 - mae: 8.2081 - val_loss: 347.0833 - val_mae: 11.6019 - learning_rate: 1.0950e-04\n",
            "Epoch 129/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 194.2854 - mae: 10.4190 - val_loss: 350.6283 - val_mae: 11.7178 - learning_rate: 1.0800e-04\n",
            "Epoch 130/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 142.3986 - mae: 8.9488 - val_loss: 348.8781 - val_mae: 11.5908 - learning_rate: 1.0650e-04\n",
            "Epoch 131/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 96.3260 - mae: 7.1989 - val_loss: 344.5338 - val_mae: 11.5656 - learning_rate: 1.0500e-04\n",
            "Epoch 132/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 104.6335 - mae: 7.4156 - val_loss: 347.7042 - val_mae: 11.6015 - learning_rate: 1.0350e-04\n",
            "Epoch 133/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 147.0905 - mae: 8.9056 - val_loss: 348.2704 - val_mae: 11.5880 - learning_rate: 1.0200e-04\n",
            "Epoch 134/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 123.1632 - mae: 8.3795 - val_loss: 347.5379 - val_mae: 11.6495 - learning_rate: 1.0050e-04\n",
            "Epoch 135/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 115.8575 - mae: 7.8069 - val_loss: 348.9637 - val_mae: 11.5366 - learning_rate: 9.9000e-05\n",
            "Epoch 136/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 135.0444 - mae: 8.4676 - val_loss: 351.2058 - val_mae: 11.6639 - learning_rate: 9.7500e-05\n",
            "Epoch 137/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 119.6031 - mae: 8.0130 - val_loss: 349.9251 - val_mae: 11.6077 - learning_rate: 9.6000e-05\n",
            "Epoch 138/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 102.9705 - mae: 7.0417 - val_loss: 354.9697 - val_mae: 11.7793 - learning_rate: 9.4500e-05\n",
            "Epoch 139/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 119.7685 - mae: 8.1131 - val_loss: 349.0655 - val_mae: 11.8487 - learning_rate: 9.3000e-05\n",
            "Epoch 140/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 109.5400 - mae: 7.9552 - val_loss: 346.7582 - val_mae: 11.7494 - learning_rate: 9.1500e-05\n",
            "Epoch 141/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 135.3475 - mae: 8.4321 - val_loss: 348.6295 - val_mae: 11.7667 - learning_rate: 9.0000e-05\n",
            "Epoch 142/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 111.3831 - mae: 7.5309 - val_loss: 342.8519 - val_mae: 11.4959 - learning_rate: 8.8500e-05\n",
            "Epoch 143/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 175.7467 - mae: 9.4886 - val_loss: 346.8448 - val_mae: 11.5665 - learning_rate: 8.7000e-05\n",
            "Epoch 144/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 143.5566 - mae: 8.8160 - val_loss: 352.0740 - val_mae: 11.4885 - learning_rate: 8.5500e-05\n",
            "Epoch 145/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 122.5485 - mae: 7.7209 - val_loss: 352.9366 - val_mae: 11.6010 - learning_rate: 8.4000e-05\n",
            "Epoch 146/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 121.7414 - mae: 7.8471 - val_loss: 353.1421 - val_mae: 11.6591 - learning_rate: 8.2500e-05\n",
            "Epoch 147/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 136.3072 - mae: 8.4798 - val_loss: 358.1006 - val_mae: 11.7706 - learning_rate: 8.1000e-05\n",
            "Epoch 148/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 123.1002 - mae: 8.3769 - val_loss: 355.5980 - val_mae: 11.7084 - learning_rate: 7.9500e-05\n",
            "Epoch 149/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 100.5458 - mae: 7.1585 - val_loss: 351.4284 - val_mae: 11.5816 - learning_rate: 7.8000e-05\n",
            "Epoch 150/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 110.7445 - mae: 7.6662 - val_loss: 348.9783 - val_mae: 11.5568 - learning_rate: 7.6500e-05\n",
            "Epoch 151/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 114.3947 - mae: 7.8089 - val_loss: 351.9738 - val_mae: 11.6354 - learning_rate: 7.5000e-05\n",
            "Epoch 152/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 118.6675 - mae: 8.0600 - val_loss: 353.5109 - val_mae: 11.5824 - learning_rate: 7.3500e-05\n",
            "Epoch 153/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 96.0861 - mae: 7.0129 - val_loss: 353.5350 - val_mae: 11.5537 - learning_rate: 7.2000e-05\n",
            "Epoch 154/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 120.8241 - mae: 8.1291 - val_loss: 353.2435 - val_mae: 11.5601 - learning_rate: 7.0500e-05\n",
            "Epoch 155/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 125.0954 - mae: 8.3325 - val_loss: 351.8913 - val_mae: 11.4750 - learning_rate: 6.9000e-05\n",
            "Epoch 156/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 111.9363 - mae: 7.6552 - val_loss: 360.3373 - val_mae: 11.5587 - learning_rate: 6.7500e-05\n",
            "Epoch 157/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 121.6069 - mae: 7.6562 - val_loss: 359.0948 - val_mae: 11.4069 - learning_rate: 6.6000e-05\n",
            "Epoch 158/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 151.6198 - mae: 8.9780 - val_loss: 358.5438 - val_mae: 11.5457 - learning_rate: 6.4500e-05\n",
            "Epoch 159/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 110.9886 - mae: 7.5250 - val_loss: 354.1039 - val_mae: 11.5048 - learning_rate: 6.3000e-05\n",
            "Epoch 160/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 93.1168 - mae: 7.3236 - val_loss: 357.0121 - val_mae: 11.6064 - learning_rate: 6.1500e-05\n",
            "Epoch 161/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 109.3138 - mae: 7.6153 - val_loss: 352.2799 - val_mae: 11.4005 - learning_rate: 6.0000e-05\n",
            "Epoch 162/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 115.8158 - mae: 7.7005 - val_loss: 354.1715 - val_mae: 11.4447 - learning_rate: 5.8500e-05\n",
            "Epoch 163/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 94.7844 - mae: 7.1600 - val_loss: 357.8607 - val_mae: 11.5986 - learning_rate: 5.7000e-05\n",
            "Epoch 164/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 126.7425 - mae: 8.3145 - val_loss: 354.2560 - val_mae: 11.5000 - learning_rate: 5.5500e-05\n",
            "Epoch 165/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 144.0216 - mae: 8.6044 - val_loss: 358.6780 - val_mae: 11.6641 - learning_rate: 5.4000e-05\n",
            "Epoch 166/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 106.9649 - mae: 7.3251 - val_loss: 357.4529 - val_mae: 11.5379 - learning_rate: 5.2500e-05\n",
            "Epoch 167/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 110.1117 - mae: 7.9019 - val_loss: 356.7265 - val_mae: 11.5209 - learning_rate: 5.1000e-05\n",
            "Epoch 168/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 133.6958 - mae: 8.6414 - val_loss: 355.3169 - val_mae: 11.4357 - learning_rate: 4.9500e-05\n",
            "Epoch 169/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 125.6870 - mae: 8.3098 - val_loss: 351.6091 - val_mae: 11.4011 - learning_rate: 4.8000e-05\n",
            "Epoch 170/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 147.0398 - mae: 8.5460 - val_loss: 351.1096 - val_mae: 11.4316 - learning_rate: 4.6500e-05\n",
            "Epoch 171/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 102.8457 - mae: 7.4025 - val_loss: 351.1961 - val_mae: 11.4613 - learning_rate: 4.5000e-05\n",
            "Epoch 172/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 125.3711 - mae: 8.1264 - val_loss: 354.8815 - val_mae: 11.5704 - learning_rate: 4.3500e-05\n",
            "Epoch 173/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 138.8950 - mae: 8.5814 - val_loss: 356.7754 - val_mae: 11.6930 - learning_rate: 4.2000e-05\n",
            "Epoch 174/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 87.5986 - mae: 6.8851 - val_loss: 353.9312 - val_mae: 11.5962 - learning_rate: 4.0500e-05\n",
            "Epoch 175/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 144.8337 - mae: 8.7679 - val_loss: 354.7842 - val_mae: 11.5392 - learning_rate: 3.9000e-05\n",
            "Epoch 176/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 99.1702 - mae: 7.1753 - val_loss: 357.1855 - val_mae: 11.6742 - learning_rate: 3.7500e-05\n",
            "Epoch 177/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 129.1013 - mae: 8.2924 - val_loss: 355.8922 - val_mae: 11.7445 - learning_rate: 3.6000e-05\n",
            "Epoch 178/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 118.4473 - mae: 7.9965 - val_loss: 355.0273 - val_mae: 11.6348 - learning_rate: 3.4500e-05\n",
            "Epoch 179/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 97.6158 - mae: 7.2802 - val_loss: 353.9160 - val_mae: 11.5508 - learning_rate: 3.3000e-05\n",
            "Epoch 180/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 113.1962 - mae: 7.7921 - val_loss: 355.9066 - val_mae: 11.6416 - learning_rate: 3.1500e-05\n",
            "Epoch 181/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 89.0851 - mae: 7.0140 - val_loss: 358.3217 - val_mae: 11.7124 - learning_rate: 3.0000e-05\n",
            "Epoch 182/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 112.8765 - mae: 7.6261 - val_loss: 360.5531 - val_mae: 11.7700 - learning_rate: 2.8500e-05\n",
            "Epoch 183/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 109.2855 - mae: 7.8180 - val_loss: 361.1924 - val_mae: 11.8081 - learning_rate: 2.7000e-05\n",
            "Epoch 184/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 109.0375 - mae: 7.9222 - val_loss: 356.5868 - val_mae: 11.6148 - learning_rate: 2.5500e-05\n",
            "Epoch 185/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 134.9107 - mae: 8.6420 - val_loss: 359.0527 - val_mae: 11.7145 - learning_rate: 2.4000e-05\n",
            "Epoch 186/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 119.3180 - mae: 7.8533 - val_loss: 359.8477 - val_mae: 11.7858 - learning_rate: 2.2500e-05\n",
            "Epoch 187/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 106.2133 - mae: 7.6436 - val_loss: 359.1800 - val_mae: 11.7408 - learning_rate: 2.1000e-05\n",
            "Epoch 188/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 93.5307 - mae: 7.0646 - val_loss: 360.2404 - val_mae: 11.7812 - learning_rate: 1.9500e-05\n",
            "Epoch 189/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 126.2744 - mae: 8.3083 - val_loss: 355.7459 - val_mae: 11.7140 - learning_rate: 1.8000e-05\n",
            "Epoch 190/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 112.3935 - mae: 7.8133 - val_loss: 356.7955 - val_mae: 11.6549 - learning_rate: 1.6500e-05\n",
            "Epoch 191/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 112.9399 - mae: 7.9190 - val_loss: 356.8748 - val_mae: 11.6082 - learning_rate: 1.5000e-05\n",
            "Epoch 192/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 109.6068 - mae: 7.7930 - val_loss: 357.1117 - val_mae: 11.6515 - learning_rate: 1.3500e-05\n",
            "Epoch 193/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 90.2631 - mae: 6.8206 - val_loss: 358.8856 - val_mae: 11.7264 - learning_rate: 1.2000e-05\n",
            "Epoch 194/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 91.4646 - mae: 6.9348 - val_loss: 358.8367 - val_mae: 11.6819 - learning_rate: 1.0500e-05\n",
            "Epoch 195/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 111.5115 - mae: 7.6416 - val_loss: 358.6243 - val_mae: 11.6987 - learning_rate: 9.0000e-06\n",
            "Epoch 196/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 107.2862 - mae: 7.3573 - val_loss: 356.6774 - val_mae: 11.6145 - learning_rate: 7.5000e-06\n",
            "Epoch 197/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 108.4697 - mae: 7.4286 - val_loss: 357.1813 - val_mae: 11.5941 - learning_rate: 6.0000e-06\n",
            "Epoch 198/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 118.8542 - mae: 7.9776 - val_loss: 357.1193 - val_mae: 11.5833 - learning_rate: 4.5000e-06\n",
            "Epoch 199/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 135.3221 - mae: 8.3933 - val_loss: 359.6821 - val_mae: 11.6332 - learning_rate: 3.0000e-06\n",
            "Epoch 200/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 112.5032 - mae: 7.5326 - val_loss: 360.1625 - val_mae: 11.6388 - learning_rate: 1.5000e-06\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\n",
            "Results for CNN_complex model:\n",
            "Метрика        Обучающая      Тестовая       Диссертация    \n",
            "MAE            3.7428     11.6388     53.2544\n",
            "MedAE          2.4778     6.2788     49.1453\n",
            "R²             0.9818     0.6193     -23.0585     \n",
            "RMSE           5.1386     18.9594     56.7989\n",
            "\n",
            "Сравнение моделей:\n",
            "Модель         MAE (test)     MedAE (test)   R² (test)      RMSE (test)    \n",
            "CNN_complex    53.2544     49.1453     -23.0585     56.7989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PCA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization, LSTM\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import QuantileTransformer, OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.decomposition import PCA  # Import PCA\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data (unchanged)\n",
        "train_df = pd.read_excel('/content/big_train_no_duples.xlsx')\n",
        "X = train_df.drop(columns=['mass'])\n",
        "y = train_df['mass']\n",
        "\n",
        "# Binning (unchanged)\n",
        "quantiles = [0, 0.25, 0.5, 0.75, 1]\n",
        "bins = [-1] + [y.quantile(q) for q in quantiles]\n",
        "y_binned = pd.cut(y, bins=bins, labels=False, duplicates='drop')\n",
        "\n",
        "# Define columns (unchanged)\n",
        "numerical_cols = ['% second component', 'day', 'ph']\n",
        "categorical_cols = ['type of pha', 'environment', 'form', 'dimensionality',\n",
        "                   'porosity', 'in vivo', 'enzymatic', 'form_type', 'environment_type']\n",
        "\n",
        "# Create preprocessing pipeline with PCA\n",
        "preprocessor = Pipeline(steps=[\n",
        "    ('col_transformer', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', Pipeline(steps=[\n",
        "                ('imputer', SimpleImputer(strategy='mean')),\n",
        "                ('scaler', StandardScaler())\n",
        "            ]), numerical_cols),\n",
        "            ('cat', Pipeline(steps=[\n",
        "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "                ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "            ]), categorical_cols)\n",
        "        ]\n",
        "    )),\n",
        "    ('pca', PCA(n_components=0.95))  # Retain 95% of variance\n",
        "])\n",
        "\n",
        "# Apply preprocessing and PCA\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Split data (unchanged)\n",
        "X_train, X_test, y_train, y_test, y_train_binned, y_test_binned = train_test_split(\n",
        "    X_preprocessed, y, y_binned,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_binned,\n",
        ")\n",
        "\n",
        "# Apply ADASYN (unchanged)\n",
        "adasyn = ADASYN(sampling_strategy='minority', n_neighbors=3, random_state=42)\n",
        "X_train_resampled, y_train_resampled_binned = adasyn.fit_resample(X_train, y_train_binned)\n",
        "\n",
        "# Map binned classes to bin centers (unchanged)\n",
        "bin_centers = [(bins[i] + bins[i + 1]) / 2 for i in range(len(bins) - 1)]\n",
        "y_train_resampled = np.array([bin_centers[int(cls)] for cls in y_train_resampled_binned])\n",
        "\n",
        "# Compute sample weights (unchanged)\n",
        "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_resampled_binned)\n",
        "\n",
        "# Prepare data for CNN\n",
        "X_train_processed = X_train_resampled\n",
        "X_test_processed = X_test\n",
        "\n",
        "# Reshape for CNN (adjust input shape based on PCA components)\n",
        "X_train_3d = np.expand_dims(X_train_processed, axis=1)  # Shape: (samples, 1, n_components)\n",
        "X_test_3d = np.expand_dims(X_test_processed, axis=1)\n",
        "\n",
        "# Define RMSE (unchanged)\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# CNN model (adjusted input shape)\n",
        "def create_cnn_model(input_shape, architecture='medium'):\n",
        "    model = Sequential()\n",
        "    if architecture == 'simple':\n",
        "        model.add(Conv1D(32, 1, activation='relu', input_shape=input_shape))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(1))\n",
        "    elif architecture == 'medium':\n",
        "        model.add(Conv1D(64, 1, activation='relu', input_shape=input_shape))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv1D(128, 1, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(1))\n",
        "    elif architecture == 'complex':\n",
        "        model.add(Conv1D(64, 1, activation='relu', input_shape=input_shape))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv1D(128, 1, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Conv1D(256, 1, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(256, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(Dropout(0.4))\n",
        "        model.add(Dense(128, activation='relu', kernel_regularizer=l2(1e-3)))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(1))\n",
        "    optimizer = RMSprop(learning_rate=3e-4, rho=0.9)\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Polynomial decay schedule (unchanged)\n",
        "def polynomial_decay_schedule(epoch, lr):\n",
        "    power = 1.0\n",
        "    max_epochs = 200\n",
        "    return 3e-4 * (1 - epoch / max_epochs) ** power\n",
        "\n",
        "# Define models (adjusted input shape)\n",
        "models_to_test = {\n",
        "    'CNN_complex': lambda: create_cnn_model((X_train_3d.shape[1], X_train_3d.shape[2]), 'complex')\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for model_name, model_creator in models_to_test.items():\n",
        "    # Callbacks (unchanged)\n",
        "    callbacks = [\n",
        "        LearningRateScheduler(polynomial_decay_schedule),\n",
        "    ]\n",
        "\n",
        "    model = model_creator()\n",
        "\n",
        "    train_data = X_train_3d\n",
        "    test_data = X_test_3d\n",
        "\n",
        "    # Train model (unchanged)\n",
        "    history = model.fit(\n",
        "        train_data, y_train_resampled,\n",
        "        validation_data=(test_data, y_test),\n",
        "        epochs=200,\n",
        "        batch_size=64,\n",
        "        callbacks=callbacks,\n",
        "        sample_weight=sample_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Validation data (apply PCA)\n",
        "    val_df = pd.read_excel('/content/final_test.xlsx')\n",
        "    X_val = val_df.drop(columns=['mass'])\n",
        "    y_val = val_df['mass']\n",
        "    X_val_preprocessed = preprocessor.transform(X_val)  # Apply same preprocessing + PCA\n",
        "    val_data = np.expand_dims(X_val_preprocessed, axis=1)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_train = model.predict(train_data).flatten()\n",
        "    y_pred_test = model.predict(test_data).flatten()\n",
        "    y_pred_val = model.predict(val_data).flatten()\n",
        "\n",
        "    # Metrics (unchanged)\n",
        "    metrics = {\n",
        "        'MAE_train': mean_absolute_error(y_train_resampled, y_pred_train),\n",
        "        'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
        "        'MAE_val': mean_absolute_error(y_val, y_pred_val),\n",
        "        'MedAE_train': median_absolute_error(y_train_resampled, y_pred_train),\n",
        "        'MedAE_test': median_absolute_error(y_test, y_pred_test),\n",
        "        'MedAE_val': median_absolute_error(y_val, y_pred_val),\n",
        "        'R2_train': r2_score(y_train_resampled, y_pred_train),\n",
        "        'R2_test': r2_score(y_test, y_pred_test),\n",
        "        'R2_val': r2_score(y_val, y_pred_val),\n",
        "        'RMSE_train': rmse(y_train_resampled, y_pred_train),\n",
        "        'RMSE_test': rmse(y_test, y_pred_test),\n",
        "        'RMSE_val': rmse(y_val, y_pred_val),\n",
        "        'history': history\n",
        "    }\n",
        "    results[model_name] = metrics\n",
        "\n",
        "    # Print results (unchanged)\n",
        "    print(f\"\\nResults for {model_name} model:\")\n",
        "    print(f\"{'Метрика':<15}{'Обучающая':<15}{'Тестовая':<15}{'Диссертация':<15}\")\n",
        "    print(f\"{'MAE':<15}{metrics['MAE_train']:.4f}{'':<5}{metrics['MAE_test']:.4f}{'':<5}{metrics['MAE_val']:.4f}\")\n",
        "    print(f\"{'MedAE':<15}{metrics['MedAE_train']:.4f}{'':<5}{metrics['MedAE_test']:.4f}{'':<5}{metrics['MedAE_val']:.4f}\")\n",
        "    print(f\"{'R²':<15}{metrics['R2_train']:.4f}{'':<5}{metrics['R2_test']:.4f}{'':<5}{metrics['R2_val']:.4f}\")\n",
        "    print(f\"{'RMSE':<15}{metrics['RMSE_train']:.4f}{'':<5}{metrics['RMSE_test']:.4f}{'':<5}{metrics['RMSE_val']:.4f}\")\n",
        "\n",
        "# Compare models (unchanged)\n",
        "print(\"\\nСравнение моделей:\")\n",
        "print(f\"{'Модель':<15}{'MAE (test)':<15}{'MedAE (test)':<15}{'R² (test)':<15}{'RMSE (test)':<15}\")\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name:<15}{metrics['MAE_val']:.4f}{'':<5}{metrics['MedAE_val']:.4f}{'':<5}{metrics['R2_val']:.4f}{'':<5}{metrics['RMSE_val']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D0qaUqQCLhi",
        "outputId": "e327f2c7-1d9a-4511-850d-61a8fdc784f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - loss: 4637.7837 - mae: 56.8374 - val_loss: 5644.7734 - val_mae: 68.5652 - learning_rate: 3.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4416.2266 - mae: 55.4765 - val_loss: 5624.6929 - val_mae: 68.4247 - learning_rate: 2.9850e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4179.7480 - mae: 54.1756 - val_loss: 5598.1816 - val_mae: 68.2415 - learning_rate: 2.9700e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3908.9604 - mae: 51.7490 - val_loss: 5563.0166 - val_mae: 67.9996 - learning_rate: 2.9550e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3901.2129 - mae: 52.2637 - val_loss: 5517.4697 - val_mae: 67.6880 - learning_rate: 2.9400e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3405.4043 - mae: 48.7167 - val_loss: 5464.7681 - val_mae: 67.3269 - learning_rate: 2.9250e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3156.1389 - mae: 46.5038 - val_loss: 5391.7471 - val_mae: 66.8307 - learning_rate: 2.9100e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2783.6545 - mae: 43.1708 - val_loss: 5307.5874 - val_mae: 66.2596 - learning_rate: 2.8950e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2412.5620 - mae: 40.1334 - val_loss: 5201.9312 - val_mae: 65.5346 - learning_rate: 2.8800e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2098.9834 - mae: 36.9816 - val_loss: 5062.9268 - val_mae: 64.5826 - learning_rate: 2.8650e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1591.4335 - mae: 31.8390 - val_loss: 4904.2822 - val_mae: 63.4761 - learning_rate: 2.8500e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1320.2987 - mae: 28.9454 - val_loss: 4743.2554 - val_mae: 62.3469 - learning_rate: 2.8350e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1005.2253 - mae: 25.1237 - val_loss: 4569.8555 - val_mae: 61.1283 - learning_rate: 2.8200e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 727.0109 - mae: 21.3787 - val_loss: 4402.4731 - val_mae: 59.9298 - learning_rate: 2.8050e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 656.7862 - mae: 20.2086 - val_loss: 4225.2124 - val_mae: 58.6701 - learning_rate: 2.7900e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 540.4236 - mae: 17.6729 - val_loss: 4139.8843 - val_mae: 58.0373 - learning_rate: 2.7750e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 522.7336 - mae: 17.6211 - val_loss: 3966.3674 - val_mae: 56.7398 - learning_rate: 2.7600e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 467.6867 - mae: 16.0306 - val_loss: 3927.6089 - val_mae: 56.4469 - learning_rate: 2.7450e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 497.2147 - mae: 17.2481 - val_loss: 3748.2766 - val_mae: 55.1271 - learning_rate: 2.7300e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 400.6517 - mae: 14.8099 - val_loss: 3741.5122 - val_mae: 55.0908 - learning_rate: 2.7150e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 392.3261 - mae: 14.9230 - val_loss: 3559.1292 - val_mae: 53.7257 - learning_rate: 2.7000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 447.9646 - mae: 15.7428 - val_loss: 3460.8411 - val_mae: 52.9639 - learning_rate: 2.6850e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 425.6162 - mae: 15.7218 - val_loss: 3383.7512 - val_mae: 52.3810 - learning_rate: 2.6700e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 343.7403 - mae: 13.7380 - val_loss: 3242.9878 - val_mae: 51.2697 - learning_rate: 2.6550e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 372.1771 - mae: 14.6625 - val_loss: 3176.1970 - val_mae: 50.7482 - learning_rate: 2.6400e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 371.8779 - mae: 14.3899 - val_loss: 3118.5801 - val_mae: 50.3020 - learning_rate: 2.6250e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 332.5873 - mae: 13.9770 - val_loss: 3048.3689 - val_mae: 49.7728 - learning_rate: 2.6100e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 287.3194 - mae: 13.0140 - val_loss: 3032.3262 - val_mae: 49.6435 - learning_rate: 2.5950e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 301.7305 - mae: 12.8037 - val_loss: 2817.2832 - val_mae: 47.8523 - learning_rate: 2.5800e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 293.6989 - mae: 13.0070 - val_loss: 2806.2485 - val_mae: 47.7435 - learning_rate: 2.5650e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 285.6899 - mae: 12.5035 - val_loss: 2646.5598 - val_mae: 46.3291 - learning_rate: 2.5500e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 277.4554 - mae: 12.5848 - val_loss: 2674.9302 - val_mae: 46.6289 - learning_rate: 2.5350e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 303.3265 - mae: 12.7710 - val_loss: 2563.7371 - val_mae: 45.6355 - learning_rate: 2.5200e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 315.0085 - mae: 13.3593 - val_loss: 2455.9290 - val_mae: 44.6671 - learning_rate: 2.5050e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 315.3106 - mae: 12.9731 - val_loss: 2466.3047 - val_mae: 44.7546 - learning_rate: 2.4900e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 238.6060 - mae: 11.4183 - val_loss: 2294.0273 - val_mae: 43.1302 - learning_rate: 2.4750e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 237.5557 - mae: 11.4160 - val_loss: 2196.7378 - val_mae: 42.2308 - learning_rate: 2.4600e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 279.6075 - mae: 12.6895 - val_loss: 2150.5557 - val_mae: 41.8417 - learning_rate: 2.4450e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 227.2594 - mae: 11.1583 - val_loss: 2054.1567 - val_mae: 40.8286 - learning_rate: 2.4300e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 243.5625 - mae: 12.3030 - val_loss: 1953.9075 - val_mae: 39.8202 - learning_rate: 2.4150e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 216.5197 - mae: 11.2589 - val_loss: 1846.9401 - val_mae: 38.6933 - learning_rate: 2.4000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 239.0379 - mae: 11.5380 - val_loss: 1833.9327 - val_mae: 38.5819 - learning_rate: 2.3850e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 237.2131 - mae: 11.6106 - val_loss: 1781.9420 - val_mae: 37.9848 - learning_rate: 2.3700e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 222.8560 - mae: 11.1456 - val_loss: 1649.1617 - val_mae: 36.5518 - learning_rate: 2.3550e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 218.1639 - mae: 11.2939 - val_loss: 1553.6820 - val_mae: 35.4557 - learning_rate: 2.3400e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 249.7220 - mae: 11.8421 - val_loss: 1538.0303 - val_mae: 35.2060 - learning_rate: 2.3250e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 244.9162 - mae: 11.7577 - val_loss: 1413.8264 - val_mae: 33.7102 - learning_rate: 2.3100e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 217.9961 - mae: 10.8254 - val_loss: 1311.6923 - val_mae: 32.4477 - learning_rate: 2.2950e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 211.7547 - mae: 11.2262 - val_loss: 1258.0811 - val_mae: 31.6905 - learning_rate: 2.2800e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 175.8238 - mae: 10.4106 - val_loss: 1295.4760 - val_mae: 32.2125 - learning_rate: 2.2650e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 193.3458 - mae: 10.8006 - val_loss: 1215.2865 - val_mae: 31.1502 - learning_rate: 2.2500e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 214.3305 - mae: 10.9244 - val_loss: 1145.4961 - val_mae: 30.2364 - learning_rate: 2.2350e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 189.7520 - mae: 10.3340 - val_loss: 1185.3270 - val_mae: 30.8928 - learning_rate: 2.2200e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 184.5427 - mae: 10.3165 - val_loss: 1101.1931 - val_mae: 29.6487 - learning_rate: 2.2050e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 217.1313 - mae: 10.9659 - val_loss: 1035.3300 - val_mae: 28.6712 - learning_rate: 2.1900e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 185.1882 - mae: 10.2138 - val_loss: 1105.3613 - val_mae: 29.8236 - learning_rate: 2.1750e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 238.5415 - mae: 11.6317 - val_loss: 997.5743 - val_mae: 28.1472 - learning_rate: 2.1600e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 193.7870 - mae: 10.3330 - val_loss: 945.7188 - val_mae: 27.2538 - learning_rate: 2.1450e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 233.9317 - mae: 11.3327 - val_loss: 808.4476 - val_mae: 24.8742 - learning_rate: 2.1300e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 215.6988 - mae: 11.1372 - val_loss: 861.4296 - val_mae: 26.0335 - learning_rate: 2.1150e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 187.9515 - mae: 9.9583 - val_loss: 782.4956 - val_mae: 24.5001 - learning_rate: 2.1000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 201.2173 - mae: 10.6053 - val_loss: 838.6783 - val_mae: 25.6117 - learning_rate: 2.0850e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 192.9619 - mae: 10.5067 - val_loss: 696.8536 - val_mae: 22.9105 - learning_rate: 2.0700e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 149.7484 - mae: 9.4436 - val_loss: 678.3420 - val_mae: 22.5615 - learning_rate: 2.0550e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 207.2121 - mae: 11.0618 - val_loss: 622.6353 - val_mae: 21.2996 - learning_rate: 2.0400e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 208.5971 - mae: 10.6630 - val_loss: 656.0342 - val_mae: 22.0810 - learning_rate: 2.0250e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 168.5041 - mae: 10.1421 - val_loss: 656.6013 - val_mae: 22.2043 - learning_rate: 2.0100e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 168.0715 - mae: 9.5459 - val_loss: 588.4440 - val_mae: 20.5793 - learning_rate: 1.9950e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 158.5931 - mae: 9.6620 - val_loss: 520.7490 - val_mae: 18.7778 - learning_rate: 1.9800e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 237.3686 - mae: 11.0661 - val_loss: 493.6010 - val_mae: 18.1249 - learning_rate: 1.9650e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 165.0213 - mae: 9.7991 - val_loss: 470.8633 - val_mae: 17.4295 - learning_rate: 1.9500e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 212.1393 - mae: 11.3722 - val_loss: 471.7965 - val_mae: 17.5461 - learning_rate: 1.9350e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 198.5175 - mae: 10.6602 - val_loss: 471.9336 - val_mae: 17.5626 - learning_rate: 1.9200e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 175.9667 - mae: 10.3458 - val_loss: 490.0546 - val_mae: 17.9951 - learning_rate: 1.9050e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 170.7879 - mae: 9.5733 - val_loss: 462.0144 - val_mae: 17.2695 - learning_rate: 1.8900e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 189.2591 - mae: 11.0761 - val_loss: 442.3371 - val_mae: 16.4754 - learning_rate: 1.8750e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 157.8967 - mae: 9.5869 - val_loss: 437.3204 - val_mae: 16.1901 - learning_rate: 1.8600e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 166.5763 - mae: 10.0906 - val_loss: 423.0811 - val_mae: 15.7924 - learning_rate: 1.8450e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 125.6104 - mae: 8.4703 - val_loss: 414.0300 - val_mae: 15.4334 - learning_rate: 1.8300e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 155.5650 - mae: 9.5681 - val_loss: 398.6898 - val_mae: 14.8834 - learning_rate: 1.8150e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 187.5575 - mae: 9.8739 - val_loss: 381.1347 - val_mae: 14.3229 - learning_rate: 1.8000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 172.6037 - mae: 9.9932 - val_loss: 369.4028 - val_mae: 13.8635 - learning_rate: 1.7850e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 137.8180 - mae: 8.5589 - val_loss: 344.7744 - val_mae: 13.1295 - learning_rate: 1.7700e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 164.0162 - mae: 9.5736 - val_loss: 355.7669 - val_mae: 13.4975 - learning_rate: 1.7550e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 147.2356 - mae: 8.8724 - val_loss: 348.0009 - val_mae: 13.1987 - learning_rate: 1.7400e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 137.5247 - mae: 8.9740 - val_loss: 346.4122 - val_mae: 13.0246 - learning_rate: 1.7250e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 153.7792 - mae: 9.1380 - val_loss: 340.3817 - val_mae: 13.0915 - learning_rate: 1.7100e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 188.4097 - mae: 10.2444 - val_loss: 341.9675 - val_mae: 12.8919 - learning_rate: 1.6950e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 165.2228 - mae: 9.6839 - val_loss: 340.3287 - val_mae: 12.9149 - learning_rate: 1.6800e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 168.3910 - mae: 9.7659 - val_loss: 358.3458 - val_mae: 13.4360 - learning_rate: 1.6650e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 133.7483 - mae: 8.7592 - val_loss: 360.9962 - val_mae: 13.4553 - learning_rate: 1.6500e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 153.0693 - mae: 9.0988 - val_loss: 333.2649 - val_mae: 12.3703 - learning_rate: 1.6350e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 163.0688 - mae: 9.9146 - val_loss: 335.7060 - val_mae: 12.5004 - learning_rate: 1.6200e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 164.2032 - mae: 9.4801 - val_loss: 327.1653 - val_mae: 12.3981 - learning_rate: 1.6050e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 151.2940 - mae: 9.2684 - val_loss: 334.4376 - val_mae: 12.6687 - learning_rate: 1.5900e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 177.9617 - mae: 10.2798 - val_loss: 330.0560 - val_mae: 12.4045 - learning_rate: 1.5750e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 157.7892 - mae: 9.3067 - val_loss: 315.9355 - val_mae: 11.7918 - learning_rate: 1.5600e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 133.7087 - mae: 8.7904 - val_loss: 310.9554 - val_mae: 11.6193 - learning_rate: 1.5450e-04\n",
            "Epoch 99/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 155.2941 - mae: 9.1854 - val_loss: 315.5931 - val_mae: 11.4276 - learning_rate: 1.5300e-04\n",
            "Epoch 100/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 149.1027 - mae: 8.7984 - val_loss: 304.5003 - val_mae: 11.6119 - learning_rate: 1.5150e-04\n",
            "Epoch 101/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 169.7743 - mae: 9.7348 - val_loss: 306.3069 - val_mae: 12.0127 - learning_rate: 1.5000e-04\n",
            "Epoch 102/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 175.2038 - mae: 10.4123 - val_loss: 319.9055 - val_mae: 12.4927 - learning_rate: 1.4850e-04\n",
            "Epoch 103/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 136.9385 - mae: 8.6402 - val_loss: 311.5545 - val_mae: 11.9597 - learning_rate: 1.4700e-04\n",
            "Epoch 104/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 127.9185 - mae: 8.3214 - val_loss: 309.9522 - val_mae: 11.7170 - learning_rate: 1.4550e-04\n",
            "Epoch 105/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 115.8039 - mae: 7.8403 - val_loss: 307.3969 - val_mae: 11.7736 - learning_rate: 1.4400e-04\n",
            "Epoch 106/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 149.5813 - mae: 9.3476 - val_loss: 299.4518 - val_mae: 11.3034 - learning_rate: 1.4250e-04\n",
            "Epoch 107/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 139.7339 - mae: 8.8958 - val_loss: 301.6961 - val_mae: 11.2887 - learning_rate: 1.4100e-04\n",
            "Epoch 108/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 148.2429 - mae: 9.1079 - val_loss: 310.4263 - val_mae: 11.4116 - learning_rate: 1.3950e-04\n",
            "Epoch 109/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 182.9612 - mae: 9.8803 - val_loss: 307.6132 - val_mae: 11.4993 - learning_rate: 1.3800e-04\n",
            "Epoch 110/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 115.9624 - mae: 7.8903 - val_loss: 306.4796 - val_mae: 11.4456 - learning_rate: 1.3650e-04\n",
            "Epoch 111/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 153.8202 - mae: 9.2601 - val_loss: 306.4138 - val_mae: 11.3854 - learning_rate: 1.3500e-04\n",
            "Epoch 112/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 147.5603 - mae: 9.0549 - val_loss: 299.8393 - val_mae: 11.5756 - learning_rate: 1.3350e-04\n",
            "Epoch 113/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 121.7556 - mae: 8.2198 - val_loss: 301.9931 - val_mae: 11.5411 - learning_rate: 1.3200e-04\n",
            "Epoch 114/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 124.0186 - mae: 8.1094 - val_loss: 306.0608 - val_mae: 11.2203 - learning_rate: 1.3050e-04\n",
            "Epoch 115/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 151.2923 - mae: 8.8587 - val_loss: 303.3637 - val_mae: 11.3203 - learning_rate: 1.2900e-04\n",
            "Epoch 116/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 157.3266 - mae: 9.2739 - val_loss: 309.4905 - val_mae: 11.2156 - learning_rate: 1.2750e-04\n",
            "Epoch 117/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 169.9522 - mae: 9.5855 - val_loss: 312.0532 - val_mae: 10.9898 - learning_rate: 1.2600e-04\n",
            "Epoch 118/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 150.6285 - mae: 9.0720 - val_loss: 315.2006 - val_mae: 11.2153 - learning_rate: 1.2450e-04\n",
            "Epoch 119/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 142.1945 - mae: 8.6917 - val_loss: 308.8440 - val_mae: 11.2067 - learning_rate: 1.2300e-04\n",
            "Epoch 120/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 115.1246 - mae: 8.0443 - val_loss: 309.6136 - val_mae: 11.4198 - learning_rate: 1.2150e-04\n",
            "Epoch 121/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 120.6106 - mae: 7.8630 - val_loss: 306.3108 - val_mae: 11.3767 - learning_rate: 1.2000e-04\n",
            "Epoch 122/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 142.7056 - mae: 8.9652 - val_loss: 302.4483 - val_mae: 11.1022 - learning_rate: 1.1850e-04\n",
            "Epoch 123/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 134.9920 - mae: 8.6250 - val_loss: 304.1820 - val_mae: 11.1453 - learning_rate: 1.1700e-04\n",
            "Epoch 124/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 159.0804 - mae: 8.9534 - val_loss: 300.8062 - val_mae: 10.9687 - learning_rate: 1.1550e-04\n",
            "Epoch 125/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 141.2484 - mae: 8.8276 - val_loss: 295.2122 - val_mae: 10.9073 - learning_rate: 1.1400e-04\n",
            "Epoch 126/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 175.0751 - mae: 9.4602 - val_loss: 292.9417 - val_mae: 10.7979 - learning_rate: 1.1250e-04\n",
            "Epoch 127/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 134.4228 - mae: 8.3691 - val_loss: 295.1763 - val_mae: 10.8540 - learning_rate: 1.1100e-04\n",
            "Epoch 128/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 181.5645 - mae: 9.1946 - val_loss: 297.9757 - val_mae: 10.5542 - learning_rate: 1.0950e-04\n",
            "Epoch 129/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 110.8847 - mae: 7.9208 - val_loss: 292.4626 - val_mae: 10.6919 - learning_rate: 1.0800e-04\n",
            "Epoch 130/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 140.1239 - mae: 8.8697 - val_loss: 293.0349 - val_mae: 10.8242 - learning_rate: 1.0650e-04\n",
            "Epoch 131/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 120.0316 - mae: 8.0452 - val_loss: 299.6473 - val_mae: 10.7069 - learning_rate: 1.0500e-04\n",
            "Epoch 132/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 140.5339 - mae: 9.0050 - val_loss: 293.7105 - val_mae: 10.6833 - learning_rate: 1.0350e-04\n",
            "Epoch 133/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 120.6833 - mae: 8.2392 - val_loss: 292.3230 - val_mae: 10.7637 - learning_rate: 1.0200e-04\n",
            "Epoch 134/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 114.4173 - mae: 7.5608 - val_loss: 293.5246 - val_mae: 10.7267 - learning_rate: 1.0050e-04\n",
            "Epoch 135/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 129.5347 - mae: 8.2265 - val_loss: 298.0874 - val_mae: 10.9271 - learning_rate: 9.9000e-05\n",
            "Epoch 136/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 115.2683 - mae: 7.6787 - val_loss: 300.6642 - val_mae: 11.0710 - learning_rate: 9.7500e-05\n",
            "Epoch 137/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 147.6977 - mae: 9.0230 - val_loss: 293.8244 - val_mae: 10.8931 - learning_rate: 9.6000e-05\n",
            "Epoch 138/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 148.1534 - mae: 8.9919 - val_loss: 297.0426 - val_mae: 11.1611 - learning_rate: 9.4500e-05\n",
            "Epoch 139/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 114.7276 - mae: 7.9476 - val_loss: 295.2881 - val_mae: 11.2299 - learning_rate: 9.3000e-05\n",
            "Epoch 140/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 131.9019 - mae: 8.4444 - val_loss: 297.8729 - val_mae: 11.1907 - learning_rate: 9.1500e-05\n",
            "Epoch 141/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 127.4868 - mae: 8.3413 - val_loss: 299.1517 - val_mae: 11.2492 - learning_rate: 9.0000e-05\n",
            "Epoch 142/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 137.9018 - mae: 8.3566 - val_loss: 295.3614 - val_mae: 11.0154 - learning_rate: 8.8500e-05\n",
            "Epoch 143/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 157.2968 - mae: 9.0690 - val_loss: 296.9404 - val_mae: 10.9506 - learning_rate: 8.7000e-05\n",
            "Epoch 144/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 129.1914 - mae: 8.5262 - val_loss: 301.9450 - val_mae: 11.0614 - learning_rate: 8.5500e-05\n",
            "Epoch 145/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 118.7426 - mae: 7.7876 - val_loss: 301.4080 - val_mae: 11.0653 - learning_rate: 8.4000e-05\n",
            "Epoch 146/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 127.7648 - mae: 8.3175 - val_loss: 295.6691 - val_mae: 11.0934 - learning_rate: 8.2500e-05\n",
            "Epoch 147/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 158.4375 - mae: 9.4995 - val_loss: 289.8907 - val_mae: 11.1148 - learning_rate: 8.1000e-05\n",
            "Epoch 148/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 116.6896 - mae: 7.7332 - val_loss: 286.9474 - val_mae: 11.0074 - learning_rate: 7.9500e-05\n",
            "Epoch 149/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 154.4485 - mae: 9.3530 - val_loss: 292.6009 - val_mae: 11.1204 - learning_rate: 7.8000e-05\n",
            "Epoch 150/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 123.8620 - mae: 7.9974 - val_loss: 293.3513 - val_mae: 11.1354 - learning_rate: 7.6500e-05\n",
            "Epoch 151/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 96.4780 - mae: 7.2432 - val_loss: 294.3454 - val_mae: 11.2127 - learning_rate: 7.5000e-05\n",
            "Epoch 152/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 142.4926 - mae: 8.4704 - val_loss: 291.2198 - val_mae: 11.0956 - learning_rate: 7.3500e-05\n",
            "Epoch 153/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 100.9326 - mae: 7.3357 - val_loss: 292.6103 - val_mae: 11.1153 - learning_rate: 7.2000e-05\n",
            "Epoch 154/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 159.2100 - mae: 9.0048 - val_loss: 293.9341 - val_mae: 11.0265 - learning_rate: 7.0500e-05\n",
            "Epoch 155/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 116.7578 - mae: 7.8994 - val_loss: 292.2996 - val_mae: 11.0679 - learning_rate: 6.9000e-05\n",
            "Epoch 156/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 112.6787 - mae: 7.6286 - val_loss: 292.4122 - val_mae: 11.1874 - learning_rate: 6.7500e-05\n",
            "Epoch 157/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 137.4663 - mae: 8.6850 - val_loss: 295.4590 - val_mae: 11.1117 - learning_rate: 6.6000e-05\n",
            "Epoch 158/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 119.3401 - mae: 8.1206 - val_loss: 298.9259 - val_mae: 10.9496 - learning_rate: 6.4500e-05\n",
            "Epoch 159/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 134.4625 - mae: 8.3162 - val_loss: 299.5411 - val_mae: 10.9250 - learning_rate: 6.3000e-05\n",
            "Epoch 160/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 124.1334 - mae: 8.1820 - val_loss: 302.1414 - val_mae: 10.9205 - learning_rate: 6.1500e-05\n",
            "Epoch 161/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 118.0434 - mae: 7.9757 - val_loss: 303.9039 - val_mae: 10.8775 - learning_rate: 6.0000e-05\n",
            "Epoch 162/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 139.8883 - mae: 8.5000 - val_loss: 305.5681 - val_mae: 10.9582 - learning_rate: 5.8500e-05\n",
            "Epoch 163/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 145.1521 - mae: 8.9285 - val_loss: 306.6008 - val_mae: 11.0615 - learning_rate: 5.7000e-05\n",
            "Epoch 164/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 116.3848 - mae: 7.8596 - val_loss: 301.2824 - val_mae: 10.9459 - learning_rate: 5.5500e-05\n",
            "Epoch 165/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 133.4911 - mae: 7.9607 - val_loss: 298.2430 - val_mae: 10.8104 - learning_rate: 5.4000e-05\n",
            "Epoch 166/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 139.7261 - mae: 8.5415 - val_loss: 298.8278 - val_mae: 10.7845 - learning_rate: 5.2500e-05\n",
            "Epoch 167/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 108.2222 - mae: 7.3034 - val_loss: 300.7540 - val_mae: 10.8048 - learning_rate: 5.1000e-05\n",
            "Epoch 168/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 138.7921 - mae: 8.4908 - val_loss: 298.0197 - val_mae: 10.7274 - learning_rate: 4.9500e-05\n",
            "Epoch 169/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 124.1076 - mae: 8.2620 - val_loss: 298.7077 - val_mae: 10.8099 - learning_rate: 4.8000e-05\n",
            "Epoch 170/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 125.7704 - mae: 8.1078 - val_loss: 299.2344 - val_mae: 10.7340 - learning_rate: 4.6500e-05\n",
            "Epoch 171/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 108.8346 - mae: 7.8695 - val_loss: 301.7860 - val_mae: 10.7926 - learning_rate: 4.5000e-05\n",
            "Epoch 172/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 161.7997 - mae: 9.2565 - val_loss: 301.2947 - val_mae: 10.7894 - learning_rate: 4.3500e-05\n",
            "Epoch 173/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 124.0640 - mae: 8.0805 - val_loss: 300.5888 - val_mae: 10.7405 - learning_rate: 4.2000e-05\n",
            "Epoch 174/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 131.2560 - mae: 8.4902 - val_loss: 298.7183 - val_mae: 10.7067 - learning_rate: 4.0500e-05\n",
            "Epoch 175/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 134.9477 - mae: 8.2600 - val_loss: 299.4547 - val_mae: 10.6423 - learning_rate: 3.9000e-05\n",
            "Epoch 176/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 125.1100 - mae: 8.4505 - val_loss: 301.0547 - val_mae: 10.6885 - learning_rate: 3.7500e-05\n",
            "Epoch 177/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 121.4859 - mae: 8.0679 - val_loss: 300.0800 - val_mae: 10.7857 - learning_rate: 3.6000e-05\n",
            "Epoch 178/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 117.7465 - mae: 7.9447 - val_loss: 300.1537 - val_mae: 10.8445 - learning_rate: 3.4500e-05\n",
            "Epoch 179/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 122.7115 - mae: 7.9422 - val_loss: 301.3585 - val_mae: 10.9128 - learning_rate: 3.3000e-05\n",
            "Epoch 180/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 146.0709 - mae: 8.8941 - val_loss: 303.1985 - val_mae: 10.9286 - learning_rate: 3.1500e-05\n",
            "Epoch 181/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 122.4986 - mae: 8.0196 - val_loss: 303.1386 - val_mae: 10.8998 - learning_rate: 3.0000e-05\n",
            "Epoch 182/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 146.8035 - mae: 8.6538 - val_loss: 302.5969 - val_mae: 10.8834 - learning_rate: 2.8500e-05\n",
            "Epoch 183/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 121.2085 - mae: 7.8894 - val_loss: 302.3348 - val_mae: 10.8905 - learning_rate: 2.7000e-05\n",
            "Epoch 184/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 123.1040 - mae: 8.3815 - val_loss: 303.6613 - val_mae: 10.9124 - learning_rate: 2.5500e-05\n",
            "Epoch 185/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 121.0921 - mae: 8.0346 - val_loss: 303.0905 - val_mae: 10.9237 - learning_rate: 2.4000e-05\n",
            "Epoch 186/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 116.3345 - mae: 7.7613 - val_loss: 301.8224 - val_mae: 10.9390 - learning_rate: 2.2500e-05\n",
            "Epoch 187/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 133.0442 - mae: 8.6780 - val_loss: 301.3670 - val_mae: 10.8842 - learning_rate: 2.1000e-05\n",
            "Epoch 188/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 95.5080 - mae: 7.3680 - val_loss: 301.1041 - val_mae: 10.8973 - learning_rate: 1.9500e-05\n",
            "Epoch 189/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 120.1303 - mae: 8.0750 - val_loss: 299.3237 - val_mae: 10.8769 - learning_rate: 1.8000e-05\n",
            "Epoch 190/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 117.6630 - mae: 8.0399 - val_loss: 297.6461 - val_mae: 10.8345 - learning_rate: 1.6500e-05\n",
            "Epoch 191/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 124.3719 - mae: 7.8528 - val_loss: 299.0871 - val_mae: 10.8403 - learning_rate: 1.5000e-05\n",
            "Epoch 192/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 134.4092 - mae: 8.4459 - val_loss: 300.0019 - val_mae: 10.8559 - learning_rate: 1.3500e-05\n",
            "Epoch 193/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 134.6969 - mae: 8.4756 - val_loss: 298.9802 - val_mae: 10.8810 - learning_rate: 1.2000e-05\n",
            "Epoch 194/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 136.5059 - mae: 8.5512 - val_loss: 297.2106 - val_mae: 10.8646 - learning_rate: 1.0500e-05\n",
            "Epoch 195/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 147.3431 - mae: 8.9729 - val_loss: 297.6429 - val_mae: 10.8571 - learning_rate: 9.0000e-06\n",
            "Epoch 196/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 118.2884 - mae: 7.6071 - val_loss: 298.4587 - val_mae: 10.8651 - learning_rate: 7.5000e-06\n",
            "Epoch 197/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 126.7514 - mae: 8.2649 - val_loss: 299.7690 - val_mae: 10.8708 - learning_rate: 6.0000e-06\n",
            "Epoch 198/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 139.8328 - mae: 8.6046 - val_loss: 299.8420 - val_mae: 10.8895 - learning_rate: 4.5000e-06\n",
            "Epoch 199/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 125.6039 - mae: 8.2835 - val_loss: 299.9239 - val_mae: 10.9270 - learning_rate: 3.0000e-06\n",
            "Epoch 200/200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 129.2406 - mae: 8.1755 - val_loss: 299.9050 - val_mae: 10.9089 - learning_rate: 1.5000e-06\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\n",
            "Results for CNN_complex model:\n",
            "Метрика        Обучающая      Тестовая       Диссертация    \n",
            "MAE            4.4692     10.9089     51.7836\n",
            "MedAE          2.6781     7.5904     48.0832\n",
            "R²             0.9745     0.6831     -23.7809\n",
            "RMSE           6.0832     17.2973     57.6452\n",
            "\n",
            "Сравнение моделей:\n",
            "Модель         MAE (test)     MedAE (test)   R² (test)      RMSE (test)    \n",
            "CNN_complex    51.7836     48.0832     -23.7809     57.6452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute and print feature importance\n",
        "def print_pca_feature_importance(preprocessor, numerical_cols, categorical_cols):\n",
        "    # Get the ColumnTransformer and PCA steps\n",
        "    col_transformer = preprocessor.named_steps['col_transformer']\n",
        "    pca = preprocessor.named_steps['pca']\n",
        "\n",
        "    # Get feature names after preprocessing\n",
        "    num_features = numerical_cols\n",
        "    cat_transformer = col_transformer.named_transformers_['cat']\n",
        "    onehot_encoder = cat_transformer.named_steps['onehot']\n",
        "    cat_features = onehot_encoder.get_feature_names_out(categorical_cols)\n",
        "    all_features = list(num_features) + list(cat_features)\n",
        "\n",
        "    # Get PCA loadings (components_ matrix)\n",
        "    loadings = pca.components_.T  # Shape: (n_features, n_components)\n",
        "\n",
        "    # Compute feature importance as weighted sum of squared loadings\n",
        "    explained_variance = pca.explained_variance_  # Variance per component\n",
        "    total_variance = np.sum(explained_variance)\n",
        "    weights = explained_variance / total_variance  # Normalize weights\n",
        "\n",
        "    # Importance is the sum of squared loadings, weighted by explained variance\n",
        "    feature_importance = np.sum((loadings ** 2) * weights, axis=1)\n",
        "\n",
        "    # Create a DataFrame for feature importance\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': all_features,\n",
        "        'Importance': feature_importance\n",
        "    })\n",
        "\n",
        "    # Aggregate importance for categorical features (sum importance of one-hot encoded columns)\n",
        "    aggregated_importance = []\n",
        "    for col in numerical_cols + categorical_cols:\n",
        "        if col in numerical_cols:\n",
        "            # For numerical features, take the importance directly\n",
        "            importance = importance_df[importance_df['Feature'] == col]['Importance'].sum()\n",
        "            aggregated_importance.append((col, importance))\n",
        "        else:\n",
        "            # For categorical features, sum the importance of all one-hot encoded columns\n",
        "            related_features = [f for f in all_features if f.startswith(f\"{col}_\")]\n",
        "            importance = importance_df[importance_df['Feature'].isin(related_features)]['Importance'].sum()\n",
        "            aggregated_importance.append((col, importance))\n",
        "\n",
        "    # Create aggregated importance DataFrame\n",
        "    agg_importance_df = pd.DataFrame(aggregated_importance, columns=['Feature', 'Importance'])\n",
        "\n",
        "    # Sort by importance\n",
        "    agg_importance_df = agg_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nPCA Feature Importance:\")\n",
        "    print(f\"{'Feature':<30}{'Importance':<15}\")\n",
        "    print(\"-\" * 45)\n",
        "    for _, row in agg_importance_df.iterrows():\n",
        "        print(f\"{row['Feature']:<30}{row['Importance']:.6f}\")\n",
        "\n",
        "    return agg_importance_df\n",
        "\n",
        "# Print feature importance\n",
        "importance_df = print_pca_feature_importance(preprocessor, numerical_cols, categorical_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfxp41p8DAdi",
        "outputId": "f6feb485-4597-4eb2-ba75-e9632f2ce057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PCA Feature Importance:\n",
            "Feature                       Importance     \n",
            "---------------------------------------------\n",
            "environment                   0.185420\n",
            "day                           0.132807\n",
            "% second component            0.132625\n",
            "ph                            0.132464\n",
            "form                          0.127045\n",
            "environment_type              0.100338\n",
            "type of pha                   0.089464\n",
            "in vivo                       0.065931\n",
            "enzymatic                     0.062917\n",
            "form_type                     0.042710\n",
            "dimensionality                0.042041\n",
            "porosity                      0.029286\n"
          ]
        }
      ]
    }
  ]
}